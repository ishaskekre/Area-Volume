{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishaskekre/Area-Volume/blob/master/ssd_extending.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7HhcFKnSS3i",
        "outputId": "7ec47a71-0d3e-459a-aa7d-f51bf894921a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pytorch_SSD' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jjjkkkjjj/pytorch_SSD.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08whFxloShoh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('..')\n",
        "os.chdir('pytorch_SSD')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQTQ7wWeSxYP",
        "outputId": "6cb4edee-cbd5-4d40-d966-771c0c3a445c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycurl in /usr/local/lib/python3.7/dist-packages (7.44.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycurl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWavt2kySm9n",
        "outputId": "3b188694-1963-4647-8132-6440de898557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  241M  100  241M    0     0  35.4M      0  0:00:06  0:00:06 --:--:-- 37.5M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 12.5G  100 12.5G    0     0  43.1M      0  0:04:58  0:04:58 --:--:-- 42.9M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 6337M  100 6337M    0     0  43.5M      0  0:02:25  0:02:25 --:--:-- 45.4M\n"
          ]
        }
      ],
      "source": [
        "!python get_dataset.py --datasets coco2014_trainval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsyyhlHSbVYr",
        "outputId": "2679ef00-482a-4466-e195-da07002aac56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.4.0+cu100\n",
            "  Downloading https://download.pytorch.org/whl/cu100/torch-1.4.0%2Bcu100-cp37-cp37m-linux_x86_64.whl (723.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 723.9 MB 22 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0+cu100\n",
            "  Downloading https://download.pytorch.org/whl/cu100/torchvision-0.5.0%2Bcu100-cp37-cp37m-linux_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0+cu100) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0+cu100) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0+cu100) (1.15.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0+cu100 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0+cu100 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0+cu100 torchvision-0.5.0+cu100\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.4.0+cu100 torchvision==0.5.0+cu100 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4Zh9fcGbJFL",
        "outputId": "81875371-ed3b-477f-a92c-844b251000c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=13.06s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO:root:Dataset info:\n",
            "root dir: ['/root/data/coco/coco2014/trainval'],\n",
            "focus: ['train2014'],\n",
            "labels:['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
            "ignore object: None\n",
            "augmentation: True\n",
            "batch size: 32\n",
            "num_workers: 4\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /pytorch_SSD/weights/vgg16-397923af.pth\n",
            "100% 528M/528M [00:02<00:00, 226MB/s]\n",
            "INFO:root:model loaded\n",
            "INFO:root:DataParallel(\n",
            "  (module): SSD300(\n",
            "    (codec): Codec(\n",
            "      (encoder): Encoder()\n",
            "      (decoder): Decoder()\n",
            "    )\n",
            "    (defaultBox): DBoxSSDOriginal()\n",
            "    (predictor): Predictor()\n",
            "    (inferenceBox): InferenceBox()\n",
            "    (feature_layers): ModuleDict(\n",
            "      (convRL1_1): ConvRelu(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL1_2): ConvRelu(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convRL2_1): ConvRelu(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL2_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convRL3_1): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL3_2): ConvRelu(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL3_3): ConvRelu(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=True)\n",
            "      (convRL4_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL4_2): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL4_3): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convRL5_1): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL5_2): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL5_3): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool5): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1, dilation=1, ceil_mode=False)\n",
            "      (convRL6): ConvRelu(\n",
            "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL7): ConvRelu(\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL8_1): ConvRelu(\n",
            "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL8_2): ConvRelu(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL9_1): ConvRelu(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL9_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL10_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL10_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL11_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL11_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (addon_layers): ModuleDict(\n",
            "      (addon_1): L2Normalization()\n",
            "    )\n",
            "    (localization_layers): ModuleDict(\n",
            "      (conv_loc_1): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_2): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_3): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_4): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_6): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (confidence_layers): ModuleDict(\n",
            "      (conv_conf_1): Conv2d(512, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_2): Conv2d(1024, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_3): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_4): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_6): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO:root:Optimizer Info:\n",
            "Optimizer: SGD\n",
            "learning rate: 0.001, Momentum: 0.9, Weight decay: 0.0005\n",
            "\n",
            "INFO:root:Multi Step Info:\n",
            "milestones: [40000, 50000]\n",
            "gamma: 0.1\n",
            "\n",
            "INFO:root:Save Info:\n",
            "filename: SSD300\n",
            "checkpoints interval: 5000\n",
            "\n",
            "INFO:root:Start Training\n",
            "\n",
            "\n",
            "Training... Epoch: 1, Iter: 1,\t [32/82081\t (0%)]\tLoss: 30.715584, Loc Loss: 4.178468, Conf Loss: 26.537117\tIter time: 0.3842\n",
            "Training... Epoch: 1, Iter: 10,\t [320/82081\t (0%)]\tLoss: 21.906908, Loc Loss: 3.817635, Conf Loss: 18.089273\tIter time: 0.2872\n",
            "Training... Epoch: 1, Iter: 20,\t [640/82081\t (1%)]\tLoss: 21.476568, Loc Loss: 3.737593, Conf Loss: 17.738976\tIter time: 0.2633\n",
            "Training... Epoch: 1, Iter: 30,\t [960/82081\t (1%)]\tLoss: 19.106182, Loc Loss: 3.550724, Conf Loss: 15.555458\tIter time: 0.2450\n",
            "Training... Epoch: 1, Iter: 40,\t [1280/82081\t (2%)]\tLoss: 13.904200, Loc Loss: 3.560940, Conf Loss: 10.343259\tIter time: 0.2500\n",
            "Training... Epoch: 1, Iter: 50,\t [1600/82081\t (2%)]\tLoss: 13.184085, Loc Loss: 3.102701, Conf Loss: 10.081384\tIter time: 0.2717\n",
            "Training... Epoch: 1, Iter: 60,\t [1920/82081\t (2%)]\tLoss: 12.590491, Loc Loss: 3.504342, Conf Loss: 9.086149\tIter time: 0.2602\n",
            "Training... Epoch: 1, Iter: 70,\t [2240/82081\t (3%)]\tLoss: 11.876377, Loc Loss: 3.462337, Conf Loss: 8.414040\tIter time: 0.2739\n",
            "Training... Epoch: 1, Iter: 80,\t [2560/82081\t (3%)]\tLoss: 10.282356, Loc Loss: 3.138900, Conf Loss: 7.143456\tIter time: 0.2680\n",
            "Training... Epoch: 1, Iter: 90,\t [2880/82081\t (4%)]\tLoss: 11.081873, Loc Loss: 3.004694, Conf Loss: 8.077179\tIter time: 0.2617\n",
            "Training... Epoch: 1, Iter: 100,\t [3200/82081\t (4%)]\tLoss: 9.833581, Loc Loss: 3.022928, Conf Loss: 6.810654\tIter time: 0.2812\n",
            "Training... Epoch: 1, Iter: 110,\t [3520/82081\t (4%)]\tLoss: 10.589522, Loc Loss: 2.851757, Conf Loss: 7.737766\tIter time: 0.2667\n",
            "Training... Epoch: 1, Iter: 120,\t [3840/82081\t (5%)]\tLoss: 10.408053, Loc Loss: 3.335895, Conf Loss: 7.072159\tIter time: 0.2695\n",
            "Training... Epoch: 1, Iter: 130,\t [4160/82081\t (5%)]\tLoss: 10.382819, Loc Loss: 3.121518, Conf Loss: 7.261302\tIter time: 0.2688\n",
            "Training... Epoch: 1, Iter: 140,\t [4480/82081\t (5%)]\tLoss: 9.436680, Loc Loss: 2.994559, Conf Loss: 6.442121\tIter time: 0.2630\n",
            "Training... Epoch: 1, Iter: 150,\t [4800/82081\t (6%)]\tLoss: 9.438719, Loc Loss: 2.858993, Conf Loss: 6.579725\tIter time: 0.2634\n",
            "Training... Epoch: 1, Iter: 160,\t [5120/82081\t (6%)]\tLoss: 10.770741, Loc Loss: 3.462353, Conf Loss: 7.308389\tIter time: 0.2637\n",
            "Training... Epoch: 1, Iter: 170,\t [5440/82081\t (7%)]\tLoss: 10.195226, Loc Loss: 2.740978, Conf Loss: 7.454247\tIter time: 0.2605\n",
            "Training... Epoch: 1, Iter: 180,\t [5760/82081\t (7%)]\tLoss: 9.963182, Loc Loss: 2.981524, Conf Loss: 6.981658\tIter time: 0.2466\n",
            "Training... Epoch: 1, Iter: 190,\t [6080/82081\t (7%)]\tLoss: 9.319385, Loc Loss: 2.725777, Conf Loss: 6.593608\tIter time: 0.2469\n",
            "Training... Epoch: 1, Iter: 200,\t [6400/82081\t (8%)]\tLoss: 9.647552, Loc Loss: 2.924625, Conf Loss: 6.722928\tIter time: 0.2635\n",
            "Training... Epoch: 1, Iter: 210,\t [6720/82081\t (8%)]\tLoss: 10.021852, Loc Loss: 3.101665, Conf Loss: 6.920187\tIter time: 0.2642\n",
            "Training... Epoch: 1, Iter: 220,\t [7040/82081\t (9%)]\tLoss: 9.806351, Loc Loss: 2.777401, Conf Loss: 7.028949\tIter time: 0.2426\n",
            "Training... Epoch: 1, Iter: 230,\t [7360/82081\t (9%)]\tLoss: 9.528156, Loc Loss: 2.743427, Conf Loss: 6.784729\tIter time: 0.2556\n",
            "Training... Epoch: 1, Iter: 240,\t [7680/82081\t (9%)]\tLoss: 9.143013, Loc Loss: 3.035997, Conf Loss: 6.107017\tIter time: 0.2660\n",
            "Training... Epoch: 1, Iter: 250,\t [8000/82081\t (10%)]\tLoss: 9.505201, Loc Loss: 2.878555, Conf Loss: 6.626647\tIter time: 0.2873\n",
            "Training... Epoch: 1, Iter: 260,\t [8320/82081\t (10%)]\tLoss: 8.791991, Loc Loss: 2.661151, Conf Loss: 6.130840\tIter time: 0.2683\n",
            "Training... Epoch: 1, Iter: 270,\t [8640/82081\t (11%)]\tLoss: 8.970937, Loc Loss: 2.917171, Conf Loss: 6.053766\tIter time: 0.2611\n",
            "Training... Epoch: 1, Iter: 280,\t [8960/82081\t (11%)]\tLoss: 9.108736, Loc Loss: 2.681815, Conf Loss: 6.426920\tIter time: 0.2586\n",
            "Training... Epoch: 1, Iter: 290,\t [9280/82081\t (11%)]\tLoss: 8.883038, Loc Loss: 2.738933, Conf Loss: 6.144104\tIter time: 0.2664\n",
            "Training... Epoch: 1, Iter: 300,\t [9600/82081\t (12%)]\tLoss: 8.918005, Loc Loss: 2.706207, Conf Loss: 6.211798\tIter time: 0.2659\n",
            "Training... Epoch: 1, Iter: 310,\t [9920/82081\t (12%)]\tLoss: 8.586923, Loc Loss: 2.678225, Conf Loss: 5.908698\tIter time: 0.2640\n",
            "Training... Epoch: 1, Iter: 320,\t [10240/82081\t (12%)]\tLoss: 9.225358, Loc Loss: 2.748004, Conf Loss: 6.477355\tIter time: 0.2739\n",
            "Training... Epoch: 1, Iter: 330,\t [10560/82081\t (13%)]\tLoss: 8.572008, Loc Loss: 2.713616, Conf Loss: 5.858392\tIter time: 0.2672\n",
            "Training... Epoch: 1, Iter: 340,\t [10880/82081\t (13%)]\tLoss: 9.195211, Loc Loss: 2.643908, Conf Loss: 6.551304\tIter time: 0.2596\n",
            "Training... Epoch: 1, Iter: 350,\t [11200/82081\t (14%)]\tLoss: 8.253865, Loc Loss: 2.568837, Conf Loss: 5.685028\tIter time: 0.2701\n",
            "Training... Epoch: 1, Iter: 360,\t [11520/82081\t (14%)]\tLoss: 8.846357, Loc Loss: 2.718664, Conf Loss: 6.127693\tIter time: 0.2805\n",
            "Training... Epoch: 1, Iter: 370,\t [11840/82081\t (14%)]\tLoss: 9.108987, Loc Loss: 2.695234, Conf Loss: 6.413753\tIter time: 0.2729\n",
            "Training... Epoch: 1, Iter: 380,\t [12160/82081\t (15%)]\tLoss: 9.536092, Loc Loss: 2.659096, Conf Loss: 6.876996\tIter time: 0.2692\n",
            "Training... Epoch: 1, Iter: 390,\t [12480/82081\t (15%)]\tLoss: 8.982136, Loc Loss: 2.609098, Conf Loss: 6.373038\tIter time: 0.2744\n",
            "Training... Epoch: 1, Iter: 400,\t [12800/82081\t (16%)]\tLoss: 8.902341, Loc Loss: 2.613021, Conf Loss: 6.289320\tIter time: 0.2859\n",
            "Training... Epoch: 1, Iter: 410,\t [13120/82081\t (16%)]\tLoss: 8.655451, Loc Loss: 2.709078, Conf Loss: 5.946373\tIter time: 0.2661\n",
            "Training... Epoch: 1, Iter: 420,\t [13440/82081\t (16%)]\tLoss: 8.805909, Loc Loss: 2.766847, Conf Loss: 6.039062\tIter time: 0.2617\n",
            "Training... Epoch: 1, Iter: 430,\t [13760/82081\t (17%)]\tLoss: 8.421435, Loc Loss: 2.679908, Conf Loss: 5.741528\tIter time: 0.2470\n",
            "Training... Epoch: 1, Iter: 440,\t [14080/82081\t (17%)]\tLoss: 8.941012, Loc Loss: 2.768248, Conf Loss: 6.172764\tIter time: 0.2920\n",
            "Training... Epoch: 1, Iter: 450,\t [14400/82081\t (18%)]\tLoss: 8.480262, Loc Loss: 2.810307, Conf Loss: 5.669955\tIter time: 0.2889\n",
            "Training... Epoch: 1, Iter: 460,\t [14720/82081\t (18%)]\tLoss: 8.638305, Loc Loss: 2.584263, Conf Loss: 6.054041\tIter time: 0.2585\n",
            "Training... Epoch: 1, Iter: 470,\t [15040/82081\t (18%)]\tLoss: 8.039227, Loc Loss: 2.689026, Conf Loss: 5.350201\tIter time: 0.2490\n",
            "Training... Epoch: 1, Iter: 480,\t [15360/82081\t (19%)]\tLoss: 8.784973, Loc Loss: 2.961005, Conf Loss: 5.823969\tIter time: 0.2674\n",
            "Training... Epoch: 1, Iter: 490,\t [15680/82081\t (19%)]\tLoss: 8.703110, Loc Loss: 2.507812, Conf Loss: 6.195297\tIter time: 0.2748\n",
            "Training... Epoch: 1, Iter: 500,\t [16000/82081\t (19%)]\tLoss: 8.307846, Loc Loss: 2.565185, Conf Loss: 5.742661\tIter time: 0.2885\n",
            "Training... Epoch: 1, Iter: 510,\t [16320/82081\t (20%)]\tLoss: 8.605583, Loc Loss: 2.427673, Conf Loss: 6.177910\tIter time: 0.2578\n",
            "Training... Epoch: 1, Iter: 520,\t [16640/82081\t (20%)]\tLoss: 8.709131, Loc Loss: 2.728995, Conf Loss: 5.980137\tIter time: 0.2919\n",
            "Training... Epoch: 1, Iter: 530,\t [16960/82081\t (21%)]\tLoss: 8.210062, Loc Loss: 2.679100, Conf Loss: 5.530962\tIter time: 0.2561\n",
            "Training... Epoch: 1, Iter: 540,\t [17280/82081\t (21%)]\tLoss: 8.999072, Loc Loss: 2.772631, Conf Loss: 6.226441\tIter time: 0.2709\n",
            "Training... Epoch: 1, Iter: 550,\t [17600/82081\t (21%)]\tLoss: 8.646159, Loc Loss: 2.640540, Conf Loss: 6.005620\tIter time: 0.2642\n",
            "Training... Epoch: 1, Iter: 560,\t [17920/82081\t (22%)]\tLoss: 8.390093, Loc Loss: 2.294130, Conf Loss: 6.095963\tIter time: 0.2406\n",
            "Training... Epoch: 1, Iter: 570,\t [18240/82081\t (22%)]\tLoss: 8.127220, Loc Loss: 2.481865, Conf Loss: 5.645355\tIter time: 0.2608\n",
            "Training... Epoch: 1, Iter: 580,\t [18560/82081\t (23%)]\tLoss: 8.244202, Loc Loss: 2.483807, Conf Loss: 5.760395\tIter time: 0.2634\n",
            "Training... Epoch: 1, Iter: 590,\t [18880/82081\t (23%)]\tLoss: 8.853857, Loc Loss: 2.497425, Conf Loss: 6.356432\tIter time: 0.2836\n",
            "Training... Epoch: 1, Iter: 600,\t [19200/82081\t (23%)]\tLoss: 8.700645, Loc Loss: 2.606126, Conf Loss: 6.094519\tIter time: 0.2660\n",
            "Training... Epoch: 1, Iter: 610,\t [19520/82081\t (24%)]\tLoss: 8.298619, Loc Loss: 2.429114, Conf Loss: 5.869505\tIter time: 0.2716\n",
            "Training... Epoch: 1, Iter: 620,\t [19840/82081\t (24%)]\tLoss: 8.404053, Loc Loss: 2.749877, Conf Loss: 5.654176\tIter time: 0.2978\n",
            "Training... Epoch: 1, Iter: 630,\t [20160/82081\t (25%)]\tLoss: 8.356595, Loc Loss: 2.638574, Conf Loss: 5.718020\tIter time: 0.2902\n",
            "Training... Epoch: 1, Iter: 640,\t [20480/82081\t (25%)]\tLoss: 9.194309, Loc Loss: 2.716601, Conf Loss: 6.477708\tIter time: 0.2479\n",
            "Training... Epoch: 1, Iter: 650,\t [20800/82081\t (25%)]\tLoss: 7.848893, Loc Loss: 2.370817, Conf Loss: 5.478076\tIter time: 0.2495\n",
            "Training... Epoch: 1, Iter: 660,\t [21120/82081\t (26%)]\tLoss: 8.104300, Loc Loss: 2.365593, Conf Loss: 5.738707\tIter time: 0.2686\n",
            "Training... Epoch: 1, Iter: 670,\t [21440/82081\t (26%)]\tLoss: 8.352563, Loc Loss: 2.534150, Conf Loss: 5.818413\tIter time: 0.2663\n",
            "Training... Epoch: 1, Iter: 680,\t [21760/82081\t (27%)]\tLoss: 8.090597, Loc Loss: 2.346199, Conf Loss: 5.744398\tIter time: 0.2716\n",
            "Training... Epoch: 1, Iter: 690,\t [22080/82081\t (27%)]\tLoss: 8.529781, Loc Loss: 2.398348, Conf Loss: 6.131433\tIter time: 0.2592\n",
            "Training... Epoch: 1, Iter: 700,\t [22400/82081\t (27%)]\tLoss: 8.467165, Loc Loss: 2.404607, Conf Loss: 6.062558\tIter time: 0.2748\n",
            "Training... Epoch: 1, Iter: 710,\t [22720/82081\t (28%)]\tLoss: 8.610831, Loc Loss: 2.788015, Conf Loss: 5.822816\tIter time: 0.2690\n",
            "Training... Epoch: 1, Iter: 720,\t [23040/82081\t (28%)]\tLoss: 8.280692, Loc Loss: 2.444850, Conf Loss: 5.835842\tIter time: 0.2693\n",
            "Training... Epoch: 1, Iter: 730,\t [23360/82081\t (28%)]\tLoss: 9.262210, Loc Loss: 2.922355, Conf Loss: 6.339855\tIter time: 0.2752\n",
            "Training... Epoch: 1, Iter: 740,\t [23680/82081\t (29%)]\tLoss: 8.110533, Loc Loss: 2.500525, Conf Loss: 5.610007\tIter time: 0.2646\n",
            "Training... Epoch: 1, Iter: 750,\t [24000/82081\t (29%)]\tLoss: 7.941971, Loc Loss: 2.364236, Conf Loss: 5.577735\tIter time: 0.2901\n",
            "Training... Epoch: 1, Iter: 760,\t [24320/82081\t (30%)]\tLoss: 8.438221, Loc Loss: 2.288078, Conf Loss: 6.150144\tIter time: 0.2675\n",
            "Training... Epoch: 1, Iter: 770,\t [24640/82081\t (30%)]\tLoss: 8.099190, Loc Loss: 2.188421, Conf Loss: 5.910768\tIter time: 0.2454\n",
            "Training... Epoch: 1, Iter: 780,\t [24960/82081\t (30%)]\tLoss: 8.324387, Loc Loss: 2.392830, Conf Loss: 5.931557\tIter time: 0.2868\n",
            "Training... Epoch: 1, Iter: 790,\t [25280/82081\t (31%)]\tLoss: 8.327336, Loc Loss: 2.617735, Conf Loss: 5.709601\tIter time: 0.2826\n",
            "Training... Epoch: 1, Iter: 800,\t [25600/82081\t (31%)]\tLoss: 7.914273, Loc Loss: 2.571794, Conf Loss: 5.342479\tIter time: 0.2455\n",
            "Training... Epoch: 1, Iter: 810,\t [25920/82081\t (32%)]\tLoss: 8.255616, Loc Loss: 2.488552, Conf Loss: 5.767064\tIter time: 0.2672\n",
            "Training... Epoch: 1, Iter: 820,\t [26240/82081\t (32%)]\tLoss: 8.251307, Loc Loss: 2.309562, Conf Loss: 5.941744\tIter time: 0.2763\n",
            "Training... Epoch: 1, Iter: 830,\t [26560/82081\t (32%)]\tLoss: 9.085291, Loc Loss: 3.158687, Conf Loss: 5.926603\tIter time: 0.2626\n",
            "Training... Epoch: 1, Iter: 840,\t [26880/82081\t (33%)]\tLoss: 8.368523, Loc Loss: 2.425643, Conf Loss: 5.942880\tIter time: 0.2607\n",
            "Training... Epoch: 1, Iter: 850,\t [27200/82081\t (33%)]\tLoss: 8.388683, Loc Loss: 2.649510, Conf Loss: 5.739173\tIter time: 0.2630\n",
            "Training... Epoch: 1, Iter: 860,\t [27520/82081\t (34%)]\tLoss: 7.695740, Loc Loss: 2.472705, Conf Loss: 5.223035\tIter time: 0.2493\n",
            "Training... Epoch: 1, Iter: 870,\t [27840/82081\t (34%)]\tLoss: 8.232948, Loc Loss: 2.592631, Conf Loss: 5.640317\tIter time: 0.2644\n",
            "Training... Epoch: 1, Iter: 880,\t [28160/82081\t (34%)]\tLoss: 8.347991, Loc Loss: 2.118566, Conf Loss: 6.229425\tIter time: 0.2750\n",
            "Training... Epoch: 1, Iter: 890,\t [28480/82081\t (35%)]\tLoss: 7.841174, Loc Loss: 2.230136, Conf Loss: 5.611038\tIter time: 0.2519\n",
            "Training... Epoch: 1, Iter: 900,\t [28800/82081\t (35%)]\tLoss: 7.845819, Loc Loss: 2.494534, Conf Loss: 5.351286\tIter time: 0.2572\n",
            "Training... Epoch: 1, Iter: 910,\t [29120/82081\t (35%)]\tLoss: 8.195845, Loc Loss: 2.282918, Conf Loss: 5.912927\tIter time: 0.2656\n",
            "Training... Epoch: 1, Iter: 920,\t [29440/82081\t (36%)]\tLoss: 7.768067, Loc Loss: 2.693027, Conf Loss: 5.075040\tIter time: 0.2691\n",
            "Training... Epoch: 1, Iter: 930,\t [29760/82081\t (36%)]\tLoss: 7.848844, Loc Loss: 2.210522, Conf Loss: 5.638322\tIter time: 0.2607\n",
            "Training... Epoch: 1, Iter: 940,\t [30080/82081\t (37%)]\tLoss: 7.423708, Loc Loss: 2.074689, Conf Loss: 5.349019\tIter time: 0.2498\n",
            "Training... Epoch: 1, Iter: 950,\t [30400/82081\t (37%)]\tLoss: 8.233074, Loc Loss: 2.571105, Conf Loss: 5.661969\tIter time: 0.2648\n",
            "Training... Epoch: 1, Iter: 960,\t [30720/82081\t (37%)]\tLoss: 8.083406, Loc Loss: 2.328470, Conf Loss: 5.754936\tIter time: 0.2596\n",
            "Training... Epoch: 1, Iter: 970,\t [31040/82081\t (38%)]\tLoss: 7.380045, Loc Loss: 2.332035, Conf Loss: 5.048009\tIter time: 0.2645\n",
            "Training... Epoch: 1, Iter: 980,\t [31360/82081\t (38%)]\tLoss: 7.913132, Loc Loss: 2.477167, Conf Loss: 5.435964\tIter time: 0.2702\n",
            "Training... Epoch: 1, Iter: 990,\t [31680/82081\t (39%)]\tLoss: 8.424817, Loc Loss: 2.335228, Conf Loss: 6.089590\tIter time: 0.2555\n",
            "Training... Epoch: 1, Iter: 1000,\t [32000/82081\t (39%)]\tLoss: 8.257579, Loc Loss: 2.517449, Conf Loss: 5.740129\tIter time: 0.2459\n",
            "Training... Epoch: 1, Iter: 1010,\t [32320/82081\t (39%)]\tLoss: 8.190026, Loc Loss: 2.324152, Conf Loss: 5.865875\tIter time: 0.2920\n",
            "Training... Epoch: 1, Iter: 1020,\t [32640/82081\t (40%)]\tLoss: 7.707095, Loc Loss: 2.628394, Conf Loss: 5.078701\tIter time: 0.2765\n",
            "Training... Epoch: 1, Iter: 1030,\t [32960/82081\t (40%)]\tLoss: 7.603293, Loc Loss: 2.236343, Conf Loss: 5.366950\tIter time: 0.2694\n",
            "Training... Epoch: 1, Iter: 1040,\t [33280/82081\t (41%)]\tLoss: 7.703848, Loc Loss: 2.189811, Conf Loss: 5.514037\tIter time: 0.2431\n",
            "Training... Epoch: 1, Iter: 1050,\t [33600/82081\t (41%)]\tLoss: 7.868877, Loc Loss: 2.229123, Conf Loss: 5.639754\tIter time: 0.2719\n",
            "Training... Epoch: 1, Iter: 1060,\t [33920/82081\t (41%)]\tLoss: 7.645885, Loc Loss: 2.368096, Conf Loss: 5.277790\tIter time: 0.2766\n",
            "Training... Epoch: 1, Iter: 1070,\t [34240/82081\t (42%)]\tLoss: 8.101500, Loc Loss: 2.649759, Conf Loss: 5.451740\tIter time: 0.2747\n",
            "Training... Epoch: 1, Iter: 1080,\t [34560/82081\t (42%)]\tLoss: 8.165334, Loc Loss: 2.342724, Conf Loss: 5.822610\tIter time: 0.2549\n",
            "Training... Epoch: 1, Iter: 1090,\t [34880/82081\t (42%)]\tLoss: 7.932951, Loc Loss: 2.358181, Conf Loss: 5.574770\tIter time: 0.2673\n",
            "Training... Epoch: 1, Iter: 1100,\t [35200/82081\t (43%)]\tLoss: 7.628448, Loc Loss: 2.263639, Conf Loss: 5.364809\tIter time: 0.2694\n",
            "Training... Epoch: 1, Iter: 1110,\t [35520/82081\t (43%)]\tLoss: 8.485717, Loc Loss: 2.534289, Conf Loss: 5.951428\tIter time: 0.2614\n",
            "Training... Epoch: 1, Iter: 1120,\t [35840/82081\t (44%)]\tLoss: 7.718596, Loc Loss: 2.165072, Conf Loss: 5.553524\tIter time: 0.2699\n",
            "Training... Epoch: 1, Iter: 1130,\t [36160/82081\t (44%)]\tLoss: 8.376335, Loc Loss: 2.382573, Conf Loss: 5.993762\tIter time: 0.2754\n",
            "Training... Epoch: 1, Iter: 1140,\t [36480/82081\t (44%)]\tLoss: 8.324568, Loc Loss: 2.446383, Conf Loss: 5.878185\tIter time: 0.2636\n",
            "Training... Epoch: 1, Iter: 1150,\t [36800/82081\t (45%)]\tLoss: 7.830089, Loc Loss: 2.424765, Conf Loss: 5.405324\tIter time: 0.2767\n",
            "Training... Epoch: 1, Iter: 1160,\t [37120/82081\t (45%)]\tLoss: 7.851814, Loc Loss: 2.305867, Conf Loss: 5.545947\tIter time: 0.2634\n",
            "Training... Epoch: 1, Iter: 1170,\t [37440/82081\t (46%)]\tLoss: 8.043689, Loc Loss: 2.317447, Conf Loss: 5.726241\tIter time: 0.2796\n",
            "Training... Epoch: 1, Iter: 1180,\t [37760/82081\t (46%)]\tLoss: 8.144127, Loc Loss: 2.503555, Conf Loss: 5.640573\tIter time: 0.2417\n",
            "Training... Epoch: 1, Iter: 1190,\t [38080/82081\t (46%)]\tLoss: 7.920752, Loc Loss: 2.212328, Conf Loss: 5.708424\tIter time: 0.2410\n",
            "Training... Epoch: 1, Iter: 1200,\t [38400/82081\t (47%)]\tLoss: 7.953997, Loc Loss: 2.295800, Conf Loss: 5.658197\tIter time: 0.2658\n",
            "Training... Epoch: 1, Iter: 1210,\t [38720/82081\t (47%)]\tLoss: 8.389817, Loc Loss: 2.298578, Conf Loss: 6.091239\tIter time: 0.2738\n",
            "Training... Epoch: 1, Iter: 1220,\t [39040/82081\t (48%)]\tLoss: 8.179780, Loc Loss: 2.298502, Conf Loss: 5.881278\tIter time: 0.2431\n",
            "Training... Epoch: 1, Iter: 1230,\t [39360/82081\t (48%)]\tLoss: 8.195591, Loc Loss: 2.288459, Conf Loss: 5.907132\tIter time: 0.2735\n",
            "Training... Epoch: 1, Iter: 1240,\t [39680/82081\t (48%)]\tLoss: 7.706322, Loc Loss: 2.259504, Conf Loss: 5.446817\tIter time: 0.2843\n",
            "Training... Epoch: 1, Iter: 1250,\t [40000/82081\t (49%)]\tLoss: 7.713566, Loc Loss: 2.490668, Conf Loss: 5.222898\tIter time: 0.2667\n",
            "Training... Epoch: 1, Iter: 1260,\t [40320/82081\t (49%)]\tLoss: 8.077286, Loc Loss: 2.329984, Conf Loss: 5.747302\tIter time: 0.2734\n",
            "Training... Epoch: 1, Iter: 1270,\t [40640/82081\t (49%)]\tLoss: 7.761449, Loc Loss: 2.082528, Conf Loss: 5.678921\tIter time: 0.2614\n",
            "Training... Epoch: 1, Iter: 1280,\t [40960/82081\t (50%)]\tLoss: 7.803940, Loc Loss: 2.209272, Conf Loss: 5.594668\tIter time: 0.2742\n",
            "Training... Epoch: 1, Iter: 1290,\t [41280/82081\t (50%)]\tLoss: 8.143207, Loc Loss: 2.443279, Conf Loss: 5.699928\tIter time: 0.2607\n",
            "Training... Epoch: 1, Iter: 1300,\t [41600/82081\t (51%)]\tLoss: 8.154474, Loc Loss: 2.242911, Conf Loss: 5.911563\tIter time: 0.2478\n",
            "Training... Epoch: 1, Iter: 1310,\t [41920/82081\t (51%)]\tLoss: 7.637986, Loc Loss: 2.205040, Conf Loss: 5.432946\tIter time: 0.2479\n",
            "Training... Epoch: 1, Iter: 1320,\t [42240/82081\t (51%)]\tLoss: 8.516685, Loc Loss: 2.685140, Conf Loss: 5.831545\tIter time: 0.2449\n",
            "Training... Epoch: 1, Iter: 1330,\t [42560/82081\t (52%)]\tLoss: 8.297758, Loc Loss: 2.329282, Conf Loss: 5.968476\tIter time: 0.2594\n",
            "Training... Epoch: 1, Iter: 1340,\t [42880/82081\t (52%)]\tLoss: 7.436347, Loc Loss: 2.139806, Conf Loss: 5.296541\tIter time: 0.2757\n",
            "Training... Epoch: 1, Iter: 1350,\t [43200/82081\t (53%)]\tLoss: 8.183195, Loc Loss: 2.395577, Conf Loss: 5.787618\tIter time: 0.2677\n",
            "Training... Epoch: 1, Iter: 1360,\t [43520/82081\t (53%)]\tLoss: 7.461234, Loc Loss: 2.175301, Conf Loss: 5.285933\tIter time: 0.2431\n",
            "Training... Epoch: 1, Iter: 1370,\t [43840/82081\t (53%)]\tLoss: 8.100002, Loc Loss: 2.377887, Conf Loss: 5.722115\tIter time: 0.2609\n",
            "Training... Epoch: 1, Iter: 1380,\t [44160/82081\t (54%)]\tLoss: 7.954526, Loc Loss: 2.324176, Conf Loss: 5.630350\tIter time: 0.2479\n",
            "Training... Epoch: 1, Iter: 1390,\t [44480/82081\t (54%)]\tLoss: 8.194919, Loc Loss: 2.196833, Conf Loss: 5.998085\tIter time: 0.2736\n",
            "Training... Epoch: 1, Iter: 1400,\t [44800/82081\t (55%)]\tLoss: 7.386526, Loc Loss: 1.953383, Conf Loss: 5.433143\tIter time: 0.2674\n",
            "Training... Epoch: 1, Iter: 1410,\t [45120/82081\t (55%)]\tLoss: 8.154647, Loc Loss: 2.447318, Conf Loss: 5.707329\tIter time: 0.2685\n",
            "Training... Epoch: 1, Iter: 1420,\t [45440/82081\t (55%)]\tLoss: 7.418610, Loc Loss: 2.283422, Conf Loss: 5.135187\tIter time: 0.2811\n",
            "Training... Epoch: 1, Iter: 1430,\t [45760/82081\t (56%)]\tLoss: 7.703918, Loc Loss: 1.975332, Conf Loss: 5.728586\tIter time: 0.2705\n",
            "Training... Epoch: 1, Iter: 1440,\t [46080/82081\t (56%)]\tLoss: 7.516151, Loc Loss: 2.312663, Conf Loss: 5.203488\tIter time: 0.2648\n",
            "Training... Epoch: 1, Iter: 1450,\t [46400/82081\t (57%)]\tLoss: 7.723504, Loc Loss: 2.225638, Conf Loss: 5.497867\tIter time: 0.2714\n",
            "Training... Epoch: 1, Iter: 1460,\t [46720/82081\t (57%)]\tLoss: 7.508786, Loc Loss: 2.085280, Conf Loss: 5.423506\tIter time: 0.2762\n",
            "Training... Epoch: 1, Iter: 1470,\t [47040/82081\t (57%)]\tLoss: 7.756394, Loc Loss: 2.199164, Conf Loss: 5.557231\tIter time: 0.2849\n",
            "Training... Epoch: 1, Iter: 1480,\t [47360/82081\t (58%)]\tLoss: 8.214340, Loc Loss: 2.188710, Conf Loss: 6.025630\tIter time: 0.2667\n",
            "Training... Epoch: 1, Iter: 1490,\t [47680/82081\t (58%)]\tLoss: 7.594954, Loc Loss: 2.051334, Conf Loss: 5.543620\tIter time: 0.2641\n",
            "Training... Epoch: 1, Iter: 1500,\t [48000/82081\t (58%)]\tLoss: 7.822785, Loc Loss: 2.434418, Conf Loss: 5.388367\tIter time: 0.2705\n",
            "Training... Epoch: 1, Iter: 1510,\t [48320/82081\t (59%)]\tLoss: 7.660000, Loc Loss: 2.379018, Conf Loss: 5.280982\tIter time: 0.2791\n",
            "Training... Epoch: 1, Iter: 1520,\t [48640/82081\t (59%)]\tLoss: 7.383224, Loc Loss: 2.258891, Conf Loss: 5.124333\tIter time: 0.2602\n",
            "Training... Epoch: 1, Iter: 1530,\t [48960/82081\t (60%)]\tLoss: 7.493391, Loc Loss: 2.190141, Conf Loss: 5.303250\tIter time: 0.2556\n",
            "Training... Epoch: 1, Iter: 1540,\t [49280/82081\t (60%)]\tLoss: 7.874010, Loc Loss: 2.046865, Conf Loss: 5.827145\tIter time: 0.2638\n",
            "Training... Epoch: 1, Iter: 1550,\t [49600/82081\t (60%)]\tLoss: 7.847793, Loc Loss: 2.253707, Conf Loss: 5.594086\tIter time: 0.2500\n",
            "Training... Epoch: 1, Iter: 1560,\t [49920/82081\t (61%)]\tLoss: 7.701726, Loc Loss: 2.289170, Conf Loss: 5.412557\tIter time: 0.2608\n",
            "Training... Epoch: 1, Iter: 1570,\t [50240/82081\t (61%)]\tLoss: 7.640352, Loc Loss: 2.107102, Conf Loss: 5.533250\tIter time: 0.2529\n",
            "Training... Epoch: 1, Iter: 1580,\t [50560/82081\t (62%)]\tLoss: 7.767039, Loc Loss: 2.233351, Conf Loss: 5.533688\tIter time: 0.2616\n",
            "Training... Epoch: 1, Iter: 1590,\t [50880/82081\t (62%)]\tLoss: 7.641111, Loc Loss: 2.053773, Conf Loss: 5.587338\tIter time: 0.2733\n",
            "Training... Epoch: 1, Iter: 1600,\t [51200/82081\t (62%)]\tLoss: 7.714163, Loc Loss: 2.302407, Conf Loss: 5.411756\tIter time: 0.2638\n",
            "Training... Epoch: 1, Iter: 1610,\t [51520/82081\t (63%)]\tLoss: 7.940985, Loc Loss: 1.996611, Conf Loss: 5.944374\tIter time: 0.2456\n",
            "Training... Epoch: 1, Iter: 1620,\t [51840/82081\t (63%)]\tLoss: 7.410515, Loc Loss: 2.061988, Conf Loss: 5.348527\tIter time: 0.2648\n",
            "Training... Epoch: 1, Iter: 1630,\t [52160/82081\t (64%)]\tLoss: 7.815392, Loc Loss: 2.188728, Conf Loss: 5.626665\tIter time: 0.2546\n",
            "Training... Epoch: 1, Iter: 1640,\t [52480/82081\t (64%)]\tLoss: 7.632665, Loc Loss: 2.198729, Conf Loss: 5.433936\tIter time: 0.2678\n",
            "Training... Epoch: 1, Iter: 1650,\t [52800/82081\t (64%)]\tLoss: 7.759389, Loc Loss: 2.326581, Conf Loss: 5.432807\tIter time: 0.2819\n",
            "Training... Epoch: 1, Iter: 1660,\t [53120/82081\t (65%)]\tLoss: 7.962902, Loc Loss: 2.084749, Conf Loss: 5.878153\tIter time: 0.2618\n",
            "Training... Epoch: 1, Iter: 1670,\t [53440/82081\t (65%)]\tLoss: 7.550449, Loc Loss: 2.197123, Conf Loss: 5.353326\tIter time: 0.2694\n",
            "Training... Epoch: 1, Iter: 1680,\t [53760/82081\t (65%)]\tLoss: 8.094011, Loc Loss: 2.241880, Conf Loss: 5.852131\tIter time: 0.2662\n",
            "Training... Epoch: 1, Iter: 1690,\t [54080/82081\t (66%)]\tLoss: 7.160940, Loc Loss: 2.169043, Conf Loss: 4.991897\tIter time: 0.2650\n",
            "Training... Epoch: 1, Iter: 1700,\t [54400/82081\t (66%)]\tLoss: 7.469714, Loc Loss: 2.215127, Conf Loss: 5.254588\tIter time: 0.2771\n",
            "Training... Epoch: 1, Iter: 1710,\t [54720/82081\t (67%)]\tLoss: 8.133897, Loc Loss: 2.370756, Conf Loss: 5.763141\tIter time: 0.2697\n",
            "Training... Epoch: 1, Iter: 1720,\t [55040/82081\t (67%)]\tLoss: 7.505218, Loc Loss: 2.147706, Conf Loss: 5.357511\tIter time: 0.2699\n",
            "Training... Epoch: 1, Iter: 1730,\t [55360/82081\t (67%)]\tLoss: 7.723372, Loc Loss: 2.323919, Conf Loss: 5.399454\tIter time: 0.2691\n",
            "Training... Epoch: 1, Iter: 1740,\t [55680/82081\t (68%)]\tLoss: 7.634746, Loc Loss: 2.496551, Conf Loss: 5.138195\tIter time: 0.2607\n",
            "Training... Epoch: 1, Iter: 1750,\t [56000/82081\t (68%)]\tLoss: 7.269005, Loc Loss: 2.323266, Conf Loss: 4.945739\tIter time: 0.2675\n",
            "Training... Epoch: 1, Iter: 1760,\t [56320/82081\t (69%)]\tLoss: 8.685880, Loc Loss: 2.594564, Conf Loss: 6.091315\tIter time: 0.2436\n",
            "Training... Epoch: 1, Iter: 1770,\t [56640/82081\t (69%)]\tLoss: 7.840322, Loc Loss: 2.310757, Conf Loss: 5.529564\tIter time: 0.3249\n",
            "Training... Epoch: 1, Iter: 1780,\t [56960/82081\t (69%)]\tLoss: 7.753685, Loc Loss: 2.414679, Conf Loss: 5.339006\tIter time: 0.2587\n",
            "Training... Epoch: 1, Iter: 1790,\t [57280/82081\t (70%)]\tLoss: 7.347761, Loc Loss: 2.462910, Conf Loss: 4.884851\tIter time: 0.2671\n",
            "Training... Epoch: 1, Iter: 1800,\t [57600/82081\t (70%)]\tLoss: 7.311420, Loc Loss: 2.203176, Conf Loss: 5.108243\tIter time: 0.2692\n",
            "Training... Epoch: 1, Iter: 1810,\t [57920/82081\t (71%)]\tLoss: 7.625673, Loc Loss: 2.243000, Conf Loss: 5.382673\tIter time: 0.2536\n",
            "Training... Epoch: 1, Iter: 1820,\t [58240/82081\t (71%)]\tLoss: 7.433389, Loc Loss: 2.342357, Conf Loss: 5.091033\tIter time: 0.2633\n",
            "Training... Epoch: 1, Iter: 1830,\t [58560/82081\t (71%)]\tLoss: 7.561307, Loc Loss: 2.218204, Conf Loss: 5.343103\tIter time: 0.2635\n",
            "Training... Epoch: 1, Iter: 1840,\t [58880/82081\t (72%)]\tLoss: 7.361433, Loc Loss: 2.194369, Conf Loss: 5.167065\tIter time: 0.2462\n",
            "Training... Epoch: 1, Iter: 1850,\t [59200/82081\t (72%)]\tLoss: 7.881884, Loc Loss: 2.099363, Conf Loss: 5.782521\tIter time: 0.2492\n",
            "Training... Epoch: 1, Iter: 1860,\t [59520/82081\t (72%)]\tLoss: 7.233479, Loc Loss: 2.159666, Conf Loss: 5.073813\tIter time: 0.2668\n",
            "Training... Epoch: 1, Iter: 1870,\t [59840/82081\t (73%)]\tLoss: 7.086069, Loc Loss: 2.068604, Conf Loss: 5.017465\tIter time: 0.2911\n",
            "Training... Epoch: 1, Iter: 1880,\t [60160/82081\t (73%)]\tLoss: 7.725019, Loc Loss: 2.008785, Conf Loss: 5.716234\tIter time: 0.2473\n",
            "Training... Epoch: 1, Iter: 1890,\t [60480/82081\t (74%)]\tLoss: 7.655451, Loc Loss: 2.045101, Conf Loss: 5.610351\tIter time: 0.2973\n",
            "Training... Epoch: 1, Iter: 1900,\t [60800/82081\t (74%)]\tLoss: 7.990127, Loc Loss: 2.062818, Conf Loss: 5.927308\tIter time: 0.2717\n",
            "Training... Epoch: 1, Iter: 1910,\t [61120/82081\t (74%)]\tLoss: 7.499722, Loc Loss: 2.349021, Conf Loss: 5.150702\tIter time: 0.2659\n",
            "Training... Epoch: 1, Iter: 1920,\t [61440/82081\t (75%)]\tLoss: 7.724433, Loc Loss: 2.349612, Conf Loss: 5.374822\tIter time: 0.2585\n",
            "Training... Epoch: 1, Iter: 1930,\t [61760/82081\t (75%)]\tLoss: 7.372945, Loc Loss: 2.184356, Conf Loss: 5.188589\tIter time: 0.2490\n",
            "Training... Epoch: 1, Iter: 1940,\t [62080/82081\t (76%)]\tLoss: 7.317295, Loc Loss: 1.880125, Conf Loss: 5.437170\tIter time: 0.2648\n",
            "Training... Epoch: 1, Iter: 1950,\t [62400/82081\t (76%)]\tLoss: 7.742367, Loc Loss: 2.016296, Conf Loss: 5.726070\tIter time: 0.2660\n",
            "Training... Epoch: 1, Iter: 1960,\t [62720/82081\t (76%)]\tLoss: 7.487617, Loc Loss: 2.566591, Conf Loss: 4.921026\tIter time: 0.2465\n",
            "Training... Epoch: 1, Iter: 1970,\t [63040/82081\t (77%)]\tLoss: 8.319709, Loc Loss: 2.351087, Conf Loss: 5.968622\tIter time: 0.2700\n",
            "Training... Epoch: 1, Iter: 1980,\t [63360/82081\t (77%)]\tLoss: 7.288476, Loc Loss: 2.122495, Conf Loss: 5.165981\tIter time: 0.2716\n",
            "Training... Epoch: 1, Iter: 1990,\t [63680/82081\t (78%)]\tLoss: 7.695502, Loc Loss: 2.076828, Conf Loss: 5.618674\tIter time: 0.2533\n",
            "Training... Epoch: 1, Iter: 2000,\t [64000/82081\t (78%)]\tLoss: 7.697405, Loc Loss: 2.383516, Conf Loss: 5.313889\tIter time: 0.2595\n",
            "Training... Epoch: 1, Iter: 2010,\t [64320/82081\t (78%)]\tLoss: 7.894513, Loc Loss: 2.370330, Conf Loss: 5.524183\tIter time: 0.2560\n",
            "Training... Epoch: 1, Iter: 2020,\t [64640/82081\t (79%)]\tLoss: 7.347139, Loc Loss: 2.250945, Conf Loss: 5.096194\tIter time: 0.2599\n",
            "Training... Epoch: 1, Iter: 2030,\t [64960/82081\t (79%)]\tLoss: 7.146340, Loc Loss: 2.154495, Conf Loss: 4.991845\tIter time: 0.2617\n",
            "Training... Epoch: 1, Iter: 2040,\t [65280/82081\t (80%)]\tLoss: 7.477253, Loc Loss: 1.919076, Conf Loss: 5.558177\tIter time: 0.2422\n",
            "Training... Epoch: 1, Iter: 2050,\t [65600/82081\t (80%)]\tLoss: 7.795527, Loc Loss: 2.235771, Conf Loss: 5.559756\tIter time: 0.2526\n",
            "Training... Epoch: 1, Iter: 2060,\t [65920/82081\t (80%)]\tLoss: 7.518047, Loc Loss: 2.151403, Conf Loss: 5.366644\tIter time: 0.2695\n",
            "Training... Epoch: 1, Iter: 2070,\t [66240/82081\t (81%)]\tLoss: 7.869725, Loc Loss: 2.287118, Conf Loss: 5.582607\tIter time: 0.2546\n",
            "Training... Epoch: 1, Iter: 2080,\t [66560/82081\t (81%)]\tLoss: 7.453265, Loc Loss: 2.129224, Conf Loss: 5.324041\tIter time: 0.2681\n",
            "Training... Epoch: 1, Iter: 2090,\t [66880/82081\t (81%)]\tLoss: 6.957387, Loc Loss: 1.994877, Conf Loss: 4.962510\tIter time: 0.2487\n",
            "Training... Epoch: 1, Iter: 2100,\t [67200/82081\t (82%)]\tLoss: 6.921141, Loc Loss: 2.236681, Conf Loss: 4.684460\tIter time: 0.2570\n",
            "Training... Epoch: 1, Iter: 2110,\t [67520/82081\t (82%)]\tLoss: 7.815116, Loc Loss: 2.410856, Conf Loss: 5.404260\tIter time: 0.2730\n",
            "Training... Epoch: 1, Iter: 2120,\t [67840/82081\t (83%)]\tLoss: 7.376375, Loc Loss: 2.200984, Conf Loss: 5.175391\tIter time: 0.2487\n",
            "Training... Epoch: 1, Iter: 2130,\t [68160/82081\t (83%)]\tLoss: 7.513375, Loc Loss: 2.316412, Conf Loss: 5.196963\tIter time: 0.2686\n",
            "Training... Epoch: 1, Iter: 2140,\t [68480/82081\t (83%)]\tLoss: 8.061780, Loc Loss: 2.763469, Conf Loss: 5.298311\tIter time: 0.2694\n",
            "Training... Epoch: 1, Iter: 2150,\t [68800/82081\t (84%)]\tLoss: 7.765845, Loc Loss: 2.055114, Conf Loss: 5.710731\tIter time: 0.2786\n",
            "Training... Epoch: 1, Iter: 2160,\t [69120/82081\t (84%)]\tLoss: 7.230379, Loc Loss: 2.165241, Conf Loss: 5.065138\tIter time: 0.2700\n",
            "Training... Epoch: 1, Iter: 2170,\t [69440/82081\t (85%)]\tLoss: 7.210959, Loc Loss: 2.248238, Conf Loss: 4.962721\tIter time: 0.2618\n",
            "Training... Epoch: 1, Iter: 2180,\t [69760/82081\t (85%)]\tLoss: 7.287087, Loc Loss: 2.281572, Conf Loss: 5.005515\tIter time: 0.2719\n",
            "Training... Epoch: 1, Iter: 2190,\t [70080/82081\t (85%)]\tLoss: 7.470417, Loc Loss: 2.226000, Conf Loss: 5.244417\tIter time: 0.2633\n",
            "Training... Epoch: 1, Iter: 2200,\t [70400/82081\t (86%)]\tLoss: 7.498693, Loc Loss: 2.368760, Conf Loss: 5.129933\tIter time: 0.2574\n",
            "Training... Epoch: 1, Iter: 2210,\t [70720/82081\t (86%)]\tLoss: 7.203055, Loc Loss: 2.064892, Conf Loss: 5.138164\tIter time: 0.2599\n",
            "Training... Epoch: 1, Iter: 2220,\t [71040/82081\t (87%)]\tLoss: 7.058312, Loc Loss: 2.133950, Conf Loss: 4.924363\tIter time: 0.2629\n",
            "Training... Epoch: 1, Iter: 2230,\t [71360/82081\t (87%)]\tLoss: 7.724893, Loc Loss: 2.422676, Conf Loss: 5.302217\tIter time: 0.2654\n",
            "Training... Epoch: 1, Iter: 2240,\t [71680/82081\t (87%)]\tLoss: 7.359990, Loc Loss: 1.865409, Conf Loss: 5.494580\tIter time: 0.2594\n",
            "Training... Epoch: 1, Iter: 2250,\t [72000/82081\t (88%)]\tLoss: 7.773301, Loc Loss: 2.306578, Conf Loss: 5.466723\tIter time: 0.2624\n",
            "Training... Epoch: 1, Iter: 2260,\t [72320/82081\t (88%)]\tLoss: 7.308644, Loc Loss: 2.070664, Conf Loss: 5.237980\tIter time: 0.2579\n",
            "Training... Epoch: 1, Iter: 2270,\t [72640/82081\t (88%)]\tLoss: 7.540175, Loc Loss: 1.931546, Conf Loss: 5.608629\tIter time: 0.2560\n",
            "Training... Epoch: 1, Iter: 2280,\t [72960/82081\t (89%)]\tLoss: 7.571457, Loc Loss: 2.090686, Conf Loss: 5.480772\tIter time: 0.2775\n",
            "Training... Epoch: 1, Iter: 2290,\t [73280/82081\t (89%)]\tLoss: 6.952315, Loc Loss: 2.074224, Conf Loss: 4.878091\tIter time: 0.2944\n",
            "Training... Epoch: 1, Iter: 2300,\t [73600/82081\t (90%)]\tLoss: 7.700982, Loc Loss: 2.068470, Conf Loss: 5.632513\tIter time: 0.2586\n",
            "Training... Epoch: 1, Iter: 2310,\t [73920/82081\t (90%)]\tLoss: 7.322685, Loc Loss: 2.246109, Conf Loss: 5.076576\tIter time: 0.2651\n",
            "Training... Epoch: 1, Iter: 2320,\t [74240/82081\t (90%)]\tLoss: 7.159585, Loc Loss: 2.068476, Conf Loss: 5.091109\tIter time: 0.2531\n",
            "Training... Epoch: 1, Iter: 2330,\t [74560/82081\t (91%)]\tLoss: 7.541193, Loc Loss: 2.111765, Conf Loss: 5.429428\tIter time: 0.2792\n",
            "Training... Epoch: 1, Iter: 2340,\t [74880/82081\t (91%)]\tLoss: 7.445664, Loc Loss: 2.344173, Conf Loss: 5.101491\tIter time: 0.2777\n",
            "Training... Epoch: 1, Iter: 2350,\t [75200/82081\t (92%)]\tLoss: 7.435876, Loc Loss: 2.149609, Conf Loss: 5.286267\tIter time: 0.2617\n",
            "Training... Epoch: 1, Iter: 2360,\t [75520/82081\t (92%)]\tLoss: 7.643736, Loc Loss: 2.219114, Conf Loss: 5.424622\tIter time: 0.2769\n",
            "Training... Epoch: 1, Iter: 2370,\t [75840/82081\t (92%)]\tLoss: 7.388968, Loc Loss: 1.950711, Conf Loss: 5.438257\tIter time: 0.2455\n",
            "Training... Epoch: 1, Iter: 2380,\t [76160/82081\t (93%)]\tLoss: 7.606210, Loc Loss: 2.140262, Conf Loss: 5.465948\tIter time: 0.2533\n",
            "Training... Epoch: 1, Iter: 2390,\t [76480/82081\t (93%)]\tLoss: 6.729103, Loc Loss: 2.248179, Conf Loss: 4.480924\tIter time: 0.2670\n",
            "Training... Epoch: 1, Iter: 2400,\t [76800/82081\t (94%)]\tLoss: 7.084627, Loc Loss: 2.382454, Conf Loss: 4.702173\tIter time: 0.2674\n",
            "Training... Epoch: 1, Iter: 2410,\t [77120/82081\t (94%)]\tLoss: 7.269055, Loc Loss: 2.119320, Conf Loss: 5.149735\tIter time: 0.2452\n",
            "Training... Epoch: 1, Iter: 2420,\t [77440/82081\t (94%)]\tLoss: 7.039419, Loc Loss: 2.042370, Conf Loss: 4.997049\tIter time: 0.2480\n",
            "Training... Epoch: 1, Iter: 2430,\t [77760/82081\t (95%)]\tLoss: 7.155426, Loc Loss: 2.076904, Conf Loss: 5.078522\tIter time: 0.2488\n",
            "Training... Epoch: 1, Iter: 2440,\t [78080/82081\t (95%)]\tLoss: 7.482116, Loc Loss: 2.185248, Conf Loss: 5.296867\tIter time: 0.2638\n",
            "Training... Epoch: 1, Iter: 2450,\t [78400/82081\t (95%)]\tLoss: 7.697616, Loc Loss: 2.014862, Conf Loss: 5.682753\tIter time: 0.2679\n",
            "Training... Epoch: 1, Iter: 2460,\t [78720/82081\t (96%)]\tLoss: 7.697418, Loc Loss: 2.310625, Conf Loss: 5.386793\tIter time: 0.2528\n",
            "Training... Epoch: 1, Iter: 2470,\t [79040/82081\t (96%)]\tLoss: 7.022777, Loc Loss: 2.007615, Conf Loss: 5.015161\tIter time: 0.2896\n",
            "Training... Epoch: 1, Iter: 2480,\t [79360/82081\t (97%)]\tLoss: 7.511816, Loc Loss: 2.118130, Conf Loss: 5.393685\tIter time: 0.2676\n",
            "Training... Epoch: 1, Iter: 2490,\t [79680/82081\t (97%)]\tLoss: 7.711585, Loc Loss: 2.403200, Conf Loss: 5.308385\tIter time: 0.2552\n",
            "Training... Epoch: 1, Iter: 2500,\t [80000/82081\t (97%)]\tLoss: 7.320343, Loc Loss: 2.114903, Conf Loss: 5.205441\tIter time: 0.2750\n",
            "Training... Epoch: 1, Iter: 2510,\t [80320/82081\t (98%)]\tLoss: 7.349483, Loc Loss: 2.058470, Conf Loss: 5.291013\tIter time: 0.2641\n",
            "Training... Epoch: 1, Iter: 2520,\t [80640/82081\t (98%)]\tLoss: 7.533779, Loc Loss: 2.460559, Conf Loss: 5.073221\tIter time: 0.2682\n",
            "Training... Epoch: 1, Iter: 2530,\t [80960/82081\t (99%)]\tLoss: 7.110632, Loc Loss: 2.228429, Conf Loss: 4.882203\tIter time: 0.2671\n",
            "Training... Epoch: 1, Iter: 2540,\t [81280/82081\t (99%)]\tLoss: 7.595003, Loc Loss: 2.197183, Conf Loss: 5.397820\tIter time: 0.2457\n",
            "Training... Epoch: 1, Iter: 2550,\t [81600/82081\t (99%)]\tLoss: 7.436808, Loc Loss: 2.163970, Conf Loss: 5.272838\tIter time: 0.2676\n",
            "Training... Epoch: 1, Iter: 2560,\t [81920/82081\t (100%)]\tLoss: 7.524476, Loc Loss: 2.165824, Conf Loss: 5.358653\tIter time: 0.2388\n",
            "Training... Epoch: 2, Iter: 2570,\t [128/82081\t (0%)]\tLoss: 7.919001, Loc Loss: 2.777813, Conf Loss: 5.141188\tIter time: 0.3421\n",
            "Training... Epoch: 2, Iter: 2580,\t [448/82081\t (1%)]\tLoss: 7.449433, Loc Loss: 2.031107, Conf Loss: 5.418326\tIter time: 0.2692\n",
            "Training... Epoch: 2, Iter: 2590,\t [768/82081\t (1%)]\tLoss: 7.280496, Loc Loss: 2.187444, Conf Loss: 5.093051\tIter time: 0.2693\n",
            "Training... Epoch: 2, Iter: 2600,\t [1088/82081\t (1%)]\tLoss: 7.155973, Loc Loss: 2.215414, Conf Loss: 4.940559\tIter time: 0.2717\n",
            "Training... Epoch: 2, Iter: 2610,\t [1408/82081\t (2%)]\tLoss: 7.468366, Loc Loss: 2.016632, Conf Loss: 5.451733\tIter time: 0.2714\n",
            "Training... Epoch: 2, Iter: 2620,\t [1728/82081\t (2%)]\tLoss: 7.345183, Loc Loss: 1.912435, Conf Loss: 5.432748\tIter time: 0.2528\n",
            "Training... Epoch: 2, Iter: 2630,\t [2048/82081\t (2%)]\tLoss: 6.911979, Loc Loss: 1.859652, Conf Loss: 5.052326\tIter time: 0.2751\n",
            "Training... Epoch: 2, Iter: 2640,\t [2368/82081\t (3%)]\tLoss: 7.074299, Loc Loss: 2.043978, Conf Loss: 5.030321\tIter time: 0.2433\n",
            "Training... Epoch: 2, Iter: 2650,\t [2688/82081\t (3%)]\tLoss: 7.469265, Loc Loss: 2.142627, Conf Loss: 5.326638\tIter time: 0.2871\n",
            "Training... Epoch: 2, Iter: 2660,\t [3008/82081\t (4%)]\tLoss: 7.449465, Loc Loss: 2.309619, Conf Loss: 5.139846\tIter time: 0.2777\n",
            "Training... Epoch: 2, Iter: 2670,\t [3328/82081\t (4%)]\tLoss: 7.112533, Loc Loss: 2.087698, Conf Loss: 5.024835\tIter time: 0.2590\n",
            "Training... Epoch: 2, Iter: 2680,\t [3648/82081\t (4%)]\tLoss: 6.904343, Loc Loss: 2.215575, Conf Loss: 4.688767\tIter time: 0.2607\n",
            "Training... Epoch: 2, Iter: 2690,\t [3968/82081\t (5%)]\tLoss: 6.969422, Loc Loss: 2.006704, Conf Loss: 4.962718\tIter time: 0.2667\n",
            "Training... Epoch: 2, Iter: 2700,\t [4288/82081\t (5%)]\tLoss: 7.418344, Loc Loss: 2.098117, Conf Loss: 5.320227\tIter time: 0.2685\n",
            "Training... Epoch: 2, Iter: 2710,\t [4608/82081\t (6%)]\tLoss: 7.546410, Loc Loss: 2.266278, Conf Loss: 5.280131\tIter time: 0.2621\n",
            "Training... Epoch: 2, Iter: 2720,\t [4928/82081\t (6%)]\tLoss: 7.002014, Loc Loss: 2.112936, Conf Loss: 4.889078\tIter time: 0.2782\n",
            "Training... Epoch: 2, Iter: 2730,\t [5248/82081\t (6%)]\tLoss: 7.193245, Loc Loss: 2.178051, Conf Loss: 5.015193\tIter time: 0.2663\n",
            "Training... Epoch: 2, Iter: 2740,\t [5568/82081\t (7%)]\tLoss: 6.595672, Loc Loss: 1.984448, Conf Loss: 4.611224\tIter time: 0.2625\n",
            "Training... Epoch: 2, Iter: 2750,\t [5888/82081\t (7%)]\tLoss: 7.193031, Loc Loss: 2.242031, Conf Loss: 4.951000\tIter time: 0.2692\n",
            "Training... Epoch: 2, Iter: 2760,\t [6208/82081\t (8%)]\tLoss: 7.218991, Loc Loss: 2.042947, Conf Loss: 5.176044\tIter time: 0.2817\n",
            "Training... Epoch: 2, Iter: 2770,\t [6528/82081\t (8%)]\tLoss: 7.184460, Loc Loss: 2.283069, Conf Loss: 4.901391\tIter time: 0.2443\n",
            "Training... Epoch: 2, Iter: 2780,\t [6848/82081\t (8%)]\tLoss: 7.396685, Loc Loss: 1.976889, Conf Loss: 5.419796\tIter time: 0.2584\n",
            "Training... Epoch: 2, Iter: 2790,\t [7168/82081\t (9%)]\tLoss: 7.461746, Loc Loss: 2.342806, Conf Loss: 5.118940\tIter time: 0.2689\n",
            "Training... Epoch: 2, Iter: 2800,\t [7488/82081\t (9%)]\tLoss: 7.192583, Loc Loss: 2.092078, Conf Loss: 5.100505\tIter time: 0.2930\n",
            "Training... Epoch: 2, Iter: 2810,\t [7808/82081\t (10%)]\tLoss: 7.295736, Loc Loss: 2.027027, Conf Loss: 5.268710\tIter time: 0.2689\n",
            "Training... Epoch: 2, Iter: 2820,\t [8128/82081\t (10%)]\tLoss: 6.848210, Loc Loss: 2.154641, Conf Loss: 4.693569\tIter time: 0.2764\n",
            "Training... Epoch: 2, Iter: 2830,\t [8448/82081\t (10%)]\tLoss: 7.132541, Loc Loss: 2.137141, Conf Loss: 4.995400\tIter time: 0.2715\n",
            "Training... Epoch: 2, Iter: 2840,\t [8768/82081\t (11%)]\tLoss: 7.120668, Loc Loss: 2.268730, Conf Loss: 4.851939\tIter time: 0.2443\n",
            "Training... Epoch: 2, Iter: 2850,\t [9088/82081\t (11%)]\tLoss: 7.607648, Loc Loss: 2.310042, Conf Loss: 5.297606\tIter time: 0.2983\n",
            "Training... Epoch: 2, Iter: 2860,\t [9408/82081\t (11%)]\tLoss: 6.835307, Loc Loss: 2.202030, Conf Loss: 4.633277\tIter time: 0.2535\n",
            "Training... Epoch: 2, Iter: 2870,\t [9728/82081\t (12%)]\tLoss: 6.738726, Loc Loss: 1.954230, Conf Loss: 4.784496\tIter time: 0.2634\n",
            "Training... Epoch: 2, Iter: 2880,\t [10048/82081\t (12%)]\tLoss: 6.446387, Loc Loss: 2.089013, Conf Loss: 4.357374\tIter time: 0.2649\n",
            "Training... Epoch: 2, Iter: 2890,\t [10368/82081\t (13%)]\tLoss: 7.224347, Loc Loss: 2.013530, Conf Loss: 5.210817\tIter time: 0.2674\n",
            "Training... Epoch: 2, Iter: 2900,\t [10688/82081\t (13%)]\tLoss: 6.909457, Loc Loss: 1.954952, Conf Loss: 4.954504\tIter time: 0.2685\n",
            "Training... Epoch: 2, Iter: 2910,\t [11008/82081\t (13%)]\tLoss: 6.876346, Loc Loss: 1.887080, Conf Loss: 4.989266\tIter time: 0.2552\n",
            "Training... Epoch: 2, Iter: 2920,\t [11328/82081\t (14%)]\tLoss: 7.388600, Loc Loss: 2.117468, Conf Loss: 5.271133\tIter time: 0.2490\n",
            "Training... Epoch: 2, Iter: 2930,\t [11648/82081\t (14%)]\tLoss: 6.861975, Loc Loss: 2.139519, Conf Loss: 4.722455\tIter time: 0.2862\n",
            "Training... Epoch: 2, Iter: 2940,\t [11968/82081\t (15%)]\tLoss: 6.829097, Loc Loss: 2.137447, Conf Loss: 4.691649\tIter time: 0.2625\n",
            "Training... Epoch: 2, Iter: 2950,\t [12288/82081\t (15%)]\tLoss: 7.467979, Loc Loss: 2.212374, Conf Loss: 5.255605\tIter time: 0.2718\n",
            "Training... Epoch: 2, Iter: 2960,\t [12608/82081\t (15%)]\tLoss: 7.596955, Loc Loss: 2.216993, Conf Loss: 5.379962\tIter time: 0.2701\n",
            "Training... Epoch: 2, Iter: 2970,\t [12928/82081\t (16%)]\tLoss: 7.028050, Loc Loss: 2.165726, Conf Loss: 4.862325\tIter time: 0.2716\n",
            "Training... Epoch: 2, Iter: 2980,\t [13248/82081\t (16%)]\tLoss: 7.186699, Loc Loss: 1.815824, Conf Loss: 5.370875\tIter time: 0.2686\n",
            "Training... Epoch: 2, Iter: 2990,\t [13568/82081\t (17%)]\tLoss: 6.540730, Loc Loss: 1.981456, Conf Loss: 4.559274\tIter time: 0.2686\n",
            "Training... Epoch: 2, Iter: 3000,\t [13888/82081\t (17%)]\tLoss: 7.009726, Loc Loss: 2.202678, Conf Loss: 4.807048\tIter time: 0.2801\n",
            "Training... Epoch: 2, Iter: 3010,\t [14208/82081\t (17%)]\tLoss: 7.079627, Loc Loss: 2.261309, Conf Loss: 4.818317\tIter time: 0.3026\n",
            "Training... Epoch: 2, Iter: 3020,\t [14528/82081\t (18%)]\tLoss: 7.433659, Loc Loss: 2.329829, Conf Loss: 5.103829\tIter time: 0.2612\n",
            "Training... Epoch: 2, Iter: 3030,\t [14848/82081\t (18%)]\tLoss: 6.993042, Loc Loss: 2.047542, Conf Loss: 4.945501\tIter time: 0.2785\n",
            "Training... Epoch: 2, Iter: 3040,\t [15168/82081\t (18%)]\tLoss: 6.896510, Loc Loss: 1.823658, Conf Loss: 5.072852\tIter time: 0.2658\n",
            "Training... Epoch: 2, Iter: 3050,\t [15488/82081\t (19%)]\tLoss: 7.506870, Loc Loss: 2.322152, Conf Loss: 5.184718\tIter time: 0.2763\n",
            "Training... Epoch: 2, Iter: 3060,\t [15808/82081\t (19%)]\tLoss: 7.271917, Loc Loss: 2.124611, Conf Loss: 5.147306\tIter time: 0.2627\n",
            "Training... Epoch: 2, Iter: 3070,\t [16128/82081\t (20%)]\tLoss: 7.504096, Loc Loss: 2.310841, Conf Loss: 5.193255\tIter time: 0.2542\n",
            "Training... Epoch: 2, Iter: 3080,\t [16448/82081\t (20%)]\tLoss: 7.140940, Loc Loss: 1.870180, Conf Loss: 5.270760\tIter time: 0.2662\n",
            "Training... Epoch: 2, Iter: 3090,\t [16768/82081\t (20%)]\tLoss: 7.110889, Loc Loss: 2.281519, Conf Loss: 4.829370\tIter time: 0.2604\n",
            "Training... Epoch: 2, Iter: 3100,\t [17088/82081\t (21%)]\tLoss: 7.190134, Loc Loss: 2.079050, Conf Loss: 5.111084\tIter time: 0.2563\n",
            "Training... Epoch: 2, Iter: 3110,\t [17408/82081\t (21%)]\tLoss: 7.125234, Loc Loss: 2.357074, Conf Loss: 4.768160\tIter time: 0.2738\n",
            "Training... Epoch: 2, Iter: 3120,\t [17728/82081\t (22%)]\tLoss: 6.931236, Loc Loss: 2.049426, Conf Loss: 4.881810\tIter time: 0.2608\n",
            "Training... Epoch: 2, Iter: 3130,\t [18048/82081\t (22%)]\tLoss: 7.506167, Loc Loss: 2.397635, Conf Loss: 5.108532\tIter time: 0.2627\n",
            "Training... Epoch: 2, Iter: 3140,\t [18368/82081\t (22%)]\tLoss: 7.347625, Loc Loss: 2.337327, Conf Loss: 5.010298\tIter time: 0.2972\n",
            "Training... Epoch: 2, Iter: 3150,\t [18688/82081\t (23%)]\tLoss: 7.226138, Loc Loss: 2.164474, Conf Loss: 5.061664\tIter time: 0.2664\n",
            "Training... Epoch: 2, Iter: 3160,\t [19008/82081\t (23%)]\tLoss: 7.718456, Loc Loss: 2.183145, Conf Loss: 5.535311\tIter time: 0.3000\n",
            "Training... Epoch: 2, Iter: 3170,\t [19328/82081\t (24%)]\tLoss: 6.897408, Loc Loss: 2.166781, Conf Loss: 4.730628\tIter time: 0.2695\n",
            "Training... Epoch: 2, Iter: 3180,\t [19648/82081\t (24%)]\tLoss: 6.930274, Loc Loss: 1.943007, Conf Loss: 4.987267\tIter time: 0.2640\n",
            "Training... Epoch: 2, Iter: 3190,\t [19968/82081\t (24%)]\tLoss: 6.895647, Loc Loss: 2.347103, Conf Loss: 4.548544\tIter time: 0.2911\n",
            "Training... Epoch: 2, Iter: 3200,\t [20288/82081\t (25%)]\tLoss: 6.656556, Loc Loss: 1.998115, Conf Loss: 4.658441\tIter time: 0.2570\n",
            "Training... Epoch: 2, Iter: 3210,\t [20608/82081\t (25%)]\tLoss: 6.875868, Loc Loss: 2.171232, Conf Loss: 4.704635\tIter time: 0.2634\n",
            "Training... Epoch: 2, Iter: 3220,\t [20928/82081\t (25%)]\tLoss: 7.054496, Loc Loss: 2.154442, Conf Loss: 4.900054\tIter time: 0.2664\n",
            "Training... Epoch: 2, Iter: 3230,\t [21248/82081\t (26%)]\tLoss: 6.994168, Loc Loss: 2.009953, Conf Loss: 4.984215\tIter time: 0.2602\n",
            "Training... Epoch: 2, Iter: 3240,\t [21568/82081\t (26%)]\tLoss: 6.757472, Loc Loss: 1.956344, Conf Loss: 4.801128\tIter time: 0.2619\n",
            "Training... Epoch: 2, Iter: 3250,\t [21888/82081\t (27%)]\tLoss: 7.141562, Loc Loss: 2.296886, Conf Loss: 4.844676\tIter time: 0.2835\n",
            "Training... Epoch: 2, Iter: 3260,\t [22208/82081\t (27%)]\tLoss: 7.378913, Loc Loss: 2.123785, Conf Loss: 5.255128\tIter time: 0.2874\n",
            "Training... Epoch: 2, Iter: 3270,\t [22528/82081\t (27%)]\tLoss: 7.000152, Loc Loss: 1.892083, Conf Loss: 5.108069\tIter time: 0.2649\n",
            "Training... Epoch: 2, Iter: 3280,\t [22848/82081\t (28%)]\tLoss: 6.930222, Loc Loss: 2.074595, Conf Loss: 4.855627\tIter time: 0.2702\n",
            "Training... Epoch: 2, Iter: 3290,\t [23168/82081\t (28%)]\tLoss: 7.222407, Loc Loss: 2.456367, Conf Loss: 4.766041\tIter time: 0.2717\n",
            "Training... Epoch: 2, Iter: 3300,\t [23488/82081\t (29%)]\tLoss: 6.701243, Loc Loss: 2.049806, Conf Loss: 4.651437\tIter time: 0.2569\n",
            "Training... Epoch: 2, Iter: 3310,\t [23808/82081\t (29%)]\tLoss: 7.425562, Loc Loss: 2.413886, Conf Loss: 5.011676\tIter time: 0.2549\n",
            "Training... Epoch: 2, Iter: 3320,\t [24128/82081\t (29%)]\tLoss: 6.456331, Loc Loss: 2.010849, Conf Loss: 4.445482\tIter time: 0.2523\n",
            "Training... Epoch: 2, Iter: 3330,\t [24448/82081\t (30%)]\tLoss: 7.048042, Loc Loss: 1.829955, Conf Loss: 5.218087\tIter time: 0.2447\n",
            "Training... Epoch: 2, Iter: 3340,\t [24768/82081\t (30%)]\tLoss: 6.918931, Loc Loss: 1.952596, Conf Loss: 4.966335\tIter time: 0.2711\n",
            "Training... Epoch: 2, Iter: 3350,\t [25088/82081\t (31%)]\tLoss: 6.945472, Loc Loss: 2.020516, Conf Loss: 4.924955\tIter time: 0.2418\n",
            "Training... Epoch: 2, Iter: 3360,\t [25408/82081\t (31%)]\tLoss: 7.215660, Loc Loss: 1.918951, Conf Loss: 5.296710\tIter time: 0.2646\n",
            "Training... Epoch: 2, Iter: 3370,\t [25728/82081\t (31%)]\tLoss: 6.519078, Loc Loss: 1.892728, Conf Loss: 4.626350\tIter time: 0.2591\n",
            "Training... Epoch: 2, Iter: 3380,\t [26048/82081\t (32%)]\tLoss: 6.883137, Loc Loss: 2.123017, Conf Loss: 4.760120\tIter time: 0.2638\n",
            "Training... Epoch: 2, Iter: 3390,\t [26368/82081\t (32%)]\tLoss: 7.012883, Loc Loss: 2.006265, Conf Loss: 5.006618\tIter time: 0.2608\n",
            "Training... Epoch: 2, Iter: 3400,\t [26688/82081\t (33%)]\tLoss: 7.195154, Loc Loss: 2.230952, Conf Loss: 4.964202\tIter time: 0.2675\n",
            "Training... Epoch: 2, Iter: 3410,\t [27008/82081\t (33%)]\tLoss: 6.707546, Loc Loss: 2.261708, Conf Loss: 4.445838\tIter time: 0.2876\n",
            "Training... Epoch: 2, Iter: 3420,\t [27328/82081\t (33%)]\tLoss: 7.246635, Loc Loss: 2.452810, Conf Loss: 4.793826\tIter time: 0.2809\n",
            "Training... Epoch: 2, Iter: 3430,\t [27648/82081\t (34%)]\tLoss: 6.644560, Loc Loss: 1.836206, Conf Loss: 4.808354\tIter time: 0.2708\n",
            "Training... Epoch: 2, Iter: 3440,\t [27968/82081\t (34%)]\tLoss: 6.614583, Loc Loss: 2.103157, Conf Loss: 4.511425\tIter time: 0.2592\n",
            "Training... Epoch: 2, Iter: 3450,\t [28288/82081\t (34%)]\tLoss: 6.715006, Loc Loss: 2.026436, Conf Loss: 4.688570\tIter time: 0.2629\n",
            "Training... Epoch: 2, Iter: 3460,\t [28608/82081\t (35%)]\tLoss: 7.263602, Loc Loss: 2.083539, Conf Loss: 5.180063\tIter time: 0.2499\n",
            "Training... Epoch: 2, Iter: 3470,\t [28928/82081\t (35%)]\tLoss: 6.514324, Loc Loss: 1.911867, Conf Loss: 4.602458\tIter time: 0.2959\n",
            "Training... Epoch: 2, Iter: 3480,\t [29248/82081\t (36%)]\tLoss: 6.962622, Loc Loss: 2.122187, Conf Loss: 4.840436\tIter time: 0.2612\n",
            "Training... Epoch: 2, Iter: 3490,\t [29568/82081\t (36%)]\tLoss: 7.134977, Loc Loss: 1.799489, Conf Loss: 5.335488\tIter time: 0.2592\n",
            "Training... Epoch: 2, Iter: 3500,\t [29888/82081\t (36%)]\tLoss: 7.094283, Loc Loss: 2.056873, Conf Loss: 5.037410\tIter time: 0.2732\n",
            "Training... Epoch: 2, Iter: 3510,\t [30208/82081\t (37%)]\tLoss: 6.720419, Loc Loss: 1.697474, Conf Loss: 5.022945\tIter time: 0.2701\n",
            "Training... Epoch: 2, Iter: 3520,\t [30528/82081\t (37%)]\tLoss: 6.993403, Loc Loss: 2.033484, Conf Loss: 4.959920\tIter time: 0.2614\n",
            "Training... Epoch: 2, Iter: 3530,\t [30848/82081\t (38%)]\tLoss: 7.313955, Loc Loss: 2.158201, Conf Loss: 5.155754\tIter time: 0.2685\n",
            "Training... Epoch: 2, Iter: 3540,\t [31168/82081\t (38%)]\tLoss: 6.553867, Loc Loss: 1.714946, Conf Loss: 4.838921\tIter time: 0.2575\n",
            "Training... Epoch: 2, Iter: 3550,\t [31488/82081\t (38%)]\tLoss: 7.413102, Loc Loss: 2.493948, Conf Loss: 4.919154\tIter time: 0.2918\n",
            "Training... Epoch: 2, Iter: 3560,\t [31808/82081\t (39%)]\tLoss: 6.589740, Loc Loss: 2.032517, Conf Loss: 4.557222\tIter time: 0.2682\n",
            "Training... Epoch: 2, Iter: 3570,\t [32128/82081\t (39%)]\tLoss: 7.108274, Loc Loss: 2.250432, Conf Loss: 4.857842\tIter time: 0.2748\n",
            "Training... Epoch: 2, Iter: 3580,\t [32448/82081\t (40%)]\tLoss: 6.643470, Loc Loss: 1.948317, Conf Loss: 4.695153\tIter time: 0.2592\n",
            "Training... Epoch: 2, Iter: 3590,\t [32768/82081\t (40%)]\tLoss: 6.874022, Loc Loss: 2.138473, Conf Loss: 4.735549\tIter time: 0.2712\n",
            "Training... Epoch: 2, Iter: 3600,\t [33088/82081\t (40%)]\tLoss: 7.453333, Loc Loss: 2.201689, Conf Loss: 5.251644\tIter time: 0.2528\n",
            "Training... Epoch: 2, Iter: 3610,\t [33408/82081\t (41%)]\tLoss: 7.124898, Loc Loss: 1.747313, Conf Loss: 5.377584\tIter time: 0.2512\n",
            "Training... Epoch: 2, Iter: 3620,\t [33728/82081\t (41%)]\tLoss: 7.104551, Loc Loss: 2.085727, Conf Loss: 5.018824\tIter time: 0.2837\n",
            "Training... Epoch: 2, Iter: 3630,\t [34048/82081\t (41%)]\tLoss: 6.630620, Loc Loss: 1.999650, Conf Loss: 4.630970\tIter time: 0.2662\n",
            "Training... Epoch: 2, Iter: 3640,\t [34368/82081\t (42%)]\tLoss: 6.767490, Loc Loss: 2.217056, Conf Loss: 4.550434\tIter time: 0.2652\n",
            "Training... Epoch: 2, Iter: 3650,\t [34688/82081\t (42%)]\tLoss: 7.387557, Loc Loss: 2.337489, Conf Loss: 5.050068\tIter time: 0.2607\n",
            "Training... Epoch: 2, Iter: 3660,\t [35008/82081\t (43%)]\tLoss: 6.861416, Loc Loss: 1.933386, Conf Loss: 4.928030\tIter time: 0.2826\n",
            "Training... Epoch: 2, Iter: 3670,\t [35328/82081\t (43%)]\tLoss: 7.111407, Loc Loss: 2.213329, Conf Loss: 4.898078\tIter time: 0.2565\n",
            "Training... Epoch: 2, Iter: 3680,\t [35648/82081\t (43%)]\tLoss: 6.921818, Loc Loss: 2.111997, Conf Loss: 4.809821\tIter time: 0.2836\n",
            "Training... Epoch: 2, Iter: 3690,\t [35968/82081\t (44%)]\tLoss: 6.614012, Loc Loss: 1.896926, Conf Loss: 4.717086\tIter time: 0.2778\n",
            "Training... Epoch: 2, Iter: 3700,\t [36288/82081\t (44%)]\tLoss: 6.643167, Loc Loss: 1.974561, Conf Loss: 4.668606\tIter time: 0.2733\n",
            "Training... Epoch: 2, Iter: 3710,\t [36608/82081\t (45%)]\tLoss: 6.986507, Loc Loss: 1.963933, Conf Loss: 5.022574\tIter time: 0.2451\n",
            "Training... Epoch: 2, Iter: 3720,\t [36928/82081\t (45%)]\tLoss: 7.157641, Loc Loss: 2.202178, Conf Loss: 4.955463\tIter time: 0.2629\n",
            "Training... Epoch: 2, Iter: 3730,\t [37248/82081\t (45%)]\tLoss: 6.831580, Loc Loss: 1.973562, Conf Loss: 4.858018\tIter time: 0.2522\n",
            "Training... Epoch: 2, Iter: 3740,\t [37568/82081\t (46%)]\tLoss: 7.355757, Loc Loss: 2.187964, Conf Loss: 5.167792\tIter time: 0.2629\n",
            "Training... Epoch: 2, Iter: 3750,\t [37888/82081\t (46%)]\tLoss: 6.870139, Loc Loss: 1.980197, Conf Loss: 4.889942\tIter time: 0.2564\n",
            "Training... Epoch: 2, Iter: 3760,\t [38208/82081\t (47%)]\tLoss: 7.488393, Loc Loss: 1.876698, Conf Loss: 5.611695\tIter time: 0.2595\n",
            "Training... Epoch: 2, Iter: 3770,\t [38528/82081\t (47%)]\tLoss: 6.896127, Loc Loss: 2.040881, Conf Loss: 4.855246\tIter time: 0.2422\n",
            "Training... Epoch: 2, Iter: 3780,\t [38848/82081\t (47%)]\tLoss: 6.704453, Loc Loss: 1.953834, Conf Loss: 4.750618\tIter time: 0.2494\n",
            "Training... Epoch: 2, Iter: 3790,\t [39168/82081\t (48%)]\tLoss: 7.682001, Loc Loss: 2.086099, Conf Loss: 5.595902\tIter time: 0.2909\n",
            "Training... Epoch: 2, Iter: 3800,\t [39488/82081\t (48%)]\tLoss: 6.898101, Loc Loss: 2.011575, Conf Loss: 4.886526\tIter time: 0.2763\n",
            "Training... Epoch: 2, Iter: 3810,\t [39808/82081\t (48%)]\tLoss: 6.691945, Loc Loss: 2.050583, Conf Loss: 4.641361\tIter time: 0.2652\n",
            "Training... Epoch: 2, Iter: 3820,\t [40128/82081\t (49%)]\tLoss: 7.082952, Loc Loss: 1.978523, Conf Loss: 5.104429\tIter time: 0.2468\n",
            "Training... Epoch: 2, Iter: 3830,\t [40448/82081\t (49%)]\tLoss: 6.572697, Loc Loss: 1.810250, Conf Loss: 4.762447\tIter time: 0.2615\n",
            "Training... Epoch: 2, Iter: 3840,\t [40768/82081\t (50%)]\tLoss: 7.562277, Loc Loss: 2.138170, Conf Loss: 5.424107\tIter time: 0.2707\n",
            "Training... Epoch: 2, Iter: 3850,\t [41088/82081\t (50%)]\tLoss: 6.269625, Loc Loss: 2.066266, Conf Loss: 4.203359\tIter time: 0.3003\n",
            "Training... Epoch: 2, Iter: 3860,\t [41408/82081\t (50%)]\tLoss: 6.764609, Loc Loss: 2.104444, Conf Loss: 4.660166\tIter time: 0.2615\n",
            "Training... Epoch: 2, Iter: 3870,\t [41728/82081\t (51%)]\tLoss: 6.664961, Loc Loss: 2.229918, Conf Loss: 4.435042\tIter time: 0.2650\n",
            "Training... Epoch: 2, Iter: 3880,\t [42048/82081\t (51%)]\tLoss: 6.918243, Loc Loss: 2.103463, Conf Loss: 4.814780\tIter time: 0.2693\n",
            "Training... Epoch: 2, Iter: 3890,\t [42368/82081\t (52%)]\tLoss: 6.767463, Loc Loss: 2.045186, Conf Loss: 4.722277\tIter time: 0.2559\n",
            "Training... Epoch: 2, Iter: 3900,\t [42688/82081\t (52%)]\tLoss: 7.179196, Loc Loss: 2.015751, Conf Loss: 5.163445\tIter time: 0.2588\n",
            "Training... Epoch: 2, Iter: 3910,\t [43008/82081\t (52%)]\tLoss: 6.931448, Loc Loss: 1.939422, Conf Loss: 4.992027\tIter time: 0.2564\n",
            "Training... Epoch: 2, Iter: 3920,\t [43328/82081\t (53%)]\tLoss: 7.215244, Loc Loss: 2.210067, Conf Loss: 5.005178\tIter time: 0.2516\n",
            "Training... Epoch: 2, Iter: 3930,\t [43648/82081\t (53%)]\tLoss: 6.908445, Loc Loss: 1.897967, Conf Loss: 5.010478\tIter time: 0.2739\n",
            "Training... Epoch: 2, Iter: 3940,\t [43968/82081\t (54%)]\tLoss: 6.939565, Loc Loss: 2.147161, Conf Loss: 4.792403\tIter time: 0.2522\n",
            "Training... Epoch: 2, Iter: 3950,\t [44288/82081\t (54%)]\tLoss: 6.728436, Loc Loss: 1.860012, Conf Loss: 4.868424\tIter time: 0.2607\n",
            "Training... Epoch: 2, Iter: 3960,\t [44608/82081\t (54%)]\tLoss: 6.542613, Loc Loss: 1.892871, Conf Loss: 4.649742\tIter time: 0.2487\n",
            "Training... Epoch: 2, Iter: 3970,\t [44928/82081\t (55%)]\tLoss: 7.145893, Loc Loss: 2.124242, Conf Loss: 5.021651\tIter time: 0.2723\n",
            "Training... Epoch: 2, Iter: 3980,\t [45248/82081\t (55%)]\tLoss: 6.723214, Loc Loss: 1.993290, Conf Loss: 4.729924\tIter time: 0.2497\n",
            "Training... Epoch: 2, Iter: 3990,\t [45568/82081\t (55%)]\tLoss: 7.104441, Loc Loss: 1.950070, Conf Loss: 5.154372\tIter time: 0.2584\n",
            "Training... Epoch: 2, Iter: 4000,\t [45888/82081\t (56%)]\tLoss: 6.668262, Loc Loss: 1.774254, Conf Loss: 4.894009\tIter time: 0.2583\n",
            "Training... Epoch: 2, Iter: 4010,\t [46208/82081\t (56%)]\tLoss: 6.991152, Loc Loss: 2.456816, Conf Loss: 4.534336\tIter time: 0.2761\n",
            "Training... Epoch: 2, Iter: 4020,\t [46528/82081\t (57%)]\tLoss: 6.698756, Loc Loss: 1.875160, Conf Loss: 4.823596\tIter time: 0.2569\n",
            "Training... Epoch: 2, Iter: 4030,\t [46848/82081\t (57%)]\tLoss: 6.522754, Loc Loss: 1.799142, Conf Loss: 4.723611\tIter time: 0.2652\n",
            "Training... Epoch: 2, Iter: 4040,\t [47168/82081\t (57%)]\tLoss: 7.123047, Loc Loss: 2.111578, Conf Loss: 5.011468\tIter time: 0.2682\n",
            "Training... Epoch: 2, Iter: 4050,\t [47488/82081\t (58%)]\tLoss: 6.173084, Loc Loss: 1.802896, Conf Loss: 4.370189\tIter time: 0.2501\n",
            "Training... Epoch: 2, Iter: 4060,\t [47808/82081\t (58%)]\tLoss: 7.324119, Loc Loss: 2.327146, Conf Loss: 4.996973\tIter time: 0.2692\n",
            "Training... Epoch: 2, Iter: 4070,\t [48128/82081\t (59%)]\tLoss: 6.725045, Loc Loss: 2.218007, Conf Loss: 4.507038\tIter time: 0.2670\n",
            "Training... Epoch: 2, Iter: 4080,\t [48448/82081\t (59%)]\tLoss: 7.165817, Loc Loss: 2.185148, Conf Loss: 4.980669\tIter time: 0.2774\n",
            "Training... Epoch: 2, Iter: 4090,\t [48768/82081\t (59%)]\tLoss: 6.749438, Loc Loss: 2.087986, Conf Loss: 4.661452\tIter time: 0.2422\n",
            "Training... Epoch: 2, Iter: 4100,\t [49088/82081\t (60%)]\tLoss: 6.645084, Loc Loss: 2.028794, Conf Loss: 4.616290\tIter time: 0.2867\n",
            "Training... Epoch: 2, Iter: 4110,\t [49408/82081\t (60%)]\tLoss: 6.918876, Loc Loss: 2.007029, Conf Loss: 4.911847\tIter time: 0.2696\n",
            "Training... Epoch: 2, Iter: 4120,\t [49728/82081\t (61%)]\tLoss: 6.974117, Loc Loss: 2.256521, Conf Loss: 4.717597\tIter time: 0.2658\n",
            "Training... Epoch: 2, Iter: 4130,\t [50048/82081\t (61%)]\tLoss: 6.976142, Loc Loss: 2.008880, Conf Loss: 4.967261\tIter time: 0.3021\n",
            "Training... Epoch: 2, Iter: 4140,\t [50368/82081\t (61%)]\tLoss: 6.700536, Loc Loss: 1.791508, Conf Loss: 4.909029\tIter time: 0.2744\n",
            "Training... Epoch: 2, Iter: 4150,\t [50688/82081\t (62%)]\tLoss: 6.789851, Loc Loss: 2.095259, Conf Loss: 4.694592\tIter time: 0.2616\n",
            "Training... Epoch: 2, Iter: 4160,\t [51008/82081\t (62%)]\tLoss: 6.812073, Loc Loss: 2.074025, Conf Loss: 4.738047\tIter time: 0.2793\n",
            "Training... Epoch: 2, Iter: 4170,\t [51328/82081\t (63%)]\tLoss: 6.563869, Loc Loss: 2.028001, Conf Loss: 4.535869\tIter time: 0.2642\n",
            "Training... Epoch: 2, Iter: 4180,\t [51648/82081\t (63%)]\tLoss: 7.153554, Loc Loss: 2.038386, Conf Loss: 5.115168\tIter time: 0.2697\n",
            "Training... Epoch: 2, Iter: 4190,\t [51968/82081\t (63%)]\tLoss: 7.045174, Loc Loss: 1.841380, Conf Loss: 5.203794\tIter time: 0.2652\n",
            "Training... Epoch: 2, Iter: 4200,\t [52288/82081\t (64%)]\tLoss: 6.722384, Loc Loss: 2.014942, Conf Loss: 4.707442\tIter time: 0.2843\n",
            "Training... Epoch: 2, Iter: 4210,\t [52608/82081\t (64%)]\tLoss: 6.763075, Loc Loss: 1.742093, Conf Loss: 5.020982\tIter time: 0.3068\n",
            "Training... Epoch: 2, Iter: 4220,\t [52928/82081\t (64%)]\tLoss: 6.805524, Loc Loss: 1.983841, Conf Loss: 4.821683\tIter time: 0.2561\n",
            "Training... Epoch: 2, Iter: 4230,\t [53248/82081\t (65%)]\tLoss: 6.727949, Loc Loss: 2.147995, Conf Loss: 4.579954\tIter time: 0.2414\n",
            "Training... Epoch: 2, Iter: 4240,\t [53568/82081\t (65%)]\tLoss: 6.874950, Loc Loss: 2.059781, Conf Loss: 4.815170\tIter time: 0.2658\n",
            "Training... Epoch: 2, Iter: 4250,\t [53888/82081\t (66%)]\tLoss: 6.311767, Loc Loss: 1.538699, Conf Loss: 4.773068\tIter time: 0.2610\n",
            "Training... Epoch: 2, Iter: 4260,\t [54208/82081\t (66%)]\tLoss: 6.592928, Loc Loss: 1.925741, Conf Loss: 4.667187\tIter time: 0.2567\n",
            "Training... Epoch: 2, Iter: 4270,\t [54528/82081\t (66%)]\tLoss: 6.808792, Loc Loss: 2.153286, Conf Loss: 4.655506\tIter time: 0.2710\n",
            "Training... Epoch: 2, Iter: 4280,\t [54848/82081\t (67%)]\tLoss: 7.250082, Loc Loss: 1.899541, Conf Loss: 5.350541\tIter time: 0.2449\n",
            "Training... Epoch: 2, Iter: 4290,\t [55168/82081\t (67%)]\tLoss: 6.235228, Loc Loss: 1.919588, Conf Loss: 4.315639\tIter time: 0.2568\n",
            "Training... Epoch: 2, Iter: 4300,\t [55488/82081\t (68%)]\tLoss: 6.927330, Loc Loss: 2.218413, Conf Loss: 4.708917\tIter time: 0.2516\n",
            "Training... Epoch: 2, Iter: 4310,\t [55808/82081\t (68%)]\tLoss: 6.700006, Loc Loss: 2.196961, Conf Loss: 4.503046\tIter time: 0.2754\n",
            "Training... Epoch: 2, Iter: 4320,\t [56128/82081\t (68%)]\tLoss: 7.122987, Loc Loss: 2.345913, Conf Loss: 4.777074\tIter time: 0.2681\n",
            "Training... Epoch: 2, Iter: 4330,\t [56448/82081\t (69%)]\tLoss: 7.083617, Loc Loss: 2.101654, Conf Loss: 4.981963\tIter time: 0.2467\n",
            "Training... Epoch: 2, Iter: 4340,\t [56768/82081\t (69%)]\tLoss: 6.527036, Loc Loss: 1.909476, Conf Loss: 4.617560\tIter time: 0.2722\n",
            "Training... Epoch: 2, Iter: 4350,\t [57088/82081\t (70%)]\tLoss: 7.079326, Loc Loss: 1.942382, Conf Loss: 5.136944\tIter time: 0.2463\n",
            "Training... Epoch: 2, Iter: 4360,\t [57408/82081\t (70%)]\tLoss: 7.164411, Loc Loss: 2.083082, Conf Loss: 5.081328\tIter time: 0.2559\n",
            "Training... Epoch: 2, Iter: 4370,\t [57728/82081\t (70%)]\tLoss: 6.901933, Loc Loss: 2.025215, Conf Loss: 4.876718\tIter time: 0.2594\n",
            "Training... Epoch: 2, Iter: 4380,\t [58048/82081\t (71%)]\tLoss: 6.795741, Loc Loss: 2.001939, Conf Loss: 4.793802\tIter time: 0.2476\n",
            "Training... Epoch: 2, Iter: 4390,\t [58368/82081\t (71%)]\tLoss: 6.311403, Loc Loss: 1.857129, Conf Loss: 4.454274\tIter time: 0.2602\n",
            "Training... Epoch: 2, Iter: 4400,\t [58688/82081\t (71%)]\tLoss: 6.481648, Loc Loss: 1.955584, Conf Loss: 4.526064\tIter time: 0.2653\n",
            "Training... Epoch: 2, Iter: 4410,\t [59008/82081\t (72%)]\tLoss: 6.608464, Loc Loss: 2.178945, Conf Loss: 4.429519\tIter time: 0.2767\n",
            "Training... Epoch: 2, Iter: 4420,\t [59328/82081\t (72%)]\tLoss: 6.794181, Loc Loss: 2.015623, Conf Loss: 4.778558\tIter time: 0.2972\n",
            "Training... Epoch: 2, Iter: 4430,\t [59648/82081\t (73%)]\tLoss: 6.899502, Loc Loss: 2.057925, Conf Loss: 4.841578\tIter time: 0.2828\n",
            "Training... Epoch: 2, Iter: 4440,\t [59968/82081\t (73%)]\tLoss: 6.341999, Loc Loss: 1.850307, Conf Loss: 4.491692\tIter time: 0.2455\n",
            "Training... Epoch: 2, Iter: 4450,\t [60288/82081\t (73%)]\tLoss: 7.052480, Loc Loss: 2.231377, Conf Loss: 4.821104\tIter time: 0.2439\n",
            "Training... Epoch: 2, Iter: 4460,\t [60608/82081\t (74%)]\tLoss: 6.663408, Loc Loss: 2.000632, Conf Loss: 4.662776\tIter time: 0.2687\n",
            "Training... Epoch: 2, Iter: 4470,\t [60928/82081\t (74%)]\tLoss: 6.123795, Loc Loss: 1.714148, Conf Loss: 4.409647\tIter time: 0.2571\n",
            "Training... Epoch: 2, Iter: 4480,\t [61248/82081\t (75%)]\tLoss: 6.342805, Loc Loss: 1.727657, Conf Loss: 4.615148\tIter time: 0.2553\n",
            "Training... Epoch: 2, Iter: 4490,\t [61568/82081\t (75%)]\tLoss: 7.054133, Loc Loss: 2.283270, Conf Loss: 4.770864\tIter time: 0.2875\n",
            "Training... Epoch: 2, Iter: 4500,\t [61888/82081\t (75%)]\tLoss: 6.972948, Loc Loss: 2.196271, Conf Loss: 4.776677\tIter time: 0.2598\n",
            "Training... Epoch: 2, Iter: 4510,\t [62208/82081\t (76%)]\tLoss: 6.540473, Loc Loss: 1.900075, Conf Loss: 4.640399\tIter time: 0.2632\n",
            "Training... Epoch: 2, Iter: 4520,\t [62528/82081\t (76%)]\tLoss: 7.124962, Loc Loss: 2.298715, Conf Loss: 4.826246\tIter time: 0.2588\n",
            "Training... Epoch: 2, Iter: 4530,\t [62848/82081\t (77%)]\tLoss: 7.101485, Loc Loss: 1.916862, Conf Loss: 5.184623\tIter time: 0.2819\n",
            "Training... Epoch: 2, Iter: 4540,\t [63168/82081\t (77%)]\tLoss: 6.973354, Loc Loss: 2.045135, Conf Loss: 4.928219\tIter time: 0.2745\n",
            "Training... Epoch: 2, Iter: 4550,\t [63488/82081\t (77%)]\tLoss: 6.876450, Loc Loss: 2.125441, Conf Loss: 4.751009\tIter time: 0.2633\n",
            "Training... Epoch: 2, Iter: 4560,\t [63808/82081\t (78%)]\tLoss: 6.818155, Loc Loss: 1.989979, Conf Loss: 4.828176\tIter time: 0.2449\n",
            "Training... Epoch: 2, Iter: 4570,\t [64128/82081\t (78%)]\tLoss: 6.427632, Loc Loss: 1.663744, Conf Loss: 4.763888\tIter time: 0.2664\n",
            "Training... Epoch: 2, Iter: 4580,\t [64448/82081\t (78%)]\tLoss: 6.953774, Loc Loss: 1.992897, Conf Loss: 4.960878\tIter time: 0.2421\n",
            "Training... Epoch: 2, Iter: 4590,\t [64768/82081\t (79%)]\tLoss: 7.092776, Loc Loss: 2.088745, Conf Loss: 5.004032\tIter time: 0.2732\n",
            "Training... Epoch: 2, Iter: 4600,\t [65088/82081\t (79%)]\tLoss: 6.359938, Loc Loss: 2.028182, Conf Loss: 4.331756\tIter time: 0.2753\n",
            "Training... Epoch: 2, Iter: 4610,\t [65408/82081\t (80%)]\tLoss: 6.453253, Loc Loss: 1.900708, Conf Loss: 4.552546\tIter time: 0.2698\n",
            "Training... Epoch: 2, Iter: 4620,\t [65728/82081\t (80%)]\tLoss: 6.340285, Loc Loss: 1.964575, Conf Loss: 4.375710\tIter time: 0.2871\n",
            "Training... Epoch: 2, Iter: 4630,\t [66048/82081\t (80%)]\tLoss: 7.108467, Loc Loss: 2.107193, Conf Loss: 5.001275\tIter time: 0.2879\n",
            "Training... Epoch: 2, Iter: 4640,\t [66368/82081\t (81%)]\tLoss: 6.483663, Loc Loss: 1.814857, Conf Loss: 4.668806\tIter time: 0.2582\n",
            "Training... Epoch: 2, Iter: 4650,\t [66688/82081\t (81%)]\tLoss: 7.436994, Loc Loss: 2.412676, Conf Loss: 5.024318\tIter time: 0.2637\n",
            "Training... Epoch: 2, Iter: 4660,\t [67008/82081\t (82%)]\tLoss: 6.592853, Loc Loss: 1.994918, Conf Loss: 4.597935\tIter time: 0.2614\n",
            "Training... Epoch: 2, Iter: 4670,\t [67328/82081\t (82%)]\tLoss: 6.758834, Loc Loss: 1.990612, Conf Loss: 4.768222\tIter time: 0.2650\n",
            "Training... Epoch: 2, Iter: 4680,\t [67648/82081\t (82%)]\tLoss: 7.033266, Loc Loss: 2.063675, Conf Loss: 4.969591\tIter time: 0.2657\n",
            "Training... Epoch: 2, Iter: 4690,\t [67968/82081\t (83%)]\tLoss: 6.788117, Loc Loss: 1.983667, Conf Loss: 4.804450\tIter time: 0.2551\n",
            "Training... Epoch: 2, Iter: 4700,\t [68288/82081\t (83%)]\tLoss: 6.934459, Loc Loss: 2.293193, Conf Loss: 4.641265\tIter time: 0.2650\n",
            "Training... Epoch: 2, Iter: 4710,\t [68608/82081\t (84%)]\tLoss: 6.495375, Loc Loss: 2.110710, Conf Loss: 4.384664\tIter time: 0.2549\n",
            "Training... Epoch: 2, Iter: 4720,\t [68928/82081\t (84%)]\tLoss: 6.650304, Loc Loss: 2.305469, Conf Loss: 4.344835\tIter time: 0.2727\n",
            "Training... Epoch: 2, Iter: 4730,\t [69248/82081\t (84%)]\tLoss: 6.880191, Loc Loss: 2.207217, Conf Loss: 4.672974\tIter time: 0.2725\n",
            "Training... Epoch: 2, Iter: 4740,\t [69568/82081\t (85%)]\tLoss: 6.361564, Loc Loss: 2.040867, Conf Loss: 4.320697\tIter time: 0.2769\n",
            "Training... Epoch: 2, Iter: 4750,\t [69888/82081\t (85%)]\tLoss: 6.589074, Loc Loss: 1.892753, Conf Loss: 4.696321\tIter time: 0.2576\n",
            "Training... Epoch: 2, Iter: 4760,\t [70208/82081\t (86%)]\tLoss: 6.527067, Loc Loss: 2.223967, Conf Loss: 4.303101\tIter time: 0.2679\n",
            "Training... Epoch: 2, Iter: 4770,\t [70528/82081\t (86%)]\tLoss: 7.228683, Loc Loss: 2.046396, Conf Loss: 5.182288\tIter time: 0.2412\n",
            "Training... Epoch: 2, Iter: 4780,\t [70848/82081\t (86%)]\tLoss: 6.404995, Loc Loss: 1.744101, Conf Loss: 4.660894\tIter time: 0.2639\n",
            "Training... Epoch: 2, Iter: 4790,\t [71168/82081\t (87%)]\tLoss: 6.352295, Loc Loss: 2.002473, Conf Loss: 4.349823\tIter time: 0.2559\n",
            "Training... Epoch: 2, Iter: 4800,\t [71488/82081\t (87%)]\tLoss: 6.284082, Loc Loss: 2.006413, Conf Loss: 4.277669\tIter time: 0.2647\n",
            "Training... Epoch: 2, Iter: 4810,\t [71808/82081\t (87%)]\tLoss: 6.264853, Loc Loss: 2.029545, Conf Loss: 4.235309\tIter time: 0.2635\n",
            "Training... Epoch: 2, Iter: 4820,\t [72128/82081\t (88%)]\tLoss: 6.817722, Loc Loss: 2.032548, Conf Loss: 4.785173\tIter time: 0.2577\n",
            "Training... Epoch: 2, Iter: 4830,\t [72448/82081\t (88%)]\tLoss: 6.538364, Loc Loss: 1.908044, Conf Loss: 4.630321\tIter time: 0.2647\n",
            "Training... Epoch: 2, Iter: 4840,\t [72768/82081\t (89%)]\tLoss: 6.556188, Loc Loss: 1.949831, Conf Loss: 4.606357\tIter time: 0.2738\n",
            "Training... Epoch: 2, Iter: 4850,\t [73088/82081\t (89%)]\tLoss: 6.884613, Loc Loss: 2.023586, Conf Loss: 4.861028\tIter time: 0.2509\n",
            "Training... Epoch: 2, Iter: 4860,\t [73408/82081\t (89%)]\tLoss: 6.622268, Loc Loss: 2.032792, Conf Loss: 4.589475\tIter time: 0.2642\n",
            "Training... Epoch: 2, Iter: 4870,\t [73728/82081\t (90%)]\tLoss: 6.768864, Loc Loss: 2.025052, Conf Loss: 4.743812\tIter time: 0.2459\n",
            "Training... Epoch: 2, Iter: 4880,\t [74048/82081\t (90%)]\tLoss: 6.962460, Loc Loss: 1.805033, Conf Loss: 5.157426\tIter time: 0.2634\n",
            "Training... Epoch: 2, Iter: 4890,\t [74368/82081\t (91%)]\tLoss: 7.215696, Loc Loss: 2.303450, Conf Loss: 4.912246\tIter time: 0.2647\n",
            "Training... Epoch: 2, Iter: 4900,\t [74688/82081\t (91%)]\tLoss: 6.842930, Loc Loss: 2.137879, Conf Loss: 4.705051\tIter time: 0.2737\n",
            "Training... Epoch: 2, Iter: 4910,\t [75008/82081\t (91%)]\tLoss: 6.643901, Loc Loss: 2.030173, Conf Loss: 4.613729\tIter time: 0.2771\n",
            "Training... Epoch: 2, Iter: 4920,\t [75328/82081\t (92%)]\tLoss: 6.437224, Loc Loss: 1.891011, Conf Loss: 4.546213\tIter time: 0.2427\n",
            "Training... Epoch: 2, Iter: 4930,\t [75648/82081\t (92%)]\tLoss: 7.124099, Loc Loss: 2.460332, Conf Loss: 4.663767\tIter time: 0.2514\n",
            "Training... Epoch: 2, Iter: 4940,\t [75968/82081\t (93%)]\tLoss: 6.639040, Loc Loss: 2.086156, Conf Loss: 4.552884\tIter time: 0.3061\n",
            "Training... Epoch: 2, Iter: 4950,\t [76288/82081\t (93%)]\tLoss: 6.871398, Loc Loss: 2.020597, Conf Loss: 4.850801\tIter time: 0.2643\n",
            "Training... Epoch: 2, Iter: 4960,\t [76608/82081\t (93%)]\tLoss: 6.421153, Loc Loss: 2.191260, Conf Loss: 4.229892\tIter time: 0.2687\n",
            "Training... Epoch: 2, Iter: 4970,\t [76928/82081\t (94%)]\tLoss: 6.219503, Loc Loss: 1.842602, Conf Loss: 4.376901\tIter time: 0.2685\n",
            "Training... Epoch: 2, Iter: 4980,\t [77248/82081\t (94%)]\tLoss: 6.577692, Loc Loss: 1.933439, Conf Loss: 4.644253\tIter time: 0.2672\n",
            "Training... Epoch: 2, Iter: 4990,\t [77568/82081\t (94%)]\tLoss: 6.884632, Loc Loss: 1.999546, Conf Loss: 4.885087\tIter time: 0.2495\n",
            "Training... Epoch: 2, Iter: 5000,\t [77888/82081\t (95%)]\tLoss: 6.981931, Loc Loss: 2.081376, Conf Loss: 4.900555\tIter time: 0.2645\n",
            "\n",
            "Training finished\n",
            "Saved model to ./weights/results/SSD300_i-5000.pth\n",
            "Saved graph to ./weights/results/SSD300_learning-curve_i-5000.png\n"
          ]
        }
      ],
      "source": [
        "#Basic training\n",
        "!python easy_train.py COCO --no_augmentation --max_iteration 5000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "MgEJZFRbNfoQ",
        "outputId": "8ae66b75-5b0a-417c-e602-679ea13bc64f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa2308e94d0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "img = mpimg.imread('./weights/results/SSD300_learning-curve_i-5000.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYJbODcOQ1ID",
        "outputId": "87895fa8-a989-4851-9c66-bdf9b91fa19d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=12.94s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO:root:Dataset info:\n",
            "root dir: ['/root/data/coco/coco2014/trainval'],\n",
            "focus: ['train2014'],\n",
            "labels:['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
            "ignore object: None\n",
            "augmentation: True\n",
            "batch size: 32\n",
            "num_workers: 4\n",
            "\n",
            "INFO:root:model loaded\n",
            "INFO:root:DataParallel(\n",
            "  (module): SSD300(\n",
            "    (codec): Codec(\n",
            "      (encoder): Encoder()\n",
            "      (decoder): Decoder()\n",
            "    )\n",
            "    (defaultBox): DBoxSSDOriginal()\n",
            "    (predictor): Predictor()\n",
            "    (inferenceBox): InferenceBox()\n",
            "    (feature_layers): ModuleDict(\n",
            "      (convRL1_1): ConvRelu(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL1_2): ConvRelu(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convRL2_1): ConvRelu(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL2_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convRL3_1): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL3_2): ConvRelu(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL3_3): ConvRelu(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=True)\n",
            "      (convRL4_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL4_2): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL4_3): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convRL5_1): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL5_2): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL5_3): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (pool5): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1, dilation=1, ceil_mode=False)\n",
            "      (convRL6): ConvRelu(\n",
            "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL7): ConvRelu(\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL8_1): ConvRelu(\n",
            "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL8_2): ConvRelu(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL9_1): ConvRelu(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL9_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL10_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL10_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL11_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (convRL11_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (addon_layers): ModuleDict(\n",
            "      (addon_1): L2Normalization()\n",
            "    )\n",
            "    (localization_layers): ModuleDict(\n",
            "      (conv_loc_1): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_2): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_3): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_4): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_6): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (confidence_layers): ModuleDict(\n",
            "      (conv_conf_1): Conv2d(512, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_2): Conv2d(1024, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_3): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_4): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_6): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO:root:Optimizer Info:\n",
            "Optimizer: SGD\n",
            "learning rate: 0.001, Momentum: 0.9, Weight decay: 0.0005\n",
            "\n",
            "INFO:root:Multi Step Info:\n",
            "milestones: [40000, 50000]\n",
            "gamma: 0.1\n",
            "\n",
            "INFO:root:Save Info:\n",
            "filename: SSD300\n",
            "checkpoints interval: 5000\n",
            "\n",
            "INFO:root:Start Training\n",
            "\n",
            "\n",
            "Training... Epoch: 1, Iter: 1,\t [32/82081\t (0%)]\tLoss: 29.521883, Loc Loss: 3.920407, Conf Loss: 25.601477\tIter time: 0.3612\n",
            "Training... Epoch: 1, Iter: 10,\t [320/82081\t (0%)]\tLoss: 21.630997, Loc Loss: 3.561994, Conf Loss: 18.069002\tIter time: 0.2807\n",
            "Training... Epoch: 1, Iter: 20,\t [640/82081\t (1%)]\tLoss: 20.917244, Loc Loss: 3.224359, Conf Loss: 17.692884\tIter time: 0.2674\n",
            "Training... Epoch: 1, Iter: 30,\t [960/82081\t (1%)]\tLoss: 20.155495, Loc Loss: 3.604517, Conf Loss: 16.550978\tIter time: 0.2435\n",
            "Training... Epoch: 1, Iter: 40,\t [1280/82081\t (2%)]\tLoss: 15.714084, Loc Loss: 3.515313, Conf Loss: 12.198771\tIter time: 0.2998\n",
            "Training... Epoch: 1, Iter: 50,\t [1600/82081\t (2%)]\tLoss: 13.412336, Loc Loss: 3.508031, Conf Loss: 9.904305\tIter time: 0.2669\n",
            "Training... Epoch: 1, Iter: 60,\t [1920/82081\t (2%)]\tLoss: 11.774030, Loc Loss: 3.161993, Conf Loss: 8.612037\tIter time: 0.2650\n",
            "Training... Epoch: 1, Iter: 70,\t [2240/82081\t (3%)]\tLoss: 11.422873, Loc Loss: 3.234039, Conf Loss: 8.188834\tIter time: 0.2859\n",
            "Training... Epoch: 1, Iter: 80,\t [2560/82081\t (3%)]\tLoss: 10.677069, Loc Loss: 3.086417, Conf Loss: 7.590652\tIter time: 0.2800\n",
            "Training... Epoch: 1, Iter: 90,\t [2880/82081\t (4%)]\tLoss: 10.111361, Loc Loss: 3.288831, Conf Loss: 6.822529\tIter time: 0.2739\n",
            "Training... Epoch: 1, Iter: 100,\t [3200/82081\t (4%)]\tLoss: 9.632703, Loc Loss: 3.107722, Conf Loss: 6.524981\tIter time: 0.2471\n",
            "Training... Epoch: 1, Iter: 110,\t [3520/82081\t (4%)]\tLoss: 9.301852, Loc Loss: 2.824151, Conf Loss: 6.477701\tIter time: 0.2733\n",
            "Training... Epoch: 1, Iter: 120,\t [3840/82081\t (5%)]\tLoss: 9.198303, Loc Loss: 2.842136, Conf Loss: 6.356167\tIter time: 0.2756\n",
            "Training... Epoch: 1, Iter: 130,\t [4160/82081\t (5%)]\tLoss: 9.235647, Loc Loss: 3.128719, Conf Loss: 6.106928\tIter time: 0.2653\n",
            "Training... Epoch: 1, Iter: 140,\t [4480/82081\t (5%)]\tLoss: 8.699720, Loc Loss: 2.850922, Conf Loss: 5.848798\tIter time: 0.2553\n",
            "Training... Epoch: 1, Iter: 150,\t [4800/82081\t (6%)]\tLoss: 9.074802, Loc Loss: 2.748704, Conf Loss: 6.326098\tIter time: 0.2702\n",
            "Training... Epoch: 1, Iter: 160,\t [5120/82081\t (6%)]\tLoss: 9.974878, Loc Loss: 3.218299, Conf Loss: 6.756579\tIter time: 0.2811\n",
            "Training... Epoch: 1, Iter: 170,\t [5440/82081\t (7%)]\tLoss: 9.112219, Loc Loss: 2.948685, Conf Loss: 6.163533\tIter time: 0.2706\n",
            "Training... Epoch: 1, Iter: 180,\t [5760/82081\t (7%)]\tLoss: 9.375591, Loc Loss: 2.820799, Conf Loss: 6.554792\tIter time: 0.2700\n",
            "Training... Epoch: 1, Iter: 190,\t [6080/82081\t (7%)]\tLoss: 8.982662, Loc Loss: 2.980347, Conf Loss: 6.002315\tIter time: 0.2677\n",
            "Training... Epoch: 1, Iter: 200,\t [6400/82081\t (8%)]\tLoss: 9.204060, Loc Loss: 2.734006, Conf Loss: 6.470053\tIter time: 0.2600\n",
            "Training... Epoch: 1, Iter: 210,\t [6720/82081\t (8%)]\tLoss: 8.924723, Loc Loss: 2.726629, Conf Loss: 6.198094\tIter time: 0.2630\n",
            "Training... Epoch: 1, Iter: 220,\t [7040/82081\t (9%)]\tLoss: 9.122812, Loc Loss: 2.781039, Conf Loss: 6.341773\tIter time: 0.2633\n",
            "Training... Epoch: 1, Iter: 230,\t [7360/82081\t (9%)]\tLoss: 8.865330, Loc Loss: 2.848553, Conf Loss: 6.016778\tIter time: 0.2748\n",
            "Training... Epoch: 1, Iter: 240,\t [7680/82081\t (9%)]\tLoss: 9.628838, Loc Loss: 2.760448, Conf Loss: 6.868390\tIter time: 0.2728\n",
            "Training... Epoch: 1, Iter: 250,\t [8000/82081\t (10%)]\tLoss: 9.133316, Loc Loss: 2.755848, Conf Loss: 6.377469\tIter time: 0.2628\n",
            "Training... Epoch: 1, Iter: 260,\t [8320/82081\t (10%)]\tLoss: 8.907796, Loc Loss: 2.746204, Conf Loss: 6.161592\tIter time: 0.2620\n",
            "Training... Epoch: 1, Iter: 270,\t [8640/82081\t (11%)]\tLoss: 8.967752, Loc Loss: 2.755067, Conf Loss: 6.212685\tIter time: 0.2436\n",
            "Training... Epoch: 1, Iter: 280,\t [8960/82081\t (11%)]\tLoss: 9.191333, Loc Loss: 2.784647, Conf Loss: 6.406686\tIter time: 0.2608\n",
            "Training... Epoch: 1, Iter: 290,\t [9280/82081\t (11%)]\tLoss: 8.776218, Loc Loss: 2.805871, Conf Loss: 5.970348\tIter time: 0.2621\n",
            "Training... Epoch: 1, Iter: 300,\t [9600/82081\t (12%)]\tLoss: 8.885599, Loc Loss: 2.639237, Conf Loss: 6.246363\tIter time: 0.2564\n",
            "Training... Epoch: 1, Iter: 310,\t [9920/82081\t (12%)]\tLoss: 8.959517, Loc Loss: 2.627949, Conf Loss: 6.331568\tIter time: 0.3013\n",
            "Training... Epoch: 1, Iter: 320,\t [10240/82081\t (12%)]\tLoss: 9.219979, Loc Loss: 2.709681, Conf Loss: 6.510298\tIter time: 0.2570\n",
            "Training... Epoch: 1, Iter: 330,\t [10560/82081\t (13%)]\tLoss: 8.714590, Loc Loss: 2.634618, Conf Loss: 6.079972\tIter time: 0.2783\n",
            "Training... Epoch: 1, Iter: 340,\t [10880/82081\t (13%)]\tLoss: 8.467108, Loc Loss: 2.546350, Conf Loss: 5.920758\tIter time: 0.2443\n",
            "Training... Epoch: 1, Iter: 350,\t [11200/82081\t (14%)]\tLoss: 10.121903, Loc Loss: 2.998767, Conf Loss: 7.123136\tIter time: 0.2640\n",
            "Training... Epoch: 1, Iter: 360,\t [11520/82081\t (14%)]\tLoss: 9.751582, Loc Loss: 2.953791, Conf Loss: 6.797791\tIter time: 0.2581\n",
            "Training... Epoch: 1, Iter: 370,\t [11840/82081\t (14%)]\tLoss: 8.898710, Loc Loss: 2.889402, Conf Loss: 6.009308\tIter time: 0.2619\n",
            "Training... Epoch: 1, Iter: 380,\t [12160/82081\t (15%)]\tLoss: 8.355288, Loc Loss: 2.624372, Conf Loss: 5.730915\tIter time: 0.2638\n",
            "Training... Epoch: 1, Iter: 390,\t [12480/82081\t (15%)]\tLoss: 8.448366, Loc Loss: 2.580475, Conf Loss: 5.867891\tIter time: 0.3037\n",
            "Training... Epoch: 1, Iter: 400,\t [12800/82081\t (16%)]\tLoss: 8.728115, Loc Loss: 2.506251, Conf Loss: 6.221863\tIter time: 0.2439\n",
            "Training... Epoch: 1, Iter: 410,\t [13120/82081\t (16%)]\tLoss: 8.702658, Loc Loss: 2.723182, Conf Loss: 5.979475\tIter time: 0.2438\n",
            "Training... Epoch: 1, Iter: 420,\t [13440/82081\t (16%)]\tLoss: 9.169638, Loc Loss: 2.721814, Conf Loss: 6.447824\tIter time: 0.2597\n",
            "Training... Epoch: 1, Iter: 430,\t [13760/82081\t (17%)]\tLoss: 8.517647, Loc Loss: 2.542405, Conf Loss: 5.975242\tIter time: 0.2707\n",
            "Training... Epoch: 1, Iter: 440,\t [14080/82081\t (17%)]\tLoss: 8.699243, Loc Loss: 2.893188, Conf Loss: 5.806055\tIter time: 0.2733\n",
            "Training... Epoch: 1, Iter: 450,\t [14400/82081\t (18%)]\tLoss: 8.585870, Loc Loss: 2.688021, Conf Loss: 5.897849\tIter time: 0.2702\n",
            "Training... Epoch: 1, Iter: 460,\t [14720/82081\t (18%)]\tLoss: 9.199244, Loc Loss: 2.807074, Conf Loss: 6.392171\tIter time: 0.2683\n",
            "Training... Epoch: 1, Iter: 470,\t [15040/82081\t (18%)]\tLoss: 8.478889, Loc Loss: 2.323021, Conf Loss: 6.155868\tIter time: 0.2453\n",
            "Training... Epoch: 1, Iter: 480,\t [15360/82081\t (19%)]\tLoss: 8.474714, Loc Loss: 2.713013, Conf Loss: 5.761702\tIter time: 0.2654\n",
            "Training... Epoch: 1, Iter: 490,\t [15680/82081\t (19%)]\tLoss: 8.534109, Loc Loss: 2.760893, Conf Loss: 5.773216\tIter time: 0.2775\n",
            "Training... Epoch: 1, Iter: 500,\t [16000/82081\t (19%)]\tLoss: 8.271810, Loc Loss: 2.649776, Conf Loss: 5.622034\tIter time: 0.2707\n",
            "Training... Epoch: 1, Iter: 510,\t [16320/82081\t (20%)]\tLoss: 8.792635, Loc Loss: 2.385346, Conf Loss: 6.407289\tIter time: 0.2682\n",
            "Training... Epoch: 1, Iter: 520,\t [16640/82081\t (20%)]\tLoss: 8.574416, Loc Loss: 2.597014, Conf Loss: 5.977402\tIter time: 0.2653\n",
            "Training... Epoch: 1, Iter: 530,\t [16960/82081\t (21%)]\tLoss: 8.424011, Loc Loss: 2.318543, Conf Loss: 6.105469\tIter time: 0.2560\n",
            "Training... Epoch: 1, Iter: 540,\t [17280/82081\t (21%)]\tLoss: 8.235065, Loc Loss: 2.462467, Conf Loss: 5.772597\tIter time: 0.2513\n",
            "Training... Epoch: 1, Iter: 550,\t [17600/82081\t (21%)]\tLoss: 8.547041, Loc Loss: 2.527878, Conf Loss: 6.019163\tIter time: 0.2457\n",
            "Training... Epoch: 1, Iter: 560,\t [17920/82081\t (22%)]\tLoss: 8.090305, Loc Loss: 2.532575, Conf Loss: 5.557731\tIter time: 0.2485\n",
            "Training... Epoch: 1, Iter: 570,\t [18240/82081\t (22%)]\tLoss: 8.711304, Loc Loss: 2.610994, Conf Loss: 6.100309\tIter time: 0.2603\n",
            "Training... Epoch: 1, Iter: 580,\t [18560/82081\t (23%)]\tLoss: 8.788838, Loc Loss: 2.654593, Conf Loss: 6.134245\tIter time: 0.2414\n",
            "Training... Epoch: 1, Iter: 590,\t [18880/82081\t (23%)]\tLoss: 9.064785, Loc Loss: 2.559984, Conf Loss: 6.504801\tIter time: 0.2675\n",
            "Training... Epoch: 1, Iter: 600,\t [19200/82081\t (23%)]\tLoss: 8.317997, Loc Loss: 2.631037, Conf Loss: 5.686960\tIter time: 0.2870\n",
            "Training... Epoch: 1, Iter: 610,\t [19520/82081\t (24%)]\tLoss: 8.105915, Loc Loss: 2.324741, Conf Loss: 5.781175\tIter time: 0.2803\n",
            "Training... Epoch: 1, Iter: 620,\t [19840/82081\t (24%)]\tLoss: 8.305540, Loc Loss: 2.345554, Conf Loss: 5.959986\tIter time: 0.2494\n",
            "Training... Epoch: 1, Iter: 630,\t [20160/82081\t (25%)]\tLoss: 8.860115, Loc Loss: 2.721267, Conf Loss: 6.138847\tIter time: 0.2600\n",
            "Training... Epoch: 1, Iter: 640,\t [20480/82081\t (25%)]\tLoss: 8.684771, Loc Loss: 2.391072, Conf Loss: 6.293699\tIter time: 0.2621\n",
            "Training... Epoch: 1, Iter: 650,\t [20800/82081\t (25%)]\tLoss: 8.810968, Loc Loss: 2.436171, Conf Loss: 6.374797\tIter time: 0.2644\n",
            "Training... Epoch: 1, Iter: 660,\t [21120/82081\t (26%)]\tLoss: 8.581249, Loc Loss: 2.709453, Conf Loss: 5.871797\tIter time: 0.2708\n",
            "Training... Epoch: 1, Iter: 670,\t [21440/82081\t (26%)]\tLoss: 8.072997, Loc Loss: 2.473392, Conf Loss: 5.599605\tIter time: 0.2735\n",
            "Training... Epoch: 1, Iter: 680,\t [21760/82081\t (27%)]\tLoss: 8.416261, Loc Loss: 2.454753, Conf Loss: 5.961508\tIter time: 0.2687\n",
            "Training... Epoch: 1, Iter: 690,\t [22080/82081\t (27%)]\tLoss: 8.177912, Loc Loss: 2.497331, Conf Loss: 5.680582\tIter time: 0.2700\n",
            "Training... Epoch: 1, Iter: 700,\t [22400/82081\t (27%)]\tLoss: 8.229456, Loc Loss: 2.522224, Conf Loss: 5.707232\tIter time: 0.2494\n",
            "Training... Epoch: 1, Iter: 710,\t [22720/82081\t (28%)]\tLoss: 8.014706, Loc Loss: 2.508553, Conf Loss: 5.506153\tIter time: 0.2799\n",
            "Training... Epoch: 1, Iter: 720,\t [23040/82081\t (28%)]\tLoss: 8.249666, Loc Loss: 2.291493, Conf Loss: 5.958173\tIter time: 0.2883\n",
            "Training... Epoch: 1, Iter: 730,\t [23360/82081\t (28%)]\tLoss: 7.890915, Loc Loss: 2.220087, Conf Loss: 5.670829\tIter time: 0.2593\n",
            "Training... Epoch: 1, Iter: 740,\t [23680/82081\t (29%)]\tLoss: 8.275736, Loc Loss: 2.348764, Conf Loss: 5.926971\tIter time: 0.2569\n",
            "Training... Epoch: 1, Iter: 750,\t [24000/82081\t (29%)]\tLoss: 8.332950, Loc Loss: 2.466950, Conf Loss: 5.866000\tIter time: 0.2677\n",
            "Training... Epoch: 1, Iter: 760,\t [24320/82081\t (30%)]\tLoss: 7.945511, Loc Loss: 2.385862, Conf Loss: 5.559649\tIter time: 0.2603\n",
            "Training... Epoch: 1, Iter: 770,\t [24640/82081\t (30%)]\tLoss: 7.844574, Loc Loss: 2.390197, Conf Loss: 5.454377\tIter time: 0.2895\n",
            "Training... Epoch: 1, Iter: 780,\t [24960/82081\t (30%)]\tLoss: 8.046872, Loc Loss: 2.620529, Conf Loss: 5.426343\tIter time: 0.2458\n",
            "Training... Epoch: 1, Iter: 790,\t [25280/82081\t (31%)]\tLoss: 7.908103, Loc Loss: 2.324043, Conf Loss: 5.584060\tIter time: 0.2429\n",
            "Training... Epoch: 1, Iter: 800,\t [25600/82081\t (31%)]\tLoss: 7.936239, Loc Loss: 2.164802, Conf Loss: 5.771438\tIter time: 0.2449\n",
            "Training... Epoch: 1, Iter: 810,\t [25920/82081\t (32%)]\tLoss: 8.071956, Loc Loss: 2.421897, Conf Loss: 5.650059\tIter time: 0.2451\n",
            "Training... Epoch: 1, Iter: 820,\t [26240/82081\t (32%)]\tLoss: 8.109543, Loc Loss: 2.730165, Conf Loss: 5.379377\tIter time: 0.2596\n",
            "Training... Epoch: 1, Iter: 830,\t [26560/82081\t (32%)]\tLoss: 8.411990, Loc Loss: 2.389438, Conf Loss: 6.022552\tIter time: 0.2629\n",
            "Training... Epoch: 1, Iter: 840,\t [26880/82081\t (33%)]\tLoss: 7.978050, Loc Loss: 2.348419, Conf Loss: 5.629632\tIter time: 0.2667\n",
            "Training... Epoch: 1, Iter: 850,\t [27200/82081\t (33%)]\tLoss: 7.620789, Loc Loss: 2.064520, Conf Loss: 5.556269\tIter time: 0.2518\n",
            "Training... Epoch: 1, Iter: 860,\t [27520/82081\t (34%)]\tLoss: 8.540281, Loc Loss: 2.796197, Conf Loss: 5.744084\tIter time: 0.2661\n",
            "Training... Epoch: 1, Iter: 870,\t [27840/82081\t (34%)]\tLoss: 8.539919, Loc Loss: 2.537031, Conf Loss: 6.002888\tIter time: 0.2474\n",
            "Training... Epoch: 1, Iter: 880,\t [28160/82081\t (34%)]\tLoss: 8.358099, Loc Loss: 2.386021, Conf Loss: 5.972078\tIter time: 0.2816\n",
            "Training... Epoch: 1, Iter: 890,\t [28480/82081\t (35%)]\tLoss: 7.831204, Loc Loss: 2.514702, Conf Loss: 5.316502\tIter time: 0.2483\n",
            "Training... Epoch: 1, Iter: 900,\t [28800/82081\t (35%)]\tLoss: 7.744158, Loc Loss: 2.555476, Conf Loss: 5.188682\tIter time: 0.2644\n",
            "Training... Epoch: 1, Iter: 910,\t [29120/82081\t (35%)]\tLoss: 7.885971, Loc Loss: 2.071454, Conf Loss: 5.814517\tIter time: 0.2594\n",
            "Training... Epoch: 1, Iter: 920,\t [29440/82081\t (36%)]\tLoss: 8.515237, Loc Loss: 2.345361, Conf Loss: 6.169877\tIter time: 0.2582\n",
            "Training... Epoch: 1, Iter: 930,\t [29760/82081\t (36%)]\tLoss: 7.893795, Loc Loss: 2.197553, Conf Loss: 5.696242\tIter time: 0.2611\n",
            "Training... Epoch: 1, Iter: 940,\t [30080/82081\t (37%)]\tLoss: 8.037610, Loc Loss: 2.712155, Conf Loss: 5.325455\tIter time: 0.2668\n",
            "Training... Epoch: 1, Iter: 950,\t [30400/82081\t (37%)]\tLoss: 8.078331, Loc Loss: 2.576792, Conf Loss: 5.501540\tIter time: 0.2953\n",
            "Training... Epoch: 1, Iter: 960,\t [30720/82081\t (37%)]\tLoss: 7.849510, Loc Loss: 2.543060, Conf Loss: 5.306450\tIter time: 0.2893\n",
            "Training... Epoch: 1, Iter: 970,\t [31040/82081\t (38%)]\tLoss: 8.092577, Loc Loss: 2.373911, Conf Loss: 5.718666\tIter time: 0.2694\n",
            "Training... Epoch: 1, Iter: 980,\t [31360/82081\t (38%)]\tLoss: 7.958961, Loc Loss: 2.342316, Conf Loss: 5.616645\tIter time: 0.2421\n",
            "Training... Epoch: 1, Iter: 990,\t [31680/82081\t (39%)]\tLoss: 8.182673, Loc Loss: 2.573069, Conf Loss: 5.609604\tIter time: 0.2487\n",
            "Training... Epoch: 1, Iter: 1000,\t [32000/82081\t (39%)]\tLoss: 8.002977, Loc Loss: 2.316911, Conf Loss: 5.686066\tIter time: 0.2625\n",
            "Training... Epoch: 1, Iter: 1010,\t [32320/82081\t (39%)]\tLoss: 8.260883, Loc Loss: 2.478868, Conf Loss: 5.782015\tIter time: 0.2702\n",
            "Training... Epoch: 1, Iter: 1020,\t [32640/82081\t (40%)]\tLoss: 7.883407, Loc Loss: 2.438077, Conf Loss: 5.445329\tIter time: 0.2687\n",
            "Training... Epoch: 1, Iter: 1030,\t [32960/82081\t (40%)]\tLoss: 7.794421, Loc Loss: 2.077484, Conf Loss: 5.716937\tIter time: 0.3020\n",
            "Training... Epoch: 1, Iter: 1040,\t [33280/82081\t (41%)]\tLoss: 7.463058, Loc Loss: 2.415523, Conf Loss: 5.047535\tIter time: 0.2856\n",
            "Training... Epoch: 1, Iter: 1050,\t [33600/82081\t (41%)]\tLoss: 8.258148, Loc Loss: 2.430278, Conf Loss: 5.827871\tIter time: 0.2584\n",
            "Training... Epoch: 1, Iter: 1060,\t [33920/82081\t (41%)]\tLoss: 7.355261, Loc Loss: 2.240113, Conf Loss: 5.115148\tIter time: 0.2634\n",
            "Training... Epoch: 1, Iter: 1070,\t [34240/82081\t (42%)]\tLoss: 8.194920, Loc Loss: 2.506344, Conf Loss: 5.688576\tIter time: 0.2488\n",
            "Training... Epoch: 1, Iter: 1080,\t [34560/82081\t (42%)]\tLoss: 8.369146, Loc Loss: 2.566170, Conf Loss: 5.802977\tIter time: 0.2511\n",
            "Training... Epoch: 1, Iter: 1090,\t [34880/82081\t (42%)]\tLoss: 7.830996, Loc Loss: 2.137499, Conf Loss: 5.693497\tIter time: 0.2709\n",
            "Training... Epoch: 1, Iter: 1100,\t [35200/82081\t (43%)]\tLoss: 8.005396, Loc Loss: 2.320912, Conf Loss: 5.684484\tIter time: 0.2547\n",
            "Training... Epoch: 1, Iter: 1110,\t [35520/82081\t (43%)]\tLoss: 8.082584, Loc Loss: 2.378548, Conf Loss: 5.704037\tIter time: 0.2605\n",
            "Training... Epoch: 1, Iter: 1120,\t [35840/82081\t (44%)]\tLoss: 7.964789, Loc Loss: 2.369327, Conf Loss: 5.595463\tIter time: 0.2705\n",
            "Training... Epoch: 1, Iter: 1130,\t [36160/82081\t (44%)]\tLoss: 7.887340, Loc Loss: 2.355105, Conf Loss: 5.532234\tIter time: 0.2555\n",
            "Training... Epoch: 1, Iter: 1140,\t [36480/82081\t (44%)]\tLoss: 7.981700, Loc Loss: 2.048212, Conf Loss: 5.933489\tIter time: 0.2633\n",
            "Training... Epoch: 1, Iter: 1150,\t [36800/82081\t (45%)]\tLoss: 8.216909, Loc Loss: 2.469047, Conf Loss: 5.747862\tIter time: 0.2444\n",
            "Training... Epoch: 1, Iter: 1160,\t [37120/82081\t (45%)]\tLoss: 8.000903, Loc Loss: 2.450598, Conf Loss: 5.550305\tIter time: 0.2465\n",
            "Training... Epoch: 1, Iter: 1170,\t [37440/82081\t (46%)]\tLoss: 7.530825, Loc Loss: 2.293602, Conf Loss: 5.237223\tIter time: 0.2663\n",
            "Training... Epoch: 1, Iter: 1180,\t [37760/82081\t (46%)]\tLoss: 8.009225, Loc Loss: 2.424199, Conf Loss: 5.585026\tIter time: 0.2656\n",
            "Training... Epoch: 1, Iter: 1190,\t [38080/82081\t (46%)]\tLoss: 7.961512, Loc Loss: 2.563726, Conf Loss: 5.397786\tIter time: 0.2642\n",
            "Training... Epoch: 1, Iter: 1200,\t [38400/82081\t (47%)]\tLoss: 8.327651, Loc Loss: 2.907307, Conf Loss: 5.420343\tIter time: 0.2500\n",
            "Training... Epoch: 1, Iter: 1210,\t [38720/82081\t (47%)]\tLoss: 7.594526, Loc Loss: 2.378051, Conf Loss: 5.216475\tIter time: 0.2706\n",
            "Training... Epoch: 1, Iter: 1220,\t [39040/82081\t (48%)]\tLoss: 7.766524, Loc Loss: 2.177820, Conf Loss: 5.588704\tIter time: 0.2649\n",
            "Training... Epoch: 1, Iter: 1230,\t [39360/82081\t (48%)]\tLoss: 7.258620, Loc Loss: 2.227997, Conf Loss: 5.030624\tIter time: 0.2698\n",
            "Training... Epoch: 1, Iter: 1240,\t [39680/82081\t (48%)]\tLoss: 7.811320, Loc Loss: 2.378746, Conf Loss: 5.432574\tIter time: 0.2708\n",
            "Training... Epoch: 1, Iter: 1250,\t [40000/82081\t (49%)]\tLoss: 7.853537, Loc Loss: 2.659778, Conf Loss: 5.193759\tIter time: 0.2894\n",
            "Training... Epoch: 1, Iter: 1260,\t [40320/82081\t (49%)]\tLoss: 7.758655, Loc Loss: 2.114425, Conf Loss: 5.644229\tIter time: 0.2407\n",
            "Training... Epoch: 1, Iter: 1270,\t [40640/82081\t (49%)]\tLoss: 7.464869, Loc Loss: 2.305465, Conf Loss: 5.159404\tIter time: 0.2903\n",
            "Training... Epoch: 1, Iter: 1280,\t [40960/82081\t (50%)]\tLoss: 8.007280, Loc Loss: 2.256659, Conf Loss: 5.750622\tIter time: 0.2778\n",
            "Training... Epoch: 1, Iter: 1290,\t [41280/82081\t (50%)]\tLoss: 8.290152, Loc Loss: 2.413606, Conf Loss: 5.876545\tIter time: 0.2506\n",
            "Training... Epoch: 1, Iter: 1300,\t [41600/82081\t (51%)]\tLoss: 7.904494, Loc Loss: 2.355986, Conf Loss: 5.548508\tIter time: 0.2736\n",
            "Training... Epoch: 1, Iter: 1310,\t [41920/82081\t (51%)]\tLoss: 7.683286, Loc Loss: 2.198757, Conf Loss: 5.484529\tIter time: 0.2649\n",
            "Training... Epoch: 1, Iter: 1320,\t [42240/82081\t (51%)]\tLoss: 7.775202, Loc Loss: 2.388212, Conf Loss: 5.386990\tIter time: 0.2560\n",
            "Training... Epoch: 1, Iter: 1330,\t [42560/82081\t (52%)]\tLoss: 8.012553, Loc Loss: 2.225069, Conf Loss: 5.787484\tIter time: 0.2575\n",
            "Training... Epoch: 1, Iter: 1340,\t [42880/82081\t (52%)]\tLoss: 7.574564, Loc Loss: 2.322207, Conf Loss: 5.252357\tIter time: 0.2677\n",
            "Training... Epoch: 1, Iter: 1350,\t [43200/82081\t (53%)]\tLoss: 7.718815, Loc Loss: 2.302846, Conf Loss: 5.415968\tIter time: 0.2615\n",
            "Training... Epoch: 1, Iter: 1360,\t [43520/82081\t (53%)]\tLoss: 7.959848, Loc Loss: 2.589646, Conf Loss: 5.370203\tIter time: 0.3005\n",
            "Training... Epoch: 1, Iter: 1370,\t [43840/82081\t (53%)]\tLoss: 7.397130, Loc Loss: 2.236029, Conf Loss: 5.161101\tIter time: 0.2544\n",
            "Training... Epoch: 1, Iter: 1380,\t [44160/82081\t (54%)]\tLoss: 7.762433, Loc Loss: 2.361358, Conf Loss: 5.401075\tIter time: 0.2624\n",
            "Training... Epoch: 1, Iter: 1390,\t [44480/82081\t (54%)]\tLoss: 7.902392, Loc Loss: 2.094278, Conf Loss: 5.808115\tIter time: 0.2654\n",
            "Training... Epoch: 1, Iter: 1400,\t [44800/82081\t (55%)]\tLoss: 8.003244, Loc Loss: 2.200408, Conf Loss: 5.802837\tIter time: 0.2411\n",
            "Training... Epoch: 1, Iter: 1410,\t [45120/82081\t (55%)]\tLoss: 6.956101, Loc Loss: 1.959902, Conf Loss: 4.996199\tIter time: 0.2698\n",
            "Training... Epoch: 1, Iter: 1420,\t [45440/82081\t (55%)]\tLoss: 8.162373, Loc Loss: 2.559911, Conf Loss: 5.602462\tIter time: 0.2464\n",
            "Training... Epoch: 1, Iter: 1430,\t [45760/82081\t (56%)]\tLoss: 8.255005, Loc Loss: 2.489100, Conf Loss: 5.765905\tIter time: 0.2733\n",
            "Training... Epoch: 1, Iter: 1440,\t [46080/82081\t (56%)]\tLoss: 7.547234, Loc Loss: 2.324862, Conf Loss: 5.222371\tIter time: 0.2650\n",
            "Training... Epoch: 1, Iter: 1450,\t [46400/82081\t (57%)]\tLoss: 8.046354, Loc Loss: 2.095767, Conf Loss: 5.950587\tIter time: 0.2511\n",
            "Training... Epoch: 1, Iter: 1460,\t [46720/82081\t (57%)]\tLoss: 7.488886, Loc Loss: 2.228781, Conf Loss: 5.260105\tIter time: 0.2416\n",
            "Training... Epoch: 1, Iter: 1470,\t [47040/82081\t (57%)]\tLoss: 7.858393, Loc Loss: 2.171121, Conf Loss: 5.687272\tIter time: 0.2619\n",
            "Training... Epoch: 1, Iter: 1480,\t [47360/82081\t (58%)]\tLoss: 7.541343, Loc Loss: 2.012347, Conf Loss: 5.528996\tIter time: 0.2620\n",
            "Training... Epoch: 1, Iter: 1490,\t [47680/82081\t (58%)]\tLoss: 7.923683, Loc Loss: 2.127664, Conf Loss: 5.796020\tIter time: 0.2671\n",
            "Training... Epoch: 1, Iter: 1500,\t [48000/82081\t (58%)]\tLoss: 7.321952, Loc Loss: 2.118992, Conf Loss: 5.202960\tIter time: 0.2637\n",
            "Training... Epoch: 1, Iter: 1510,\t [48320/82081\t (59%)]\tLoss: 7.657960, Loc Loss: 2.360411, Conf Loss: 5.297549\tIter time: 0.2776\n",
            "Training... Epoch: 1, Iter: 1520,\t [48640/82081\t (59%)]\tLoss: 7.994054, Loc Loss: 2.209161, Conf Loss: 5.784894\tIter time: 0.2451\n",
            "Training... Epoch: 1, Iter: 1530,\t [48960/82081\t (60%)]\tLoss: 7.890656, Loc Loss: 2.447527, Conf Loss: 5.443130\tIter time: 0.2732\n",
            "Training... Epoch: 1, Iter: 1540,\t [49280/82081\t (60%)]\tLoss: 7.415529, Loc Loss: 2.137774, Conf Loss: 5.277755\tIter time: 0.2625\n",
            "Training... Epoch: 1, Iter: 1550,\t [49600/82081\t (60%)]\tLoss: 8.244626, Loc Loss: 2.353748, Conf Loss: 5.890878\tIter time: 0.2637\n",
            "Training... Epoch: 1, Iter: 1560,\t [49920/82081\t (61%)]\tLoss: 7.799555, Loc Loss: 2.571279, Conf Loss: 5.228276\tIter time: 0.2422\n",
            "Training... Epoch: 1, Iter: 1570,\t [50240/82081\t (61%)]\tLoss: 7.269900, Loc Loss: 2.007787, Conf Loss: 5.262113\tIter time: 0.2611\n",
            "Training... Epoch: 1, Iter: 1580,\t [50560/82081\t (62%)]\tLoss: 7.847086, Loc Loss: 2.060897, Conf Loss: 5.786189\tIter time: 0.2479\n",
            "Training... Epoch: 1, Iter: 1590,\t [50880/82081\t (62%)]\tLoss: 7.673938, Loc Loss: 1.987396, Conf Loss: 5.686542\tIter time: 0.2659\n",
            "Training... Epoch: 1, Iter: 1600,\t [51200/82081\t (62%)]\tLoss: 7.504073, Loc Loss: 2.341361, Conf Loss: 5.162712\tIter time: 0.2692\n",
            "Training... Epoch: 1, Iter: 1610,\t [51520/82081\t (63%)]\tLoss: 7.164453, Loc Loss: 2.169812, Conf Loss: 4.994641\tIter time: 0.2526\n",
            "Training... Epoch: 1, Iter: 1620,\t [51840/82081\t (63%)]\tLoss: 7.705890, Loc Loss: 2.216091, Conf Loss: 5.489799\tIter time: 0.2633\n",
            "Training... Epoch: 1, Iter: 1630,\t [52160/82081\t (64%)]\tLoss: 7.579905, Loc Loss: 2.081063, Conf Loss: 5.498842\tIter time: 0.2692\n",
            "Training... Epoch: 1, Iter: 1640,\t [52480/82081\t (64%)]\tLoss: 7.712064, Loc Loss: 2.244105, Conf Loss: 5.467959\tIter time: 0.2445\n",
            "Training... Epoch: 1, Iter: 1650,\t [52800/82081\t (64%)]\tLoss: 7.959112, Loc Loss: 2.205791, Conf Loss: 5.753321\tIter time: 0.2454\n",
            "Training... Epoch: 1, Iter: 1660,\t [53120/82081\t (65%)]\tLoss: 6.915959, Loc Loss: 2.138805, Conf Loss: 4.777155\tIter time: 0.2854\n",
            "Training... Epoch: 1, Iter: 1670,\t [53440/82081\t (65%)]\tLoss: 7.244478, Loc Loss: 2.213453, Conf Loss: 5.031024\tIter time: 0.2860\n",
            "Training... Epoch: 1, Iter: 1680,\t [53760/82081\t (65%)]\tLoss: 7.921050, Loc Loss: 2.519770, Conf Loss: 5.401280\tIter time: 0.2765\n",
            "Training... Epoch: 1, Iter: 1690,\t [54080/82081\t (66%)]\tLoss: 7.746842, Loc Loss: 2.057822, Conf Loss: 5.689020\tIter time: 0.2599\n",
            "Training... Epoch: 1, Iter: 1700,\t [54400/82081\t (66%)]\tLoss: 6.963984, Loc Loss: 2.071814, Conf Loss: 4.892170\tIter time: 0.2524\n",
            "Training... Epoch: 1, Iter: 1710,\t [54720/82081\t (67%)]\tLoss: 7.599625, Loc Loss: 2.003748, Conf Loss: 5.595877\tIter time: 0.2593\n",
            "Training... Epoch: 1, Iter: 1720,\t [55040/82081\t (67%)]\tLoss: 7.447496, Loc Loss: 2.038844, Conf Loss: 5.408652\tIter time: 0.2432\n",
            "Training... Epoch: 1, Iter: 1730,\t [55360/82081\t (67%)]\tLoss: 7.594469, Loc Loss: 2.283489, Conf Loss: 5.310980\tIter time: 0.2734\n",
            "Training... Epoch: 1, Iter: 1740,\t [55680/82081\t (68%)]\tLoss: 7.207438, Loc Loss: 2.000816, Conf Loss: 5.206622\tIter time: 0.2672\n",
            "Training... Epoch: 1, Iter: 1750,\t [56000/82081\t (68%)]\tLoss: 8.170987, Loc Loss: 2.516347, Conf Loss: 5.654640\tIter time: 0.2638\n",
            "Training... Epoch: 1, Iter: 1760,\t [56320/82081\t (69%)]\tLoss: 7.685085, Loc Loss: 2.198863, Conf Loss: 5.486222\tIter time: 0.2522\n",
            "Training... Epoch: 1, Iter: 1770,\t [56640/82081\t (69%)]\tLoss: 7.423207, Loc Loss: 2.090787, Conf Loss: 5.332420\tIter time: 0.2556\n",
            "Training... Epoch: 1, Iter: 1780,\t [56960/82081\t (69%)]\tLoss: 6.902650, Loc Loss: 2.020292, Conf Loss: 4.882358\tIter time: 0.2446\n",
            "Training... Epoch: 1, Iter: 1790,\t [57280/82081\t (70%)]\tLoss: 7.687632, Loc Loss: 2.242884, Conf Loss: 5.444747\tIter time: 0.2880\n",
            "Training... Epoch: 1, Iter: 1800,\t [57600/82081\t (70%)]\tLoss: 7.109677, Loc Loss: 2.148239, Conf Loss: 4.961438\tIter time: 0.2603\n",
            "Training... Epoch: 1, Iter: 1810,\t [57920/82081\t (71%)]\tLoss: 7.215092, Loc Loss: 2.141850, Conf Loss: 5.073242\tIter time: 0.2678\n",
            "Training... Epoch: 1, Iter: 1820,\t [58240/82081\t (71%)]\tLoss: 8.022001, Loc Loss: 2.235528, Conf Loss: 5.786474\tIter time: 0.2525\n",
            "Training... Epoch: 1, Iter: 1830,\t [58560/82081\t (71%)]\tLoss: 7.530918, Loc Loss: 2.293699, Conf Loss: 5.237218\tIter time: 0.2645\n",
            "Training... Epoch: 1, Iter: 1840,\t [58880/82081\t (72%)]\tLoss: 7.485902, Loc Loss: 2.007491, Conf Loss: 5.478411\tIter time: 0.2601\n",
            "Training... Epoch: 1, Iter: 1850,\t [59200/82081\t (72%)]\tLoss: 7.326941, Loc Loss: 2.155069, Conf Loss: 5.171872\tIter time: 0.2667\n",
            "Training... Epoch: 1, Iter: 1860,\t [59520/82081\t (72%)]\tLoss: 7.555242, Loc Loss: 2.039985, Conf Loss: 5.515257\tIter time: 0.2717\n",
            "Training... Epoch: 1, Iter: 1870,\t [59840/82081\t (73%)]\tLoss: 7.424991, Loc Loss: 2.238547, Conf Loss: 5.186443\tIter time: 0.2608\n",
            "Training... Epoch: 1, Iter: 1880,\t [60160/82081\t (73%)]\tLoss: 7.697200, Loc Loss: 2.401355, Conf Loss: 5.295846\tIter time: 0.2904\n",
            "Training... Epoch: 1, Iter: 1890,\t [60480/82081\t (74%)]\tLoss: 7.271020, Loc Loss: 2.067018, Conf Loss: 5.204002\tIter time: 0.2904\n",
            "Training... Epoch: 1, Iter: 1900,\t [60800/82081\t (74%)]\tLoss: 6.806087, Loc Loss: 2.084772, Conf Loss: 4.721315\tIter time: 0.2813\n",
            "Training... Epoch: 1, Iter: 1910,\t [61120/82081\t (74%)]\tLoss: 7.609084, Loc Loss: 1.991508, Conf Loss: 5.617576\tIter time: 0.2675\n",
            "Training... Epoch: 1, Iter: 1920,\t [61440/82081\t (75%)]\tLoss: 7.423593, Loc Loss: 2.091876, Conf Loss: 5.331717\tIter time: 0.2763\n",
            "Training... Epoch: 1, Iter: 1930,\t [61760/82081\t (75%)]\tLoss: 7.838752, Loc Loss: 2.251097, Conf Loss: 5.587655\tIter time: 0.2506\n",
            "Training... Epoch: 1, Iter: 1940,\t [62080/82081\t (76%)]\tLoss: 7.413360, Loc Loss: 2.370975, Conf Loss: 5.042385\tIter time: 0.2454\n",
            "Training... Epoch: 1, Iter: 1950,\t [62400/82081\t (76%)]\tLoss: 7.406413, Loc Loss: 2.234084, Conf Loss: 5.172329\tIter time: 0.2448\n",
            "Training... Epoch: 1, Iter: 1960,\t [62720/82081\t (76%)]\tLoss: 6.906375, Loc Loss: 2.188189, Conf Loss: 4.718186\tIter time: 0.2929\n",
            "Training... Epoch: 1, Iter: 1970,\t [63040/82081\t (77%)]\tLoss: 7.431500, Loc Loss: 2.087796, Conf Loss: 5.343704\tIter time: 0.2500\n",
            "Training... Epoch: 1, Iter: 1980,\t [63360/82081\t (77%)]\tLoss: 7.768600, Loc Loss: 2.225199, Conf Loss: 5.543402\tIter time: 0.2609\n",
            "Training... Epoch: 1, Iter: 1990,\t [63680/82081\t (78%)]\tLoss: 7.693972, Loc Loss: 2.222531, Conf Loss: 5.471440\tIter time: 0.2548\n",
            "Training... Epoch: 1, Iter: 2000,\t [64000/82081\t (78%)]\tLoss: 7.103636, Loc Loss: 2.204427, Conf Loss: 4.899208\tIter time: 0.2610\n",
            "Training... Epoch: 1, Iter: 2010,\t [64320/82081\t (78%)]\tLoss: 8.113484, Loc Loss: 2.505188, Conf Loss: 5.608296\tIter time: 0.2437\n",
            "Training... Epoch: 1, Iter: 2020,\t [64640/82081\t (79%)]\tLoss: 7.238025, Loc Loss: 2.074484, Conf Loss: 5.163541\tIter time: 0.2487\n",
            "Training... Epoch: 1, Iter: 2030,\t [64960/82081\t (79%)]\tLoss: 7.154451, Loc Loss: 2.122729, Conf Loss: 5.031722\tIter time: 0.2708\n",
            "Training... Epoch: 1, Iter: 2040,\t [65280/82081\t (80%)]\tLoss: 7.293268, Loc Loss: 2.077298, Conf Loss: 5.215971\tIter time: 0.2594\n",
            "Training... Epoch: 1, Iter: 2050,\t [65600/82081\t (80%)]\tLoss: 7.385365, Loc Loss: 2.182331, Conf Loss: 5.203034\tIter time: 0.2563\n",
            "Training... Epoch: 1, Iter: 2060,\t [65920/82081\t (80%)]\tLoss: 7.377244, Loc Loss: 2.258805, Conf Loss: 5.118439\tIter time: 0.2624\n",
            "Training... Epoch: 1, Iter: 2070,\t [66240/82081\t (81%)]\tLoss: 7.180428, Loc Loss: 2.178093, Conf Loss: 5.002335\tIter time: 0.2575\n",
            "Training... Epoch: 1, Iter: 2080,\t [66560/82081\t (81%)]\tLoss: 7.452113, Loc Loss: 2.218581, Conf Loss: 5.233532\tIter time: 0.2601\n",
            "Training... Epoch: 1, Iter: 2090,\t [66880/82081\t (81%)]\tLoss: 7.321717, Loc Loss: 2.115949, Conf Loss: 5.205769\tIter time: 0.2416\n",
            "Training... Epoch: 1, Iter: 2100,\t [67200/82081\t (82%)]\tLoss: 7.144631, Loc Loss: 2.258130, Conf Loss: 4.886501\tIter time: 0.2727\n",
            "Training... Epoch: 1, Iter: 2110,\t [67520/82081\t (82%)]\tLoss: 7.320380, Loc Loss: 2.359541, Conf Loss: 4.960838\tIter time: 0.2731\n",
            "Training... Epoch: 1, Iter: 2120,\t [67840/82081\t (83%)]\tLoss: 7.269395, Loc Loss: 2.354336, Conf Loss: 4.915060\tIter time: 0.2579\n",
            "Training... Epoch: 1, Iter: 2130,\t [68160/82081\t (83%)]\tLoss: 7.389038, Loc Loss: 2.074734, Conf Loss: 5.314303\tIter time: 0.2577\n",
            "Training... Epoch: 1, Iter: 2140,\t [68480/82081\t (83%)]\tLoss: 7.373386, Loc Loss: 2.257418, Conf Loss: 5.115968\tIter time: 0.2724\n",
            "Training... Epoch: 1, Iter: 2150,\t [68800/82081\t (84%)]\tLoss: 7.279405, Loc Loss: 1.987074, Conf Loss: 5.292331\tIter time: 0.2471\n",
            "Training... Epoch: 1, Iter: 2160,\t [69120/82081\t (84%)]\tLoss: 7.254666, Loc Loss: 2.104779, Conf Loss: 5.149887\tIter time: 0.2542\n",
            "Training... Epoch: 1, Iter: 2170,\t [69440/82081\t (85%)]\tLoss: 7.305429, Loc Loss: 1.956057, Conf Loss: 5.349372\tIter time: 0.2527\n",
            "Training... Epoch: 1, Iter: 2180,\t [69760/82081\t (85%)]\tLoss: 7.483590, Loc Loss: 2.246882, Conf Loss: 5.236709\tIter time: 0.2689\n",
            "Training... Epoch: 1, Iter: 2190,\t [70080/82081\t (85%)]\tLoss: 7.472445, Loc Loss: 2.274579, Conf Loss: 5.197866\tIter time: 0.2637\n",
            "Training... Epoch: 1, Iter: 2200,\t [70400/82081\t (86%)]\tLoss: 6.916866, Loc Loss: 1.908867, Conf Loss: 5.007999\tIter time: 0.2442\n",
            "Training... Epoch: 1, Iter: 2210,\t [70720/82081\t (86%)]\tLoss: 7.030080, Loc Loss: 1.934450, Conf Loss: 5.095630\tIter time: 0.2708\n",
            "Training... Epoch: 1, Iter: 2220,\t [71040/82081\t (87%)]\tLoss: 7.205834, Loc Loss: 2.155117, Conf Loss: 5.050717\tIter time: 0.2802\n",
            "Training... Epoch: 1, Iter: 2230,\t [71360/82081\t (87%)]\tLoss: 7.296195, Loc Loss: 1.923392, Conf Loss: 5.372802\tIter time: 0.2598\n",
            "Training... Epoch: 1, Iter: 2240,\t [71680/82081\t (87%)]\tLoss: 7.615252, Loc Loss: 2.278509, Conf Loss: 5.336743\tIter time: 0.2467\n",
            "Training... Epoch: 1, Iter: 2250,\t [72000/82081\t (88%)]\tLoss: 7.529580, Loc Loss: 2.145854, Conf Loss: 5.383726\tIter time: 0.2664\n",
            "Training... Epoch: 1, Iter: 2260,\t [72320/82081\t (88%)]\tLoss: 7.382767, Loc Loss: 2.007179, Conf Loss: 5.375588\tIter time: 0.2721\n",
            "Training... Epoch: 1, Iter: 2270,\t [72640/82081\t (88%)]\tLoss: 7.711363, Loc Loss: 2.220004, Conf Loss: 5.491359\tIter time: 0.2621\n",
            "Training... Epoch: 1, Iter: 2280,\t [72960/82081\t (89%)]\tLoss: 7.587309, Loc Loss: 2.032687, Conf Loss: 5.554623\tIter time: 0.2732\n",
            "Training... Epoch: 1, Iter: 2290,\t [73280/82081\t (89%)]\tLoss: 7.124865, Loc Loss: 2.104990, Conf Loss: 5.019875\tIter time: 0.2935\n",
            "Training... Epoch: 1, Iter: 2300,\t [73600/82081\t (90%)]\tLoss: 7.014874, Loc Loss: 2.097397, Conf Loss: 4.917477\tIter time: 0.2570\n",
            "Training... Epoch: 1, Iter: 2310,\t [73920/82081\t (90%)]\tLoss: 6.878379, Loc Loss: 2.145618, Conf Loss: 4.732761\tIter time: 0.2658\n",
            "Training... Epoch: 1, Iter: 2320,\t [74240/82081\t (90%)]\tLoss: 7.389609, Loc Loss: 2.197057, Conf Loss: 5.192552\tIter time: 0.2873\n",
            "Training... Epoch: 1, Iter: 2330,\t [74560/82081\t (91%)]\tLoss: 7.226079, Loc Loss: 1.959128, Conf Loss: 5.266950\tIter time: 0.2641\n",
            "Training... Epoch: 1, Iter: 2340,\t [74880/82081\t (91%)]\tLoss: 7.216714, Loc Loss: 2.090059, Conf Loss: 5.126655\tIter time: 0.2662\n",
            "Training... Epoch: 1, Iter: 2350,\t [75200/82081\t (92%)]\tLoss: 7.692722, Loc Loss: 2.401112, Conf Loss: 5.291611\tIter time: 0.2599\n",
            "Training... Epoch: 1, Iter: 2360,\t [75520/82081\t (92%)]\tLoss: 7.380004, Loc Loss: 2.234277, Conf Loss: 5.145727\tIter time: 0.2663\n",
            "Training... Epoch: 1, Iter: 2370,\t [75840/82081\t (92%)]\tLoss: 7.424906, Loc Loss: 2.283786, Conf Loss: 5.141120\tIter time: 0.2944\n",
            "Training... Epoch: 1, Iter: 2380,\t [76160/82081\t (93%)]\tLoss: 6.880046, Loc Loss: 1.839067, Conf Loss: 5.040979\tIter time: 0.2398\n",
            "Training... Epoch: 1, Iter: 2390,\t [76480/82081\t (93%)]\tLoss: 7.379599, Loc Loss: 2.203791, Conf Loss: 5.175807\tIter time: 0.2463\n",
            "Training... Epoch: 1, Iter: 2400,\t [76800/82081\t (94%)]\tLoss: 6.888089, Loc Loss: 2.058023, Conf Loss: 4.830066\tIter time: 0.2611\n",
            "Training... Epoch: 1, Iter: 2410,\t [77120/82081\t (94%)]\tLoss: 6.858368, Loc Loss: 1.963851, Conf Loss: 4.894517\tIter time: 0.2653\n",
            "Training... Epoch: 1, Iter: 2420,\t [77440/82081\t (94%)]\tLoss: 7.177531, Loc Loss: 2.160127, Conf Loss: 5.017405\tIter time: 0.2659\n",
            "Training... Epoch: 1, Iter: 2430,\t [77760/82081\t (95%)]\tLoss: 7.185148, Loc Loss: 2.019331, Conf Loss: 5.165817\tIter time: 0.2598\n",
            "Training... Epoch: 1, Iter: 2440,\t [78080/82081\t (95%)]\tLoss: 7.508365, Loc Loss: 2.227965, Conf Loss: 5.280400\tIter time: 0.2537\n",
            "Training... Epoch: 1, Iter: 2450,\t [78400/82081\t (95%)]\tLoss: 7.718897, Loc Loss: 2.205533, Conf Loss: 5.513364\tIter time: 0.2743\n",
            "Training... Epoch: 1, Iter: 2460,\t [78720/82081\t (96%)]\tLoss: 7.282714, Loc Loss: 2.246941, Conf Loss: 5.035773\tIter time: 0.2591\n",
            "Training... Epoch: 1, Iter: 2470,\t [79040/82081\t (96%)]\tLoss: 7.361259, Loc Loss: 2.073218, Conf Loss: 5.288042\tIter time: 0.2482\n",
            "Training... Epoch: 1, Iter: 2480,\t [79360/82081\t (97%)]\tLoss: 7.275057, Loc Loss: 2.195913, Conf Loss: 5.079144\tIter time: 0.2922\n",
            "Training... Epoch: 1, Iter: 2490,\t [79680/82081\t (97%)]\tLoss: 7.204621, Loc Loss: 2.112343, Conf Loss: 5.092278\tIter time: 0.2632\n",
            "Training... Epoch: 1, Iter: 2500,\t [80000/82081\t (97%)]\tLoss: 7.390747, Loc Loss: 2.354963, Conf Loss: 5.035784\tIter time: 0.2582\n",
            "Training... Epoch: 1, Iter: 2510,\t [80320/82081\t (98%)]\tLoss: 7.067019, Loc Loss: 1.862867, Conf Loss: 5.204151\tIter time: 0.2620\n",
            "Training... Epoch: 1, Iter: 2520,\t [80640/82081\t (98%)]\tLoss: 7.162120, Loc Loss: 1.900568, Conf Loss: 5.261552\tIter time: 0.2783\n",
            "Training... Epoch: 1, Iter: 2530,\t [80960/82081\t (99%)]\tLoss: 7.054788, Loc Loss: 1.977938, Conf Loss: 5.076850\tIter time: 0.2605\n",
            "Training... Epoch: 1, Iter: 2540,\t [81280/82081\t (99%)]\tLoss: 7.158698, Loc Loss: 2.296921, Conf Loss: 4.861777\tIter time: 0.2679\n",
            "Training... Epoch: 1, Iter: 2550,\t [81600/82081\t (99%)]\tLoss: 7.254622, Loc Loss: 2.133924, Conf Loss: 5.120698\tIter time: 0.2478\n",
            "Training... Epoch: 1, Iter: 2560,\t [81920/82081\t (100%)]\tLoss: 7.478256, Loc Loss: 2.196155, Conf Loss: 5.282102\tIter time: 0.2413\n",
            "Training... Epoch: 2, Iter: 2570,\t [128/82081\t (0%)]\tLoss: 7.643237, Loc Loss: 2.047705, Conf Loss: 5.595532\tIter time: 0.3554\n",
            "Training... Epoch: 2, Iter: 2580,\t [448/82081\t (1%)]\tLoss: 7.861081, Loc Loss: 2.240887, Conf Loss: 5.620194\tIter time: 0.2438\n",
            "Training... Epoch: 2, Iter: 2590,\t [768/82081\t (1%)]\tLoss: 7.876295, Loc Loss: 2.247031, Conf Loss: 5.629264\tIter time: 0.2496\n",
            "Training... Epoch: 2, Iter: 2600,\t [1088/82081\t (1%)]\tLoss: 7.403036, Loc Loss: 2.039328, Conf Loss: 5.363708\tIter time: 0.2534\n",
            "Training... Epoch: 2, Iter: 2610,\t [1408/82081\t (2%)]\tLoss: 6.873656, Loc Loss: 1.886079, Conf Loss: 4.987576\tIter time: 0.2651\n",
            "Training... Epoch: 2, Iter: 2620,\t [1728/82081\t (2%)]\tLoss: 7.020878, Loc Loss: 2.077488, Conf Loss: 4.943390\tIter time: 0.2808\n",
            "Training... Epoch: 2, Iter: 2630,\t [2048/82081\t (2%)]\tLoss: 6.931356, Loc Loss: 2.033024, Conf Loss: 4.898333\tIter time: 0.2850\n",
            "Training... Epoch: 2, Iter: 2640,\t [2368/82081\t (3%)]\tLoss: 7.530970, Loc Loss: 2.255367, Conf Loss: 5.275603\tIter time: 0.2932\n",
            "Training... Epoch: 2, Iter: 2650,\t [2688/82081\t (3%)]\tLoss: 7.197208, Loc Loss: 2.117852, Conf Loss: 5.079356\tIter time: 0.2519\n",
            "Training... Epoch: 2, Iter: 2660,\t [3008/82081\t (4%)]\tLoss: 7.656073, Loc Loss: 2.246675, Conf Loss: 5.409398\tIter time: 0.2612\n",
            "Training... Epoch: 2, Iter: 2670,\t [3328/82081\t (4%)]\tLoss: 6.915813, Loc Loss: 1.871666, Conf Loss: 5.044147\tIter time: 0.2489\n",
            "Training... Epoch: 2, Iter: 2680,\t [3648/82081\t (4%)]\tLoss: 7.118267, Loc Loss: 2.469697, Conf Loss: 4.648570\tIter time: 0.2686\n",
            "Training... Epoch: 2, Iter: 2690,\t [3968/82081\t (5%)]\tLoss: 7.260092, Loc Loss: 1.957616, Conf Loss: 5.302475\tIter time: 0.2423\n",
            "Training... Epoch: 2, Iter: 2700,\t [4288/82081\t (5%)]\tLoss: 7.540363, Loc Loss: 2.492857, Conf Loss: 5.047506\tIter time: 0.2768\n",
            "Training... Epoch: 2, Iter: 2710,\t [4608/82081\t (6%)]\tLoss: 7.281299, Loc Loss: 2.044765, Conf Loss: 5.236534\tIter time: 0.2567\n",
            "Training... Epoch: 2, Iter: 2720,\t [4928/82081\t (6%)]\tLoss: 7.203670, Loc Loss: 2.334116, Conf Loss: 4.869554\tIter time: 0.2764\n",
            "Training... Epoch: 2, Iter: 2730,\t [5248/82081\t (6%)]\tLoss: 7.369852, Loc Loss: 2.228818, Conf Loss: 5.141034\tIter time: 0.2661\n",
            "Training... Epoch: 2, Iter: 2740,\t [5568/82081\t (7%)]\tLoss: 7.548727, Loc Loss: 2.144300, Conf Loss: 5.404427\tIter time: 0.2583\n",
            "Training... Epoch: 2, Iter: 2750,\t [5888/82081\t (7%)]\tLoss: 7.193444, Loc Loss: 1.961557, Conf Loss: 5.231887\tIter time: 0.2743\n",
            "Training... Epoch: 2, Iter: 2760,\t [6208/82081\t (8%)]\tLoss: 6.936222, Loc Loss: 2.062647, Conf Loss: 4.873575\tIter time: 0.2660\n",
            "Training... Epoch: 2, Iter: 2770,\t [6528/82081\t (8%)]\tLoss: 7.390473, Loc Loss: 2.092218, Conf Loss: 5.298255\tIter time: 0.2749\n",
            "Training... Epoch: 2, Iter: 2780,\t [6848/82081\t (8%)]\tLoss: 7.432469, Loc Loss: 2.259765, Conf Loss: 5.172704\tIter time: 0.2603\n",
            "Training... Epoch: 2, Iter: 2790,\t [7168/82081\t (9%)]\tLoss: 6.996232, Loc Loss: 2.164362, Conf Loss: 4.831871\tIter time: 0.2669\n",
            "Training... Epoch: 2, Iter: 2800,\t [7488/82081\t (9%)]\tLoss: 7.294089, Loc Loss: 2.415118, Conf Loss: 4.878971\tIter time: 0.2706\n",
            "Training... Epoch: 2, Iter: 2810,\t [7808/82081\t (10%)]\tLoss: 7.224104, Loc Loss: 2.374542, Conf Loss: 4.849562\tIter time: 0.2702\n",
            "Training... Epoch: 2, Iter: 2820,\t [8128/82081\t (10%)]\tLoss: 7.653591, Loc Loss: 2.323201, Conf Loss: 5.330390\tIter time: 0.2676\n",
            "Training... Epoch: 2, Iter: 2830,\t [8448/82081\t (10%)]\tLoss: 6.860445, Loc Loss: 2.048361, Conf Loss: 4.812084\tIter time: 0.2637\n",
            "Training... Epoch: 2, Iter: 2840,\t [8768/82081\t (11%)]\tLoss: 7.664792, Loc Loss: 2.636900, Conf Loss: 5.027892\tIter time: 0.2622\n",
            "Training... Epoch: 2, Iter: 2850,\t [9088/82081\t (11%)]\tLoss: 7.157861, Loc Loss: 2.163280, Conf Loss: 4.994581\tIter time: 0.2541\n",
            "Training... Epoch: 2, Iter: 2860,\t [9408/82081\t (11%)]\tLoss: 7.044577, Loc Loss: 2.152742, Conf Loss: 4.891835\tIter time: 0.2664\n",
            "Training... Epoch: 2, Iter: 2870,\t [9728/82081\t (12%)]\tLoss: 7.043965, Loc Loss: 2.186099, Conf Loss: 4.857866\tIter time: 0.2685\n",
            "Training... Epoch: 2, Iter: 2880,\t [10048/82081\t (12%)]\tLoss: 7.379830, Loc Loss: 2.348080, Conf Loss: 5.031750\tIter time: 0.2692\n",
            "Training... Epoch: 2, Iter: 2890,\t [10368/82081\t (13%)]\tLoss: 6.839041, Loc Loss: 1.957199, Conf Loss: 4.881842\tIter time: 0.2773\n",
            "Training... Epoch: 2, Iter: 2900,\t [10688/82081\t (13%)]\tLoss: 7.678912, Loc Loss: 2.342408, Conf Loss: 5.336504\tIter time: 0.2688\n",
            "Training... Epoch: 2, Iter: 2910,\t [11008/82081\t (13%)]\tLoss: 6.944754, Loc Loss: 1.887406, Conf Loss: 5.057348\tIter time: 0.2580\n",
            "Training... Epoch: 2, Iter: 2920,\t [11328/82081\t (14%)]\tLoss: 7.102437, Loc Loss: 1.911205, Conf Loss: 5.191232\tIter time: 0.2880\n",
            "Training... Epoch: 2, Iter: 2930,\t [11648/82081\t (14%)]\tLoss: 7.504057, Loc Loss: 2.215548, Conf Loss: 5.288509\tIter time: 0.2458\n",
            "Training... Epoch: 2, Iter: 2940,\t [11968/82081\t (15%)]\tLoss: 7.250359, Loc Loss: 2.096476, Conf Loss: 5.153882\tIter time: 0.2449\n",
            "Training... Epoch: 2, Iter: 2950,\t [12288/82081\t (15%)]\tLoss: 7.339774, Loc Loss: 2.019736, Conf Loss: 5.320039\tIter time: 0.2431\n",
            "Training... Epoch: 2, Iter: 2960,\t [12608/82081\t (15%)]\tLoss: 7.168197, Loc Loss: 2.215798, Conf Loss: 4.952398\tIter time: 0.2692\n",
            "Training... Epoch: 2, Iter: 2970,\t [12928/82081\t (16%)]\tLoss: 7.361797, Loc Loss: 2.043349, Conf Loss: 5.318448\tIter time: 0.2631\n",
            "Training... Epoch: 2, Iter: 2980,\t [13248/82081\t (16%)]\tLoss: 7.086167, Loc Loss: 2.081435, Conf Loss: 5.004732\tIter time: 0.2439\n",
            "Training... Epoch: 2, Iter: 2990,\t [13568/82081\t (17%)]\tLoss: 7.005245, Loc Loss: 1.991781, Conf Loss: 5.013463\tIter time: 0.2648\n",
            "Training... Epoch: 2, Iter: 3000,\t [13888/82081\t (17%)]\tLoss: 7.826697, Loc Loss: 2.478506, Conf Loss: 5.348191\tIter time: 0.2694\n",
            "Training... Epoch: 2, Iter: 3010,\t [14208/82081\t (17%)]\tLoss: 7.158779, Loc Loss: 2.103759, Conf Loss: 5.055020\tIter time: 0.2665\n",
            "Training... Epoch: 2, Iter: 3020,\t [14528/82081\t (18%)]\tLoss: 7.215901, Loc Loss: 2.175639, Conf Loss: 5.040263\tIter time: 0.2606\n",
            "Training... Epoch: 2, Iter: 3030,\t [14848/82081\t (18%)]\tLoss: 7.365585, Loc Loss: 2.269137, Conf Loss: 5.096448\tIter time: 0.2567\n",
            "Training... Epoch: 2, Iter: 3040,\t [15168/82081\t (18%)]\tLoss: 6.880432, Loc Loss: 1.963897, Conf Loss: 4.916535\tIter time: 0.2688\n",
            "Training... Epoch: 2, Iter: 3050,\t [15488/82081\t (19%)]\tLoss: 6.860537, Loc Loss: 1.856879, Conf Loss: 5.003657\tIter time: 0.2567\n",
            "Training... Epoch: 2, Iter: 3060,\t [15808/82081\t (19%)]\tLoss: 6.996030, Loc Loss: 2.067421, Conf Loss: 4.928609\tIter time: 0.2444\n",
            "Training... Epoch: 2, Iter: 3070,\t [16128/82081\t (20%)]\tLoss: 7.378288, Loc Loss: 1.809702, Conf Loss: 5.568586\tIter time: 0.2720\n",
            "Training... Epoch: 2, Iter: 3080,\t [16448/82081\t (20%)]\tLoss: 7.396943, Loc Loss: 2.257302, Conf Loss: 5.139641\tIter time: 0.2696\n",
            "Training... Epoch: 2, Iter: 3090,\t [16768/82081\t (20%)]\tLoss: 6.975428, Loc Loss: 1.992101, Conf Loss: 4.983326\tIter time: 0.2742\n",
            "Training... Epoch: 2, Iter: 3100,\t [17088/82081\t (21%)]\tLoss: 7.145394, Loc Loss: 2.011435, Conf Loss: 5.133959\tIter time: 0.2667\n",
            "Training... Epoch: 2, Iter: 3110,\t [17408/82081\t (21%)]\tLoss: 6.710824, Loc Loss: 2.115669, Conf Loss: 4.595155\tIter time: 0.2583\n",
            "Training... Epoch: 2, Iter: 3120,\t [17728/82081\t (22%)]\tLoss: 7.305505, Loc Loss: 2.142287, Conf Loss: 5.163218\tIter time: 0.2599\n",
            "Training... Epoch: 2, Iter: 3130,\t [18048/82081\t (22%)]\tLoss: 6.743666, Loc Loss: 2.122747, Conf Loss: 4.620918\tIter time: 0.2851\n",
            "Training... Epoch: 2, Iter: 3140,\t [18368/82081\t (22%)]\tLoss: 6.966297, Loc Loss: 2.183157, Conf Loss: 4.783140\tIter time: 0.2463\n",
            "Training... Epoch: 2, Iter: 3150,\t [18688/82081\t (23%)]\tLoss: 6.598726, Loc Loss: 2.018119, Conf Loss: 4.580607\tIter time: 0.2665\n",
            "Training... Epoch: 2, Iter: 3160,\t [19008/82081\t (23%)]\tLoss: 6.759698, Loc Loss: 1.885175, Conf Loss: 4.874524\tIter time: 0.2762\n",
            "Training... Epoch: 2, Iter: 3170,\t [19328/82081\t (24%)]\tLoss: 6.803251, Loc Loss: 2.030154, Conf Loss: 4.773098\tIter time: 0.2461\n",
            "Training... Epoch: 2, Iter: 3180,\t [19648/82081\t (24%)]\tLoss: 7.669947, Loc Loss: 2.256322, Conf Loss: 5.413624\tIter time: 0.2649\n",
            "Training... Epoch: 2, Iter: 3190,\t [19968/82081\t (24%)]\tLoss: 7.220605, Loc Loss: 2.235341, Conf Loss: 4.985264\tIter time: 0.2757\n",
            "Training... Epoch: 2, Iter: 3200,\t [20288/82081\t (25%)]\tLoss: 7.078232, Loc Loss: 1.984610, Conf Loss: 5.093622\tIter time: 0.2687\n",
            "Training... Epoch: 2, Iter: 3210,\t [20608/82081\t (25%)]\tLoss: 7.021203, Loc Loss: 2.274912, Conf Loss: 4.746291\tIter time: 0.2730\n",
            "Training... Epoch: 2, Iter: 3220,\t [20928/82081\t (25%)]\tLoss: 6.709786, Loc Loss: 1.944682, Conf Loss: 4.765104\tIter time: 0.2653\n",
            "Training... Epoch: 2, Iter: 3230,\t [21248/82081\t (26%)]\tLoss: 6.831804, Loc Loss: 2.027905, Conf Loss: 4.803899\tIter time: 0.2741\n",
            "Training... Epoch: 2, Iter: 3240,\t [21568/82081\t (26%)]\tLoss: 7.292745, Loc Loss: 2.208051, Conf Loss: 5.084693\tIter time: 0.2629\n",
            "Training... Epoch: 2, Iter: 3250,\t [21888/82081\t (27%)]\tLoss: 6.840478, Loc Loss: 2.281656, Conf Loss: 4.558823\tIter time: 0.2620\n",
            "Training... Epoch: 2, Iter: 3260,\t [22208/82081\t (27%)]\tLoss: 6.928333, Loc Loss: 2.304110, Conf Loss: 4.624223\tIter time: 0.2537\n",
            "Training... Epoch: 2, Iter: 3270,\t [22528/82081\t (27%)]\tLoss: 7.328179, Loc Loss: 2.130665, Conf Loss: 5.197515\tIter time: 0.3019\n",
            "Training... Epoch: 2, Iter: 3280,\t [22848/82081\t (28%)]\tLoss: 7.148928, Loc Loss: 2.060899, Conf Loss: 5.088028\tIter time: 0.2670\n",
            "Training... Epoch: 2, Iter: 3290,\t [23168/82081\t (28%)]\tLoss: 6.977824, Loc Loss: 2.013300, Conf Loss: 4.964524\tIter time: 0.2729\n",
            "Training... Epoch: 2, Iter: 3300,\t [23488/82081\t (29%)]\tLoss: 6.986675, Loc Loss: 1.914955, Conf Loss: 5.071719\tIter time: 0.2540\n",
            "Training... Epoch: 2, Iter: 3310,\t [23808/82081\t (29%)]\tLoss: 6.965075, Loc Loss: 1.948103, Conf Loss: 5.016971\tIter time: 0.2781\n",
            "Training... Epoch: 2, Iter: 3320,\t [24128/82081\t (29%)]\tLoss: 6.785221, Loc Loss: 2.123046, Conf Loss: 4.662175\tIter time: 0.2790\n",
            "Training... Epoch: 2, Iter: 3330,\t [24448/82081\t (30%)]\tLoss: 6.600229, Loc Loss: 1.831577, Conf Loss: 4.768651\tIter time: 0.2568\n",
            "Training... Epoch: 2, Iter: 3340,\t [24768/82081\t (30%)]\tLoss: 7.386022, Loc Loss: 2.155440, Conf Loss: 5.230582\tIter time: 0.2654\n",
            "Training... Epoch: 2, Iter: 3350,\t [25088/82081\t (31%)]\tLoss: 7.419792, Loc Loss: 2.067585, Conf Loss: 5.352207\tIter time: 0.2572\n",
            "Training... Epoch: 2, Iter: 3360,\t [25408/82081\t (31%)]\tLoss: 7.196189, Loc Loss: 2.149772, Conf Loss: 5.046418\tIter time: 0.2624\n",
            "Training... Epoch: 2, Iter: 3370,\t [25728/82081\t (31%)]\tLoss: 6.728079, Loc Loss: 1.936353, Conf Loss: 4.791725\tIter time: 0.2603\n",
            "Training... Epoch: 2, Iter: 3380,\t [26048/82081\t (32%)]\tLoss: 7.229698, Loc Loss: 2.473318, Conf Loss: 4.756380\tIter time: 0.2765\n",
            "Training... Epoch: 2, Iter: 3390,\t [26368/82081\t (32%)]\tLoss: 6.725897, Loc Loss: 2.174703, Conf Loss: 4.551194\tIter time: 0.2919\n",
            "Training... Epoch: 2, Iter: 3400,\t [26688/82081\t (33%)]\tLoss: 7.098355, Loc Loss: 2.047997, Conf Loss: 5.050358\tIter time: 0.2599\n",
            "Training... Epoch: 2, Iter: 3410,\t [27008/82081\t (33%)]\tLoss: 7.122403, Loc Loss: 2.105797, Conf Loss: 5.016606\tIter time: 0.2472\n",
            "Training... Epoch: 2, Iter: 3420,\t [27328/82081\t (33%)]\tLoss: 6.626636, Loc Loss: 2.041610, Conf Loss: 4.585026\tIter time: 0.2861\n",
            "Training... Epoch: 2, Iter: 3430,\t [27648/82081\t (34%)]\tLoss: 6.881018, Loc Loss: 2.040533, Conf Loss: 4.840485\tIter time: 0.2597\n",
            "Training... Epoch: 2, Iter: 3440,\t [27968/82081\t (34%)]\tLoss: 7.112645, Loc Loss: 2.233720, Conf Loss: 4.878925\tIter time: 0.2653\n",
            "Training... Epoch: 2, Iter: 3450,\t [28288/82081\t (34%)]\tLoss: 7.101859, Loc Loss: 2.107552, Conf Loss: 4.994307\tIter time: 0.2637\n",
            "Training... Epoch: 2, Iter: 3460,\t [28608/82081\t (35%)]\tLoss: 7.021282, Loc Loss: 2.060969, Conf Loss: 4.960313\tIter time: 0.2777\n",
            "Training... Epoch: 2, Iter: 3470,\t [28928/82081\t (35%)]\tLoss: 6.689744, Loc Loss: 2.080656, Conf Loss: 4.609088\tIter time: 0.2697\n",
            "Training... Epoch: 2, Iter: 3480,\t [29248/82081\t (36%)]\tLoss: 6.194415, Loc Loss: 1.973755, Conf Loss: 4.220660\tIter time: 0.2491\n",
            "Training... Epoch: 2, Iter: 3490,\t [29568/82081\t (36%)]\tLoss: 7.400781, Loc Loss: 2.007939, Conf Loss: 5.392842\tIter time: 0.2643\n",
            "Training... Epoch: 2, Iter: 3500,\t [29888/82081\t (36%)]\tLoss: 7.081674, Loc Loss: 1.982269, Conf Loss: 5.099404\tIter time: 0.2476\n",
            "Training... Epoch: 2, Iter: 3510,\t [30208/82081\t (37%)]\tLoss: 7.058538, Loc Loss: 1.954094, Conf Loss: 5.104444\tIter time: 0.2673\n",
            "Training... Epoch: 2, Iter: 3520,\t [30528/82081\t (37%)]\tLoss: 7.266325, Loc Loss: 1.991783, Conf Loss: 5.274542\tIter time: 0.2576\n",
            "Training... Epoch: 2, Iter: 3530,\t [30848/82081\t (38%)]\tLoss: 7.572604, Loc Loss: 1.980364, Conf Loss: 5.592239\tIter time: 0.2635\n",
            "Training... Epoch: 2, Iter: 3540,\t [31168/82081\t (38%)]\tLoss: 6.645386, Loc Loss: 2.103445, Conf Loss: 4.541942\tIter time: 0.2616\n",
            "Training... Epoch: 2, Iter: 3550,\t [31488/82081\t (38%)]\tLoss: 6.993454, Loc Loss: 2.078444, Conf Loss: 4.915010\tIter time: 0.2572\n",
            "Training... Epoch: 2, Iter: 3560,\t [31808/82081\t (39%)]\tLoss: 6.736247, Loc Loss: 2.097163, Conf Loss: 4.639084\tIter time: 0.2610\n",
            "Training... Epoch: 2, Iter: 3570,\t [32128/82081\t (39%)]\tLoss: 6.971182, Loc Loss: 2.139151, Conf Loss: 4.832031\tIter time: 0.2660\n",
            "Training... Epoch: 2, Iter: 3580,\t [32448/82081\t (40%)]\tLoss: 6.847023, Loc Loss: 2.050814, Conf Loss: 4.796208\tIter time: 0.2899\n",
            "Training... Epoch: 2, Iter: 3590,\t [32768/82081\t (40%)]\tLoss: 7.187699, Loc Loss: 1.888720, Conf Loss: 5.298979\tIter time: 0.2505\n",
            "Training... Epoch: 2, Iter: 3600,\t [33088/82081\t (40%)]\tLoss: 6.516112, Loc Loss: 1.907051, Conf Loss: 4.609061\tIter time: 0.2670\n",
            "Training... Epoch: 2, Iter: 3610,\t [33408/82081\t (41%)]\tLoss: 7.260987, Loc Loss: 1.923275, Conf Loss: 5.337712\tIter time: 0.2664\n",
            "Training... Epoch: 2, Iter: 3620,\t [33728/82081\t (41%)]\tLoss: 7.019540, Loc Loss: 2.156451, Conf Loss: 4.863090\tIter time: 0.2666\n",
            "Training... Epoch: 2, Iter: 3630,\t [34048/82081\t (41%)]\tLoss: 6.978740, Loc Loss: 2.332241, Conf Loss: 4.646499\tIter time: 0.2872\n",
            "Training... Epoch: 2, Iter: 3640,\t [34368/82081\t (42%)]\tLoss: 6.883531, Loc Loss: 2.162526, Conf Loss: 4.721004\tIter time: 0.2666\n",
            "Training... Epoch: 2, Iter: 3650,\t [34688/82081\t (42%)]\tLoss: 6.771279, Loc Loss: 2.144469, Conf Loss: 4.626810\tIter time: 0.2768\n",
            "Training... Epoch: 2, Iter: 3660,\t [35008/82081\t (43%)]\tLoss: 6.780641, Loc Loss: 1.975604, Conf Loss: 4.805037\tIter time: 0.2649\n",
            "Training... Epoch: 2, Iter: 3670,\t [35328/82081\t (43%)]\tLoss: 7.325017, Loc Loss: 1.899372, Conf Loss: 5.425645\tIter time: 0.2559\n",
            "Training... Epoch: 2, Iter: 3680,\t [35648/82081\t (43%)]\tLoss: 6.955977, Loc Loss: 2.048148, Conf Loss: 4.907829\tIter time: 0.2598\n",
            "Training... Epoch: 2, Iter: 3690,\t [35968/82081\t (44%)]\tLoss: 7.253930, Loc Loss: 2.040020, Conf Loss: 5.213910\tIter time: 0.2880\n",
            "Training... Epoch: 2, Iter: 3700,\t [36288/82081\t (44%)]\tLoss: 7.002153, Loc Loss: 2.047370, Conf Loss: 4.954783\tIter time: 0.2571\n",
            "Training... Epoch: 2, Iter: 3710,\t [36608/82081\t (45%)]\tLoss: 6.782608, Loc Loss: 2.139510, Conf Loss: 4.643098\tIter time: 0.2708\n",
            "Training... Epoch: 2, Iter: 3720,\t [36928/82081\t (45%)]\tLoss: 6.461442, Loc Loss: 1.788560, Conf Loss: 4.672882\tIter time: 0.2639\n",
            "Training... Epoch: 2, Iter: 3730,\t [37248/82081\t (45%)]\tLoss: 6.570947, Loc Loss: 1.980249, Conf Loss: 4.590698\tIter time: 0.2822\n",
            "Training... Epoch: 2, Iter: 3740,\t [37568/82081\t (46%)]\tLoss: 7.239661, Loc Loss: 1.992210, Conf Loss: 5.247452\tIter time: 0.2579\n",
            "Training... Epoch: 2, Iter: 3750,\t [37888/82081\t (46%)]\tLoss: 6.776756, Loc Loss: 2.137657, Conf Loss: 4.639100\tIter time: 0.2669\n",
            "Training... Epoch: 2, Iter: 3760,\t [38208/82081\t (47%)]\tLoss: 7.743793, Loc Loss: 2.226488, Conf Loss: 5.517305\tIter time: 0.2584\n",
            "Training... Epoch: 2, Iter: 3770,\t [38528/82081\t (47%)]\tLoss: 7.551231, Loc Loss: 2.152222, Conf Loss: 5.399009\tIter time: 0.2872\n",
            "Training... Epoch: 2, Iter: 3780,\t [38848/82081\t (47%)]\tLoss: 6.598660, Loc Loss: 2.130050, Conf Loss: 4.468609\tIter time: 0.2719\n",
            "Training... Epoch: 2, Iter: 3790,\t [39168/82081\t (48%)]\tLoss: 6.822469, Loc Loss: 2.078573, Conf Loss: 4.743896\tIter time: 0.2437\n",
            "Training... Epoch: 2, Iter: 3800,\t [39488/82081\t (48%)]\tLoss: 7.083414, Loc Loss: 2.184771, Conf Loss: 4.898643\tIter time: 0.2650\n",
            "Training... Epoch: 2, Iter: 3810,\t [39808/82081\t (48%)]\tLoss: 6.868742, Loc Loss: 2.119340, Conf Loss: 4.749402\tIter time: 0.2641\n",
            "Training... Epoch: 2, Iter: 3820,\t [40128/82081\t (49%)]\tLoss: 6.612610, Loc Loss: 1.948021, Conf Loss: 4.664589\tIter time: 0.2496\n",
            "Training... Epoch: 2, Iter: 3830,\t [40448/82081\t (49%)]\tLoss: 6.365461, Loc Loss: 2.009043, Conf Loss: 4.356418\tIter time: 0.2547\n",
            "Training... Epoch: 2, Iter: 3840,\t [40768/82081\t (50%)]\tLoss: 6.600824, Loc Loss: 1.959698, Conf Loss: 4.641126\tIter time: 0.2696\n",
            "Training... Epoch: 2, Iter: 3850,\t [41088/82081\t (50%)]\tLoss: 6.687374, Loc Loss: 2.186264, Conf Loss: 4.501110\tIter time: 0.2517\n",
            "Training... Epoch: 2, Iter: 3860,\t [41408/82081\t (50%)]\tLoss: 6.785539, Loc Loss: 2.021716, Conf Loss: 4.763823\tIter time: 0.2508\n",
            "Training... Epoch: 2, Iter: 3870,\t [41728/82081\t (51%)]\tLoss: 6.419558, Loc Loss: 1.865118, Conf Loss: 4.554440\tIter time: 0.2600\n",
            "Training... Epoch: 2, Iter: 3880,\t [42048/82081\t (51%)]\tLoss: 6.947001, Loc Loss: 1.884074, Conf Loss: 5.062927\tIter time: 0.2741\n",
            "Training... Epoch: 2, Iter: 3890,\t [42368/82081\t (52%)]\tLoss: 6.561710, Loc Loss: 2.036400, Conf Loss: 4.525311\tIter time: 0.2693\n",
            "Training... Epoch: 2, Iter: 3900,\t [42688/82081\t (52%)]\tLoss: 6.536474, Loc Loss: 2.019191, Conf Loss: 4.517284\tIter time: 0.2689\n",
            "Training... Epoch: 2, Iter: 3910,\t [43008/82081\t (52%)]\tLoss: 6.588423, Loc Loss: 1.982400, Conf Loss: 4.606023\tIter time: 0.2616\n",
            "Training... Epoch: 2, Iter: 3920,\t [43328/82081\t (53%)]\tLoss: 6.907793, Loc Loss: 2.391778, Conf Loss: 4.516015\tIter time: 0.2657\n",
            "Training... Epoch: 2, Iter: 3930,\t [43648/82081\t (53%)]\tLoss: 6.672132, Loc Loss: 2.022816, Conf Loss: 4.649316\tIter time: 0.2539\n",
            "Training... Epoch: 2, Iter: 3940,\t [43968/82081\t (54%)]\tLoss: 6.506009, Loc Loss: 2.022726, Conf Loss: 4.483283\tIter time: 0.2678\n",
            "Training... Epoch: 2, Iter: 3950,\t [44288/82081\t (54%)]\tLoss: 6.549488, Loc Loss: 2.145993, Conf Loss: 4.403495\tIter time: 0.2613\n",
            "Training... Epoch: 2, Iter: 3960,\t [44608/82081\t (54%)]\tLoss: 6.552553, Loc Loss: 2.287053, Conf Loss: 4.265500\tIter time: 0.2850\n",
            "Training... Epoch: 2, Iter: 3970,\t [44928/82081\t (55%)]\tLoss: 6.925309, Loc Loss: 2.138555, Conf Loss: 4.786754\tIter time: 0.2792\n",
            "Training... Epoch: 2, Iter: 3980,\t [45248/82081\t (55%)]\tLoss: 6.549619, Loc Loss: 2.035860, Conf Loss: 4.513759\tIter time: 0.2644\n",
            "Training... Epoch: 2, Iter: 3990,\t [45568/82081\t (55%)]\tLoss: 6.884358, Loc Loss: 2.093452, Conf Loss: 4.790907\tIter time: 0.2851\n",
            "Training... Epoch: 2, Iter: 4000,\t [45888/82081\t (56%)]\tLoss: 6.717930, Loc Loss: 2.092638, Conf Loss: 4.625293\tIter time: 0.2605\n",
            "Training... Epoch: 2, Iter: 4010,\t [46208/82081\t (56%)]\tLoss: 7.424534, Loc Loss: 1.853781, Conf Loss: 5.570753\tIter time: 0.2586\n",
            "Training... Epoch: 2, Iter: 4020,\t [46528/82081\t (57%)]\tLoss: 6.768396, Loc Loss: 2.076419, Conf Loss: 4.691978\tIter time: 0.2464\n",
            "Training... Epoch: 2, Iter: 4030,\t [46848/82081\t (57%)]\tLoss: 7.216982, Loc Loss: 2.027176, Conf Loss: 5.189806\tIter time: 0.2697\n",
            "Training... Epoch: 2, Iter: 4040,\t [47168/82081\t (57%)]\tLoss: 6.333115, Loc Loss: 1.716051, Conf Loss: 4.617064\tIter time: 0.2606\n",
            "Training... Epoch: 2, Iter: 4050,\t [47488/82081\t (58%)]\tLoss: 6.438215, Loc Loss: 2.097537, Conf Loss: 4.340678\tIter time: 0.2436\n",
            "Training... Epoch: 2, Iter: 4060,\t [47808/82081\t (58%)]\tLoss: 7.167109, Loc Loss: 2.355918, Conf Loss: 4.811192\tIter time: 0.2810\n",
            "Training... Epoch: 2, Iter: 4070,\t [48128/82081\t (59%)]\tLoss: 6.794841, Loc Loss: 1.843880, Conf Loss: 4.950962\tIter time: 0.2589\n",
            "Training... Epoch: 2, Iter: 4080,\t [48448/82081\t (59%)]\tLoss: 6.361872, Loc Loss: 2.055596, Conf Loss: 4.306276\tIter time: 0.2626\n",
            "Training... Epoch: 2, Iter: 4090,\t [48768/82081\t (59%)]\tLoss: 6.524284, Loc Loss: 1.879267, Conf Loss: 4.645017\tIter time: 0.2601\n",
            "Training... Epoch: 2, Iter: 4100,\t [49088/82081\t (60%)]\tLoss: 6.950324, Loc Loss: 1.997967, Conf Loss: 4.952356\tIter time: 0.2809\n",
            "Training... Epoch: 2, Iter: 4110,\t [49408/82081\t (60%)]\tLoss: 6.695559, Loc Loss: 1.922503, Conf Loss: 4.773056\tIter time: 0.2716\n",
            "Training... Epoch: 2, Iter: 4120,\t [49728/82081\t (61%)]\tLoss: 6.163253, Loc Loss: 1.948508, Conf Loss: 4.214745\tIter time: 0.2777\n",
            "Training... Epoch: 2, Iter: 4130,\t [50048/82081\t (61%)]\tLoss: 6.992107, Loc Loss: 2.127328, Conf Loss: 4.864779\tIter time: 0.2601\n",
            "Training... Epoch: 2, Iter: 4140,\t [50368/82081\t (61%)]\tLoss: 7.271377, Loc Loss: 1.979542, Conf Loss: 5.291834\tIter time: 0.2568\n",
            "Training... Epoch: 2, Iter: 4150,\t [50688/82081\t (62%)]\tLoss: 6.632211, Loc Loss: 2.027712, Conf Loss: 4.604499\tIter time: 0.2707\n",
            "Training... Epoch: 2, Iter: 4160,\t [51008/82081\t (62%)]\tLoss: 7.224504, Loc Loss: 2.376180, Conf Loss: 4.848323\tIter time: 0.2667\n",
            "Training... Epoch: 2, Iter: 4170,\t [51328/82081\t (63%)]\tLoss: 7.001869, Loc Loss: 2.003113, Conf Loss: 4.998755\tIter time: 0.2457\n",
            "Training... Epoch: 2, Iter: 4180,\t [51648/82081\t (63%)]\tLoss: 6.892948, Loc Loss: 2.356821, Conf Loss: 4.536127\tIter time: 0.2753\n",
            "Training... Epoch: 2, Iter: 4190,\t [51968/82081\t (63%)]\tLoss: 6.432551, Loc Loss: 2.025947, Conf Loss: 4.406604\tIter time: 0.2772\n",
            "Training... Epoch: 2, Iter: 4200,\t [52288/82081\t (64%)]\tLoss: 6.627130, Loc Loss: 2.058930, Conf Loss: 4.568200\tIter time: 0.2443\n",
            "Training... Epoch: 2, Iter: 4210,\t [52608/82081\t (64%)]\tLoss: 6.762637, Loc Loss: 1.979271, Conf Loss: 4.783366\tIter time: 0.2724\n",
            "Training... Epoch: 2, Iter: 4220,\t [52928/82081\t (64%)]\tLoss: 6.860454, Loc Loss: 1.945320, Conf Loss: 4.915133\tIter time: 0.2738\n",
            "Training... Epoch: 2, Iter: 4230,\t [53248/82081\t (65%)]\tLoss: 6.673782, Loc Loss: 1.811241, Conf Loss: 4.862541\tIter time: 0.2615\n",
            "Training... Epoch: 2, Iter: 4240,\t [53568/82081\t (65%)]\tLoss: 6.671687, Loc Loss: 2.367313, Conf Loss: 4.304374\tIter time: 0.2846\n",
            "Training... Epoch: 2, Iter: 4250,\t [53888/82081\t (66%)]\tLoss: 7.314135, Loc Loss: 2.238066, Conf Loss: 5.076069\tIter time: 0.2823\n",
            "Training... Epoch: 2, Iter: 4260,\t [54208/82081\t (66%)]\tLoss: 6.815407, Loc Loss: 2.167498, Conf Loss: 4.647909\tIter time: 0.2652\n",
            "Training... Epoch: 2, Iter: 4270,\t [54528/82081\t (66%)]\tLoss: 6.513826, Loc Loss: 2.087453, Conf Loss: 4.426373\tIter time: 0.2694\n",
            "Training... Epoch: 2, Iter: 4280,\t [54848/82081\t (67%)]\tLoss: 7.140523, Loc Loss: 2.234637, Conf Loss: 4.905887\tIter time: 0.2652\n",
            "Training... Epoch: 2, Iter: 4290,\t [55168/82081\t (67%)]\tLoss: 7.167075, Loc Loss: 2.030310, Conf Loss: 5.136765\tIter time: 0.2705\n",
            "Training... Epoch: 2, Iter: 4300,\t [55488/82081\t (68%)]\tLoss: 5.922129, Loc Loss: 1.948029, Conf Loss: 3.974100\tIter time: 0.2638\n",
            "Training... Epoch: 2, Iter: 4310,\t [55808/82081\t (68%)]\tLoss: 6.459422, Loc Loss: 2.052961, Conf Loss: 4.406461\tIter time: 0.2605\n",
            "Training... Epoch: 2, Iter: 4320,\t [56128/82081\t (68%)]\tLoss: 7.050718, Loc Loss: 2.299244, Conf Loss: 4.751475\tIter time: 0.2773\n",
            "Training... Epoch: 2, Iter: 4330,\t [56448/82081\t (69%)]\tLoss: 6.642951, Loc Loss: 2.027084, Conf Loss: 4.615868\tIter time: 0.2419\n",
            "Training... Epoch: 2, Iter: 4340,\t [56768/82081\t (69%)]\tLoss: 7.115519, Loc Loss: 2.379952, Conf Loss: 4.735567\tIter time: 0.2734\n",
            "Training... Epoch: 2, Iter: 4350,\t [57088/82081\t (70%)]\tLoss: 6.468350, Loc Loss: 1.957451, Conf Loss: 4.510900\tIter time: 0.2704\n",
            "Training... Epoch: 2, Iter: 4360,\t [57408/82081\t (70%)]\tLoss: 6.697513, Loc Loss: 1.979661, Conf Loss: 4.717852\tIter time: 0.2821\n",
            "Training... Epoch: 2, Iter: 4370,\t [57728/82081\t (70%)]\tLoss: 6.851690, Loc Loss: 2.011917, Conf Loss: 4.839773\tIter time: 0.2654\n",
            "Training... Epoch: 2, Iter: 4380,\t [58048/82081\t (71%)]\tLoss: 7.393472, Loc Loss: 2.140769, Conf Loss: 5.252703\tIter time: 0.2546\n",
            "Training... Epoch: 2, Iter: 4390,\t [58368/82081\t (71%)]\tLoss: 6.782375, Loc Loss: 1.863749, Conf Loss: 4.918626\tIter time: 0.2535\n",
            "Training... Epoch: 2, Iter: 4400,\t [58688/82081\t (71%)]\tLoss: 7.051831, Loc Loss: 2.111921, Conf Loss: 4.939910\tIter time: 0.2567\n",
            "Training... Epoch: 2, Iter: 4410,\t [59008/82081\t (72%)]\tLoss: 7.253514, Loc Loss: 2.041389, Conf Loss: 5.212126\tIter time: 0.2555\n",
            "Training... Epoch: 2, Iter: 4420,\t [59328/82081\t (72%)]\tLoss: 6.458591, Loc Loss: 1.818593, Conf Loss: 4.639998\tIter time: 0.2639\n",
            "Training... Epoch: 2, Iter: 4430,\t [59648/82081\t (73%)]\tLoss: 6.786794, Loc Loss: 2.149606, Conf Loss: 4.637187\tIter time: 0.2675\n",
            "Training... Epoch: 2, Iter: 4440,\t [59968/82081\t (73%)]\tLoss: 7.267230, Loc Loss: 2.312240, Conf Loss: 4.954990\tIter time: 0.2506\n",
            "Training... Epoch: 2, Iter: 4450,\t [60288/82081\t (73%)]\tLoss: 6.966588, Loc Loss: 2.153387, Conf Loss: 4.813202\tIter time: 0.2697\n",
            "Training... Epoch: 2, Iter: 4460,\t [60608/82081\t (74%)]\tLoss: 6.725986, Loc Loss: 2.342695, Conf Loss: 4.383291\tIter time: 0.2702\n",
            "Training... Epoch: 2, Iter: 4470,\t [60928/82081\t (74%)]\tLoss: 6.870053, Loc Loss: 2.083576, Conf Loss: 4.786477\tIter time: 0.2437\n",
            "Training... Epoch: 2, Iter: 4480,\t [61248/82081\t (75%)]\tLoss: 7.298009, Loc Loss: 2.324168, Conf Loss: 4.973841\tIter time: 0.2740\n",
            "Training... Epoch: 2, Iter: 4490,\t [61568/82081\t (75%)]\tLoss: 6.583385, Loc Loss: 2.082817, Conf Loss: 4.500568\tIter time: 0.2455\n",
            "Training... Epoch: 2, Iter: 4500,\t [61888/82081\t (75%)]\tLoss: 6.666464, Loc Loss: 2.101623, Conf Loss: 4.564841\tIter time: 0.2761\n",
            "Training... Epoch: 2, Iter: 4510,\t [62208/82081\t (76%)]\tLoss: 7.222265, Loc Loss: 2.124013, Conf Loss: 5.098252\tIter time: 0.2439\n",
            "Training... Epoch: 2, Iter: 4520,\t [62528/82081\t (76%)]\tLoss: 6.957809, Loc Loss: 2.400745, Conf Loss: 4.557065\tIter time: 0.2788\n",
            "Training... Epoch: 2, Iter: 4530,\t [62848/82081\t (77%)]\tLoss: 6.820324, Loc Loss: 2.255184, Conf Loss: 4.565140\tIter time: 0.2931\n",
            "Training... Epoch: 2, Iter: 4540,\t [63168/82081\t (77%)]\tLoss: 6.888342, Loc Loss: 2.243958, Conf Loss: 4.644384\tIter time: 0.2609\n",
            "Training... Epoch: 2, Iter: 4550,\t [63488/82081\t (77%)]\tLoss: 6.656247, Loc Loss: 1.764673, Conf Loss: 4.891574\tIter time: 0.2553\n",
            "Training... Epoch: 2, Iter: 4560,\t [63808/82081\t (78%)]\tLoss: 6.471099, Loc Loss: 1.875580, Conf Loss: 4.595519\tIter time: 0.2448\n",
            "Training... Epoch: 2, Iter: 4570,\t [64128/82081\t (78%)]\tLoss: 7.076667, Loc Loss: 2.268015, Conf Loss: 4.808651\tIter time: 0.2914\n",
            "Training... Epoch: 2, Iter: 4580,\t [64448/82081\t (78%)]\tLoss: 6.592223, Loc Loss: 1.891194, Conf Loss: 4.701029\tIter time: 0.2708\n",
            "Training... Epoch: 2, Iter: 4590,\t [64768/82081\t (79%)]\tLoss: 6.567525, Loc Loss: 1.860285, Conf Loss: 4.707241\tIter time: 0.2588\n",
            "Training... Epoch: 2, Iter: 4600,\t [65088/82081\t (79%)]\tLoss: 6.749179, Loc Loss: 1.871408, Conf Loss: 4.877771\tIter time: 0.2473\n",
            "Training... Epoch: 2, Iter: 4610,\t [65408/82081\t (80%)]\tLoss: 6.905589, Loc Loss: 1.980518, Conf Loss: 4.925071\tIter time: 0.2475\n",
            "Training... Epoch: 2, Iter: 4620,\t [65728/82081\t (80%)]\tLoss: 6.893935, Loc Loss: 2.076012, Conf Loss: 4.817923\tIter time: 0.2559\n",
            "Training... Epoch: 2, Iter: 4630,\t [66048/82081\t (80%)]\tLoss: 6.809742, Loc Loss: 2.080516, Conf Loss: 4.729227\tIter time: 0.2498\n",
            "Training... Epoch: 2, Iter: 4640,\t [66368/82081\t (81%)]\tLoss: 6.718669, Loc Loss: 1.969462, Conf Loss: 4.749207\tIter time: 0.2568\n",
            "Training... Epoch: 2, Iter: 4650,\t [66688/82081\t (81%)]\tLoss: 6.532495, Loc Loss: 2.001048, Conf Loss: 4.531447\tIter time: 0.2892\n",
            "Training... Epoch: 2, Iter: 4660,\t [67008/82081\t (82%)]\tLoss: 7.139383, Loc Loss: 2.237177, Conf Loss: 4.902206\tIter time: 0.2487\n",
            "Training... Epoch: 2, Iter: 4670,\t [67328/82081\t (82%)]\tLoss: 6.614252, Loc Loss: 2.107472, Conf Loss: 4.506780\tIter time: 0.2790\n",
            "Training... Epoch: 2, Iter: 4680,\t [67648/82081\t (82%)]\tLoss: 6.310463, Loc Loss: 1.722189, Conf Loss: 4.588274\tIter time: 0.2583\n",
            "Training... Epoch: 2, Iter: 4690,\t [67968/82081\t (83%)]\tLoss: 6.141975, Loc Loss: 1.702889, Conf Loss: 4.439086\tIter time: 0.2581\n",
            "Training... Epoch: 2, Iter: 4700,\t [68288/82081\t (83%)]\tLoss: 6.591976, Loc Loss: 2.168023, Conf Loss: 4.423953\tIter time: 0.2696\n",
            "Training... Epoch: 2, Iter: 4710,\t [68608/82081\t (84%)]\tLoss: 6.652328, Loc Loss: 2.176234, Conf Loss: 4.476093\tIter time: 0.2702\n",
            "Training... Epoch: 2, Iter: 4720,\t [68928/82081\t (84%)]\tLoss: 7.203737, Loc Loss: 2.119556, Conf Loss: 5.084180\tIter time: 0.2738\n",
            "Training... Epoch: 2, Iter: 4730,\t [69248/82081\t (84%)]\tLoss: 6.291232, Loc Loss: 1.793842, Conf Loss: 4.497390\tIter time: 0.2548\n",
            "Training... Epoch: 2, Iter: 4740,\t [69568/82081\t (85%)]\tLoss: 7.342425, Loc Loss: 2.303408, Conf Loss: 5.039017\tIter time: 0.2819\n",
            "Training... Epoch: 2, Iter: 4750,\t [69888/82081\t (85%)]\tLoss: 6.832223, Loc Loss: 1.894362, Conf Loss: 4.937860\tIter time: 0.2728\n",
            "Training... Epoch: 2, Iter: 4760,\t [70208/82081\t (86%)]\tLoss: 6.511158, Loc Loss: 1.802471, Conf Loss: 4.708687\tIter time: 0.2665\n",
            "Training... Epoch: 2, Iter: 4770,\t [70528/82081\t (86%)]\tLoss: 6.611584, Loc Loss: 1.828538, Conf Loss: 4.783046\tIter time: 0.2546\n",
            "Training... Epoch: 2, Iter: 4780,\t [70848/82081\t (86%)]\tLoss: 7.182514, Loc Loss: 1.923880, Conf Loss: 5.258634\tIter time: 0.2408\n",
            "Training... Epoch: 2, Iter: 4790,\t [71168/82081\t (87%)]\tLoss: 6.594274, Loc Loss: 1.864182, Conf Loss: 4.730092\tIter time: 0.2606\n",
            "Training... Epoch: 2, Iter: 4800,\t [71488/82081\t (87%)]\tLoss: 7.143604, Loc Loss: 2.340551, Conf Loss: 4.803053\tIter time: 0.2799\n",
            "Training... Epoch: 2, Iter: 4810,\t [71808/82081\t (87%)]\tLoss: 6.774833, Loc Loss: 2.092003, Conf Loss: 4.682830\tIter time: 0.2715\n",
            "Training... Epoch: 2, Iter: 4820,\t [72128/82081\t (88%)]\tLoss: 6.791479, Loc Loss: 1.969500, Conf Loss: 4.821979\tIter time: 0.2486\n",
            "Training... Epoch: 2, Iter: 4830,\t [72448/82081\t (88%)]\tLoss: 6.705802, Loc Loss: 2.030657, Conf Loss: 4.675145\tIter time: 0.2532\n",
            "Training... Epoch: 2, Iter: 4840,\t [72768/82081\t (89%)]\tLoss: 6.217614, Loc Loss: 1.786763, Conf Loss: 4.430851\tIter time: 0.2608\n",
            "Training... Epoch: 2, Iter: 4850,\t [73088/82081\t (89%)]\tLoss: 6.750130, Loc Loss: 1.881474, Conf Loss: 4.868656\tIter time: 0.2667\n",
            "Training... Epoch: 2, Iter: 4860,\t [73408/82081\t (89%)]\tLoss: 6.521924, Loc Loss: 1.751637, Conf Loss: 4.770287\tIter time: 0.2639\n",
            "Training... Epoch: 2, Iter: 4870,\t [73728/82081\t (90%)]\tLoss: 7.024094, Loc Loss: 2.287231, Conf Loss: 4.736863\tIter time: 0.2752\n",
            "Training... Epoch: 2, Iter: 4880,\t [74048/82081\t (90%)]\tLoss: 6.531865, Loc Loss: 1.723427, Conf Loss: 4.808437\tIter time: 0.2586\n",
            "Training... Epoch: 2, Iter: 4890,\t [74368/82081\t (91%)]\tLoss: 6.653918, Loc Loss: 1.914487, Conf Loss: 4.739431\tIter time: 0.2721\n",
            "Training... Epoch: 2, Iter: 4900,\t [74688/82081\t (91%)]\tLoss: 6.630729, Loc Loss: 1.854044, Conf Loss: 4.776685\tIter time: 0.2636\n",
            "Training... Epoch: 2, Iter: 4910,\t [75008/82081\t (91%)]\tLoss: 6.972093, Loc Loss: 2.372021, Conf Loss: 4.600071\tIter time: 0.2461\n",
            "Training... Epoch: 2, Iter: 4920,\t [75328/82081\t (92%)]\tLoss: 7.137280, Loc Loss: 2.446738, Conf Loss: 4.690542\tIter time: 0.2680\n",
            "Training... Epoch: 2, Iter: 4930,\t [75648/82081\t (92%)]\tLoss: 6.730895, Loc Loss: 1.916539, Conf Loss: 4.814356\tIter time: 0.2492\n",
            "Training... Epoch: 2, Iter: 4940,\t [75968/82081\t (93%)]\tLoss: 6.432567, Loc Loss: 1.935376, Conf Loss: 4.497190\tIter time: 0.2693\n",
            "Training... Epoch: 2, Iter: 4950,\t [76288/82081\t (93%)]\tLoss: 6.738432, Loc Loss: 2.187151, Conf Loss: 4.551281\tIter time: 0.2441\n",
            "Training... Epoch: 2, Iter: 4960,\t [76608/82081\t (93%)]\tLoss: 6.204568, Loc Loss: 1.806279, Conf Loss: 4.398289\tIter time: 0.2696\n",
            "Training... Epoch: 2, Iter: 4970,\t [76928/82081\t (94%)]\tLoss: 6.041945, Loc Loss: 1.924404, Conf Loss: 4.117542\tIter time: 0.2666\n",
            "Training... Epoch: 2, Iter: 4980,\t [77248/82081\t (94%)]\tLoss: 6.281558, Loc Loss: 1.664546, Conf Loss: 4.617012\tIter time: 0.2564\n",
            "Training... Epoch: 2, Iter: 4990,\t [77568/82081\t (94%)]\tLoss: 6.206658, Loc Loss: 1.781809, Conf Loss: 4.424850\tIter time: 0.2577\n",
            "Training... Epoch: 2, Iter: 5000,\t [77888/82081\t (95%)]\tLoss: 7.120991, Loc Loss: 2.183039, Conf Loss: 4.937951\tIter time: 0.2440\n",
            "\n",
            "Training finished\n",
            "Saved model to ./weights/results/SSD300_i-5000.pth\n",
            "Saved graph to ./weights/results/SSD300_learning-curve_i-5000.png\n"
          ]
        }
      ],
      "source": [
        "#augmentation\n",
        "!python easy_train.py COCO --max_iteration 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZzb_Xk7YkBO",
        "outputId": "16b6c6f8-af41-49b7-fb80-303a8a7608a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=12.39s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO:root:Dataset info:\n",
            "root dir: ['/root/data/coco/coco2014/trainval'],\n",
            "focus: ['train2014'],\n",
            "labels:['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
            "ignore object: None\n",
            "augmentation: True\n",
            "batch size: 32\n",
            "num_workers: 4\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /content/pytorch_SSD/weights/vgg16_bn-6c64b313.pth\n",
            "100% 528M/528M [00:05<00:00, 95.4MB/s]\n",
            "INFO:root:model loaded\n",
            "INFO:root:DataParallel(\n",
            "  (module): SSD300(\n",
            "    (codec): Codec(\n",
            "      (encoder): Encoder()\n",
            "      (decoder): Decoder()\n",
            "    )\n",
            "    (defaultBox): DBoxSSDOriginal()\n",
            "    (predictor): Predictor()\n",
            "    (inferenceBox): InferenceBox()\n",
            "    (feature_layers): ModuleDict(\n",
            "      (convBnRL1_1): ConvRelu(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL1_2): ConvRelu(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convBnRL2_1): ConvRelu(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL2_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convBnRL3_1): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL3_2): ConvRelu(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL3_3): ConvRelu(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=True)\n",
            "      (convBnRL4_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL4_2): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL4_3): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convBnRL5_1): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL5_2): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL5_3): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool5): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1, dilation=1, ceil_mode=False)\n",
            "      (convBnRL6): ConvRelu(\n",
            "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL7): ConvRelu(\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL8_1): ConvRelu(\n",
            "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL8_2): ConvRelu(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL9_1): ConvRelu(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL9_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL10_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL10_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL11_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convRL11_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (addon_layers): ModuleDict(\n",
            "      (addon_1): L2Normalization()\n",
            "    )\n",
            "    (localization_layers): ModuleDict(\n",
            "      (conv_loc_1): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_2): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_3): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_4): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_6): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (confidence_layers): ModuleDict(\n",
            "      (conv_conf_1): Conv2d(512, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_2): Conv2d(1024, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_3): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_4): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_6): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO:root:Optimizer Info:\n",
            "Optimizer: SGD\n",
            "learning rate: 0.001, Momentum: 0.9, Weight decay: 0.0005\n",
            "\n",
            "INFO:root:Multi Step Info:\n",
            "milestones: [40000, 50000]\n",
            "gamma: 0.1\n",
            "\n",
            "INFO:root:Save Info:\n",
            "filename: SSD300\n",
            "checkpoints interval: 5000\n",
            "\n",
            "INFO:root:Start Training\n",
            "\n",
            "\n",
            "Training... Epoch: 1, Iter: 1,\t [32/82081\t (0%)]\tLoss: 28.902193, Loc Loss: 4.441763, Conf Loss: 24.460430\tIter time: 0.3875\n",
            "Training... Epoch: 1, Iter: 10,\t [320/82081\t (0%)]\tLoss: 21.544928, Loc Loss: 4.289934, Conf Loss: 17.254993\tIter time: 0.2867\n",
            "Training... Epoch: 1, Iter: 20,\t [640/82081\t (1%)]\tLoss: 14.622351, Loc Loss: 3.443279, Conf Loss: 11.179071\tIter time: 0.2846\n",
            "Training... Epoch: 1, Iter: 30,\t [960/82081\t (1%)]\tLoss: 12.752584, Loc Loss: 3.981672, Conf Loss: 8.770912\tIter time: 0.2836\n",
            "Training... Epoch: 1, Iter: 40,\t [1280/82081\t (2%)]\tLoss: 11.130983, Loc Loss: 3.391684, Conf Loss: 7.739299\tIter time: 0.2916\n",
            "Training... Epoch: 1, Iter: 50,\t [1600/82081\t (2%)]\tLoss: 10.239071, Loc Loss: 3.280169, Conf Loss: 6.958902\tIter time: 0.2821\n",
            "Training... Epoch: 1, Iter: 60,\t [1920/82081\t (2%)]\tLoss: 10.103745, Loc Loss: 3.227920, Conf Loss: 6.875824\tIter time: 0.2717\n",
            "Training... Epoch: 1, Iter: 70,\t [2240/82081\t (3%)]\tLoss: 10.185104, Loc Loss: 3.417901, Conf Loss: 6.767203\tIter time: 0.2868\n",
            "Training... Epoch: 1, Iter: 80,\t [2560/82081\t (3%)]\tLoss: 9.933678, Loc Loss: 3.343400, Conf Loss: 6.590278\tIter time: 0.2765\n",
            "Training... Epoch: 1, Iter: 90,\t [2880/82081\t (4%)]\tLoss: 10.309201, Loc Loss: 3.250804, Conf Loss: 7.058397\tIter time: 0.2889\n",
            "Training... Epoch: 1, Iter: 100,\t [3200/82081\t (4%)]\tLoss: 10.070063, Loc Loss: 3.170818, Conf Loss: 6.899244\tIter time: 0.2843\n",
            "Training... Epoch: 1, Iter: 110,\t [3520/82081\t (4%)]\tLoss: 9.942375, Loc Loss: 2.975342, Conf Loss: 6.967034\tIter time: 0.2665\n",
            "Training... Epoch: 1, Iter: 120,\t [3840/82081\t (5%)]\tLoss: 9.607840, Loc Loss: 2.947613, Conf Loss: 6.660226\tIter time: 0.3008\n",
            "Training... Epoch: 1, Iter: 130,\t [4160/82081\t (5%)]\tLoss: 9.468916, Loc Loss: 3.065263, Conf Loss: 6.403653\tIter time: 0.2969\n",
            "Training... Epoch: 1, Iter: 140,\t [4480/82081\t (5%)]\tLoss: 9.695998, Loc Loss: 2.828909, Conf Loss: 6.867089\tIter time: 0.2850\n",
            "Training... Epoch: 1, Iter: 150,\t [4800/82081\t (6%)]\tLoss: 9.912894, Loc Loss: 2.923250, Conf Loss: 6.989644\tIter time: 0.2767\n",
            "Training... Epoch: 1, Iter: 160,\t [5120/82081\t (6%)]\tLoss: 9.623722, Loc Loss: 2.923640, Conf Loss: 6.700082\tIter time: 0.2691\n",
            "Training... Epoch: 1, Iter: 170,\t [5440/82081\t (7%)]\tLoss: 9.441351, Loc Loss: 2.668092, Conf Loss: 6.773259\tIter time: 0.2728\n",
            "Training... Epoch: 1, Iter: 180,\t [5760/82081\t (7%)]\tLoss: 9.495776, Loc Loss: 3.028922, Conf Loss: 6.466855\tIter time: 0.2725\n",
            "Training... Epoch: 1, Iter: 190,\t [6080/82081\t (7%)]\tLoss: 9.851980, Loc Loss: 2.923041, Conf Loss: 6.928940\tIter time: 0.2661\n",
            "Training... Epoch: 1, Iter: 200,\t [6400/82081\t (8%)]\tLoss: 10.088722, Loc Loss: 2.903522, Conf Loss: 7.185201\tIter time: 0.2926\n",
            "Training... Epoch: 1, Iter: 210,\t [6720/82081\t (8%)]\tLoss: 9.192458, Loc Loss: 2.865108, Conf Loss: 6.327351\tIter time: 0.2908\n",
            "Training... Epoch: 1, Iter: 220,\t [7040/82081\t (9%)]\tLoss: 9.608843, Loc Loss: 2.906236, Conf Loss: 6.702607\tIter time: 0.2770\n",
            "Training... Epoch: 1, Iter: 230,\t [7360/82081\t (9%)]\tLoss: 9.459028, Loc Loss: 2.879998, Conf Loss: 6.579030\tIter time: 0.2837\n",
            "Training... Epoch: 1, Iter: 240,\t [7680/82081\t (9%)]\tLoss: 8.794596, Loc Loss: 2.856186, Conf Loss: 5.938410\tIter time: 0.3035\n",
            "Training... Epoch: 1, Iter: 250,\t [8000/82081\t (10%)]\tLoss: 9.226068, Loc Loss: 3.021318, Conf Loss: 6.204751\tIter time: 0.2823\n",
            "Training... Epoch: 1, Iter: 260,\t [8320/82081\t (10%)]\tLoss: 9.416177, Loc Loss: 2.830899, Conf Loss: 6.585278\tIter time: 0.2971\n",
            "Training... Epoch: 1, Iter: 270,\t [8640/82081\t (11%)]\tLoss: 9.611670, Loc Loss: 3.271899, Conf Loss: 6.339771\tIter time: 0.2804\n",
            "Training... Epoch: 1, Iter: 280,\t [8960/82081\t (11%)]\tLoss: 9.272158, Loc Loss: 2.753154, Conf Loss: 6.519003\tIter time: 0.2928\n",
            "Training... Epoch: 1, Iter: 290,\t [9280/82081\t (11%)]\tLoss: 9.399729, Loc Loss: 2.879189, Conf Loss: 6.520539\tIter time: 0.2980\n",
            "Training... Epoch: 1, Iter: 300,\t [9600/82081\t (12%)]\tLoss: 8.635242, Loc Loss: 2.545455, Conf Loss: 6.089786\tIter time: 0.2838\n",
            "Training... Epoch: 1, Iter: 310,\t [9920/82081\t (12%)]\tLoss: 8.770337, Loc Loss: 2.781948, Conf Loss: 5.988389\tIter time: 0.2867\n",
            "Training... Epoch: 1, Iter: 320,\t [10240/82081\t (12%)]\tLoss: 8.828969, Loc Loss: 2.859600, Conf Loss: 5.969369\tIter time: 0.2871\n",
            "Training... Epoch: 1, Iter: 330,\t [10560/82081\t (13%)]\tLoss: 9.137094, Loc Loss: 2.730392, Conf Loss: 6.406703\tIter time: 0.2877\n",
            "Training... Epoch: 1, Iter: 340,\t [10880/82081\t (13%)]\tLoss: 9.135349, Loc Loss: 2.746279, Conf Loss: 6.389071\tIter time: 0.2712\n",
            "Training... Epoch: 1, Iter: 350,\t [11200/82081\t (14%)]\tLoss: 9.570618, Loc Loss: 2.955641, Conf Loss: 6.614977\tIter time: 0.2989\n",
            "Training... Epoch: 1, Iter: 360,\t [11520/82081\t (14%)]\tLoss: 9.240474, Loc Loss: 2.799277, Conf Loss: 6.441196\tIter time: 0.2895\n",
            "Training... Epoch: 1, Iter: 370,\t [11840/82081\t (14%)]\tLoss: 8.890253, Loc Loss: 2.668649, Conf Loss: 6.221605\tIter time: 0.2937\n",
            "Training... Epoch: 1, Iter: 380,\t [12160/82081\t (15%)]\tLoss: 9.333572, Loc Loss: 2.844928, Conf Loss: 6.488644\tIter time: 0.2692\n",
            "Training... Epoch: 1, Iter: 390,\t [12480/82081\t (15%)]\tLoss: 9.022738, Loc Loss: 2.814958, Conf Loss: 6.207780\tIter time: 0.2962\n",
            "Training... Epoch: 1, Iter: 400,\t [12800/82081\t (16%)]\tLoss: 8.677496, Loc Loss: 2.612276, Conf Loss: 6.065220\tIter time: 0.2800\n",
            "Training... Epoch: 1, Iter: 410,\t [13120/82081\t (16%)]\tLoss: 9.116691, Loc Loss: 2.409884, Conf Loss: 6.706806\tIter time: 0.2986\n",
            "Training... Epoch: 1, Iter: 420,\t [13440/82081\t (16%)]\tLoss: 9.156492, Loc Loss: 2.598063, Conf Loss: 6.558430\tIter time: 0.2683\n",
            "Training... Epoch: 1, Iter: 430,\t [13760/82081\t (17%)]\tLoss: 8.320537, Loc Loss: 2.556429, Conf Loss: 5.764107\tIter time: 0.2706\n",
            "Training... Epoch: 1, Iter: 440,\t [14080/82081\t (17%)]\tLoss: 8.837545, Loc Loss: 2.746787, Conf Loss: 6.090758\tIter time: 0.2891\n",
            "Training... Epoch: 1, Iter: 450,\t [14400/82081\t (18%)]\tLoss: 8.756858, Loc Loss: 3.065578, Conf Loss: 5.691279\tIter time: 0.3010\n",
            "Training... Epoch: 1, Iter: 460,\t [14720/82081\t (18%)]\tLoss: 9.129791, Loc Loss: 2.490934, Conf Loss: 6.638857\tIter time: 0.2940\n",
            "Training... Epoch: 1, Iter: 470,\t [15040/82081\t (18%)]\tLoss: 9.415527, Loc Loss: 2.676073, Conf Loss: 6.739454\tIter time: 0.2919\n",
            "Training... Epoch: 1, Iter: 480,\t [15360/82081\t (19%)]\tLoss: 10.056211, Loc Loss: 2.985447, Conf Loss: 7.070764\tIter time: 0.3093\n",
            "Training... Epoch: 1, Iter: 490,\t [15680/82081\t (19%)]\tLoss: 8.833488, Loc Loss: 2.847982, Conf Loss: 5.985506\tIter time: 0.2701\n",
            "Training... Epoch: 1, Iter: 500,\t [16000/82081\t (19%)]\tLoss: 8.930172, Loc Loss: 2.787115, Conf Loss: 6.143057\tIter time: 0.2738\n",
            "Training... Epoch: 1, Iter: 510,\t [16320/82081\t (20%)]\tLoss: 8.630557, Loc Loss: 2.670601, Conf Loss: 5.959956\tIter time: 0.2722\n",
            "Training... Epoch: 1, Iter: 520,\t [16640/82081\t (20%)]\tLoss: 9.327735, Loc Loss: 3.343864, Conf Loss: 5.983871\tIter time: 0.2871\n",
            "Training... Epoch: 1, Iter: 530,\t [16960/82081\t (21%)]\tLoss: 9.181808, Loc Loss: 2.858006, Conf Loss: 6.323802\tIter time: 0.2954\n",
            "Training... Epoch: 1, Iter: 540,\t [17280/82081\t (21%)]\tLoss: 9.597548, Loc Loss: 3.035194, Conf Loss: 6.562354\tIter time: 0.2865\n",
            "Training... Epoch: 1, Iter: 550,\t [17600/82081\t (21%)]\tLoss: 8.777559, Loc Loss: 2.542840, Conf Loss: 6.234719\tIter time: 0.2962\n",
            "Training... Epoch: 1, Iter: 560,\t [17920/82081\t (22%)]\tLoss: 8.971853, Loc Loss: 2.664955, Conf Loss: 6.306899\tIter time: 0.2953\n",
            "Training... Epoch: 1, Iter: 570,\t [18240/82081\t (22%)]\tLoss: 9.142424, Loc Loss: 2.839195, Conf Loss: 6.303228\tIter time: 0.2803\n",
            "Training... Epoch: 1, Iter: 580,\t [18560/82081\t (23%)]\tLoss: 8.714150, Loc Loss: 2.665003, Conf Loss: 6.049148\tIter time: 0.2945\n",
            "Training... Epoch: 1, Iter: 590,\t [18880/82081\t (23%)]\tLoss: 8.032743, Loc Loss: 2.654260, Conf Loss: 5.378483\tIter time: 0.2860\n",
            "Training... Epoch: 1, Iter: 600,\t [19200/82081\t (23%)]\tLoss: 9.720312, Loc Loss: 3.052401, Conf Loss: 6.667912\tIter time: 0.2700\n",
            "Training... Epoch: 1, Iter: 610,\t [19520/82081\t (24%)]\tLoss: 8.906289, Loc Loss: 2.548620, Conf Loss: 6.357669\tIter time: 0.2914\n",
            "Training... Epoch: 1, Iter: 620,\t [19840/82081\t (24%)]\tLoss: 8.645969, Loc Loss: 2.604349, Conf Loss: 6.041620\tIter time: 0.2909\n",
            "Training... Epoch: 1, Iter: 630,\t [20160/82081\t (25%)]\tLoss: 8.366274, Loc Loss: 2.554384, Conf Loss: 5.811889\tIter time: 0.2869\n",
            "Training... Epoch: 1, Iter: 640,\t [20480/82081\t (25%)]\tLoss: 8.648423, Loc Loss: 2.378168, Conf Loss: 6.270255\tIter time: 0.2889\n",
            "Training... Epoch: 1, Iter: 650,\t [20800/82081\t (25%)]\tLoss: 8.470506, Loc Loss: 2.670721, Conf Loss: 5.799785\tIter time: 0.2874\n",
            "Training... Epoch: 1, Iter: 660,\t [21120/82081\t (26%)]\tLoss: 9.088507, Loc Loss: 2.686614, Conf Loss: 6.401894\tIter time: 0.2868\n",
            "Training... Epoch: 1, Iter: 670,\t [21440/82081\t (26%)]\tLoss: 8.787333, Loc Loss: 2.489010, Conf Loss: 6.298323\tIter time: 0.2664\n",
            "Training... Epoch: 1, Iter: 680,\t [21760/82081\t (27%)]\tLoss: 8.400326, Loc Loss: 2.296957, Conf Loss: 6.103369\tIter time: 0.2746\n",
            "Training... Epoch: 1, Iter: 690,\t [22080/82081\t (27%)]\tLoss: 8.243098, Loc Loss: 2.331135, Conf Loss: 5.911963\tIter time: 0.2863\n",
            "Training... Epoch: 1, Iter: 700,\t [22400/82081\t (27%)]\tLoss: 8.505457, Loc Loss: 2.649740, Conf Loss: 5.855717\tIter time: 0.2975\n",
            "Training... Epoch: 1, Iter: 710,\t [22720/82081\t (28%)]\tLoss: 8.585296, Loc Loss: 2.642540, Conf Loss: 5.942755\tIter time: 0.2951\n",
            "Training... Epoch: 1, Iter: 720,\t [23040/82081\t (28%)]\tLoss: 8.502661, Loc Loss: 2.584067, Conf Loss: 5.918594\tIter time: 0.2869\n",
            "Training... Epoch: 1, Iter: 730,\t [23360/82081\t (28%)]\tLoss: 8.420178, Loc Loss: 2.598066, Conf Loss: 5.822113\tIter time: 0.2892\n",
            "Training... Epoch: 1, Iter: 740,\t [23680/82081\t (29%)]\tLoss: 8.819096, Loc Loss: 3.095691, Conf Loss: 5.723404\tIter time: 0.2942\n",
            "Training... Epoch: 1, Iter: 750,\t [24000/82081\t (29%)]\tLoss: 8.582785, Loc Loss: 2.591404, Conf Loss: 5.991381\tIter time: 0.2853\n",
            "Training... Epoch: 1, Iter: 760,\t [24320/82081\t (30%)]\tLoss: 8.273486, Loc Loss: 2.447077, Conf Loss: 5.826410\tIter time: 0.2922\n",
            "Training... Epoch: 1, Iter: 770,\t [24640/82081\t (30%)]\tLoss: 8.745465, Loc Loss: 2.706808, Conf Loss: 6.038657\tIter time: 0.2840\n",
            "Training... Epoch: 1, Iter: 780,\t [24960/82081\t (30%)]\tLoss: 9.258711, Loc Loss: 2.645276, Conf Loss: 6.613435\tIter time: 0.2836\n",
            "Training... Epoch: 1, Iter: 790,\t [25280/82081\t (31%)]\tLoss: 8.792204, Loc Loss: 2.377898, Conf Loss: 6.414306\tIter time: 0.2741\n",
            "Training... Epoch: 1, Iter: 800,\t [25600/82081\t (31%)]\tLoss: 8.531245, Loc Loss: 2.548431, Conf Loss: 5.982814\tIter time: 0.2803\n",
            "Training... Epoch: 1, Iter: 810,\t [25920/82081\t (32%)]\tLoss: 8.470192, Loc Loss: 2.397391, Conf Loss: 6.072801\tIter time: 0.2823\n",
            "Training... Epoch: 1, Iter: 820,\t [26240/82081\t (32%)]\tLoss: 8.725442, Loc Loss: 2.422868, Conf Loss: 6.302575\tIter time: 0.2669\n",
            "Training... Epoch: 1, Iter: 830,\t [26560/82081\t (32%)]\tLoss: 8.623116, Loc Loss: 2.711150, Conf Loss: 5.911965\tIter time: 0.2917\n",
            "Training... Epoch: 1, Iter: 840,\t [26880/82081\t (33%)]\tLoss: 9.140463, Loc Loss: 2.617057, Conf Loss: 6.523406\tIter time: 0.2952\n",
            "Training... Epoch: 1, Iter: 850,\t [27200/82081\t (33%)]\tLoss: 8.844671, Loc Loss: 2.610861, Conf Loss: 6.233810\tIter time: 0.2825\n",
            "Training... Epoch: 1, Iter: 860,\t [27520/82081\t (34%)]\tLoss: 8.544504, Loc Loss: 2.485781, Conf Loss: 6.058722\tIter time: 0.2903\n",
            "Training... Epoch: 1, Iter: 870,\t [27840/82081\t (34%)]\tLoss: 8.161762, Loc Loss: 2.450401, Conf Loss: 5.711361\tIter time: 0.2729\n",
            "Training... Epoch: 1, Iter: 880,\t [28160/82081\t (34%)]\tLoss: 8.135626, Loc Loss: 2.436076, Conf Loss: 5.699550\tIter time: 0.3062\n",
            "Training... Epoch: 1, Iter: 890,\t [28480/82081\t (35%)]\tLoss: 7.868379, Loc Loss: 2.257002, Conf Loss: 5.611377\tIter time: 0.3076\n",
            "Training... Epoch: 1, Iter: 900,\t [28800/82081\t (35%)]\tLoss: 9.248621, Loc Loss: 2.823452, Conf Loss: 6.425170\tIter time: 0.2950\n",
            "Training... Epoch: 1, Iter: 910,\t [29120/82081\t (35%)]\tLoss: 7.667261, Loc Loss: 2.396252, Conf Loss: 5.271009\tIter time: 0.2894\n",
            "Training... Epoch: 1, Iter: 920,\t [29440/82081\t (36%)]\tLoss: 8.514001, Loc Loss: 2.641628, Conf Loss: 5.872373\tIter time: 0.2932\n",
            "Training... Epoch: 1, Iter: 930,\t [29760/82081\t (36%)]\tLoss: 8.173855, Loc Loss: 2.491637, Conf Loss: 5.682218\tIter time: 0.2900\n",
            "Training... Epoch: 1, Iter: 940,\t [30080/82081\t (37%)]\tLoss: 8.584321, Loc Loss: 2.517878, Conf Loss: 6.066443\tIter time: 0.2933\n",
            "Training... Epoch: 1, Iter: 950,\t [30400/82081\t (37%)]\tLoss: 8.446342, Loc Loss: 2.666741, Conf Loss: 5.779602\tIter time: 0.2912\n",
            "Training... Epoch: 1, Iter: 960,\t [30720/82081\t (37%)]\tLoss: 8.949298, Loc Loss: 2.891634, Conf Loss: 6.057664\tIter time: 0.2987\n",
            "Training... Epoch: 1, Iter: 970,\t [31040/82081\t (38%)]\tLoss: 8.052159, Loc Loss: 2.497012, Conf Loss: 5.555147\tIter time: 0.2689\n",
            "Training... Epoch: 1, Iter: 980,\t [31360/82081\t (38%)]\tLoss: 8.159823, Loc Loss: 2.562839, Conf Loss: 5.596984\tIter time: 0.2903\n",
            "Training... Epoch: 1, Iter: 990,\t [31680/82081\t (39%)]\tLoss: 8.547762, Loc Loss: 2.460987, Conf Loss: 6.086775\tIter time: 0.2882\n",
            "Training... Epoch: 1, Iter: 1000,\t [32000/82081\t (39%)]\tLoss: 8.510378, Loc Loss: 2.427610, Conf Loss: 6.082768\tIter time: 0.2858\n",
            "Training... Epoch: 1, Iter: 1010,\t [32320/82081\t (39%)]\tLoss: 8.148250, Loc Loss: 2.404698, Conf Loss: 5.743552\tIter time: 0.2946\n",
            "Training... Epoch: 1, Iter: 1020,\t [32640/82081\t (40%)]\tLoss: 8.161820, Loc Loss: 2.598842, Conf Loss: 5.562978\tIter time: 0.2687\n",
            "Training... Epoch: 1, Iter: 1030,\t [32960/82081\t (40%)]\tLoss: 8.406565, Loc Loss: 2.268161, Conf Loss: 6.138403\tIter time: 0.2864\n",
            "Training... Epoch: 1, Iter: 1040,\t [33280/82081\t (41%)]\tLoss: 8.325493, Loc Loss: 2.474113, Conf Loss: 5.851380\tIter time: 0.2766\n",
            "Training... Epoch: 1, Iter: 1050,\t [33600/82081\t (41%)]\tLoss: 8.006084, Loc Loss: 2.492946, Conf Loss: 5.513139\tIter time: 0.2801\n",
            "Training... Epoch: 1, Iter: 1060,\t [33920/82081\t (41%)]\tLoss: 8.700635, Loc Loss: 2.538015, Conf Loss: 6.162620\tIter time: 0.2692\n",
            "Training... Epoch: 1, Iter: 1070,\t [34240/82081\t (42%)]\tLoss: 8.177092, Loc Loss: 2.457711, Conf Loss: 5.719381\tIter time: 0.2894\n",
            "Training... Epoch: 1, Iter: 1080,\t [34560/82081\t (42%)]\tLoss: 8.531653, Loc Loss: 2.756944, Conf Loss: 5.774709\tIter time: 0.2974\n",
            "Training... Epoch: 1, Iter: 1090,\t [34880/82081\t (42%)]\tLoss: 8.295738, Loc Loss: 2.708322, Conf Loss: 5.587417\tIter time: 0.2837\n",
            "Training... Epoch: 1, Iter: 1100,\t [35200/82081\t (43%)]\tLoss: 8.082962, Loc Loss: 2.312849, Conf Loss: 5.770113\tIter time: 0.3479\n",
            "Training... Epoch: 1, Iter: 1110,\t [35520/82081\t (43%)]\tLoss: 8.365675, Loc Loss: 2.504847, Conf Loss: 5.860828\tIter time: 0.2922\n",
            "Training... Epoch: 1, Iter: 1120,\t [35840/82081\t (44%)]\tLoss: 8.319439, Loc Loss: 2.602698, Conf Loss: 5.716741\tIter time: 0.2770\n",
            "Training... Epoch: 1, Iter: 1130,\t [36160/82081\t (44%)]\tLoss: 9.008692, Loc Loss: 2.695701, Conf Loss: 6.312990\tIter time: 0.2932\n",
            "Training... Epoch: 1, Iter: 1140,\t [36480/82081\t (44%)]\tLoss: 8.086394, Loc Loss: 2.312328, Conf Loss: 5.774066\tIter time: 0.2810\n",
            "Training... Epoch: 1, Iter: 1150,\t [36800/82081\t (45%)]\tLoss: 8.335586, Loc Loss: 2.365579, Conf Loss: 5.970006\tIter time: 0.2821\n",
            "Training... Epoch: 1, Iter: 1160,\t [37120/82081\t (45%)]\tLoss: 9.033330, Loc Loss: 2.804741, Conf Loss: 6.228589\tIter time: 0.2856\n",
            "Training... Epoch: 1, Iter: 1170,\t [37440/82081\t (46%)]\tLoss: 8.982877, Loc Loss: 2.951332, Conf Loss: 6.031545\tIter time: 0.2980\n",
            "Training... Epoch: 1, Iter: 1180,\t [37760/82081\t (46%)]\tLoss: 8.864378, Loc Loss: 2.961657, Conf Loss: 5.902722\tIter time: 0.2922\n",
            "Training... Epoch: 1, Iter: 1190,\t [38080/82081\t (46%)]\tLoss: 7.992901, Loc Loss: 2.321526, Conf Loss: 5.671376\tIter time: 0.2718\n",
            "Training... Epoch: 1, Iter: 1200,\t [38400/82081\t (47%)]\tLoss: 8.049512, Loc Loss: 2.710900, Conf Loss: 5.338612\tIter time: 0.2831\n",
            "Training... Epoch: 1, Iter: 1210,\t [38720/82081\t (47%)]\tLoss: 8.172101, Loc Loss: 2.435303, Conf Loss: 5.736798\tIter time: 0.2914\n",
            "Training... Epoch: 1, Iter: 1220,\t [39040/82081\t (48%)]\tLoss: 8.276304, Loc Loss: 2.664389, Conf Loss: 5.611916\tIter time: 0.2695\n",
            "Training... Epoch: 1, Iter: 1230,\t [39360/82081\t (48%)]\tLoss: 8.196682, Loc Loss: 2.423957, Conf Loss: 5.772726\tIter time: 0.2809\n",
            "Training... Epoch: 1, Iter: 1240,\t [39680/82081\t (48%)]\tLoss: 8.087529, Loc Loss: 2.542642, Conf Loss: 5.544888\tIter time: 0.2696\n",
            "Training... Epoch: 1, Iter: 1250,\t [40000/82081\t (49%)]\tLoss: 8.238304, Loc Loss: 2.398846, Conf Loss: 5.839458\tIter time: 0.2851\n",
            "Training... Epoch: 1, Iter: 1260,\t [40320/82081\t (49%)]\tLoss: 8.247004, Loc Loss: 2.387578, Conf Loss: 5.859426\tIter time: 0.2659\n",
            "Training... Epoch: 1, Iter: 1270,\t [40640/82081\t (49%)]\tLoss: 8.324441, Loc Loss: 2.630121, Conf Loss: 5.694320\tIter time: 0.2862\n",
            "Training... Epoch: 1, Iter: 1280,\t [40960/82081\t (50%)]\tLoss: 8.178779, Loc Loss: 2.472479, Conf Loss: 5.706299\tIter time: 0.2999\n",
            "Training... Epoch: 1, Iter: 1290,\t [41280/82081\t (50%)]\tLoss: 8.518199, Loc Loss: 2.654211, Conf Loss: 5.863988\tIter time: 0.2963\n",
            "Training... Epoch: 1, Iter: 1300,\t [41600/82081\t (51%)]\tLoss: 8.872697, Loc Loss: 2.660101, Conf Loss: 6.212596\tIter time: 0.3004\n",
            "Training... Epoch: 1, Iter: 1310,\t [41920/82081\t (51%)]\tLoss: 8.079077, Loc Loss: 2.245218, Conf Loss: 5.833859\tIter time: 0.2971\n",
            "Training... Epoch: 1, Iter: 1320,\t [42240/82081\t (51%)]\tLoss: 8.193452, Loc Loss: 2.357204, Conf Loss: 5.836248\tIter time: 0.2941\n",
            "Training... Epoch: 1, Iter: 1330,\t [42560/82081\t (52%)]\tLoss: 8.485023, Loc Loss: 2.399643, Conf Loss: 6.085381\tIter time: 0.2850\n",
            "Training... Epoch: 1, Iter: 1340,\t [42880/82081\t (52%)]\tLoss: 8.381071, Loc Loss: 2.451637, Conf Loss: 5.929435\tIter time: 0.2970\n",
            "Training... Epoch: 1, Iter: 1350,\t [43200/82081\t (53%)]\tLoss: 8.370498, Loc Loss: 2.516205, Conf Loss: 5.854293\tIter time: 0.2878\n",
            "Training... Epoch: 1, Iter: 1360,\t [43520/82081\t (53%)]\tLoss: 8.357080, Loc Loss: 2.487717, Conf Loss: 5.869364\tIter time: 0.3167\n",
            "Training... Epoch: 1, Iter: 1370,\t [43840/82081\t (53%)]\tLoss: 8.074409, Loc Loss: 2.402411, Conf Loss: 5.671999\tIter time: 0.2694\n",
            "Training... Epoch: 1, Iter: 1380,\t [44160/82081\t (54%)]\tLoss: 8.206716, Loc Loss: 2.327168, Conf Loss: 5.879548\tIter time: 0.2925\n",
            "Training... Epoch: 1, Iter: 1390,\t [44480/82081\t (54%)]\tLoss: 8.080652, Loc Loss: 2.583618, Conf Loss: 5.497034\tIter time: 0.3086\n",
            "Training... Epoch: 1, Iter: 1400,\t [44800/82081\t (55%)]\tLoss: 7.818338, Loc Loss: 2.351589, Conf Loss: 5.466749\tIter time: 0.2939\n",
            "Training... Epoch: 1, Iter: 1410,\t [45120/82081\t (55%)]\tLoss: 7.852481, Loc Loss: 2.521610, Conf Loss: 5.330871\tIter time: 0.2731\n",
            "Training... Epoch: 1, Iter: 1420,\t [45440/82081\t (55%)]\tLoss: 8.187128, Loc Loss: 2.310016, Conf Loss: 5.877111\tIter time: 0.2983\n",
            "Training... Epoch: 1, Iter: 1430,\t [45760/82081\t (56%)]\tLoss: 8.049704, Loc Loss: 2.251454, Conf Loss: 5.798250\tIter time: 0.2965\n",
            "Training... Epoch: 1, Iter: 1440,\t [46080/82081\t (56%)]\tLoss: 8.310305, Loc Loss: 2.561079, Conf Loss: 5.749226\tIter time: 0.2936\n",
            "Training... Epoch: 1, Iter: 1450,\t [46400/82081\t (57%)]\tLoss: 8.020024, Loc Loss: 2.272502, Conf Loss: 5.747522\tIter time: 0.2809\n",
            "Training... Epoch: 1, Iter: 1460,\t [46720/82081\t (57%)]\tLoss: 8.291798, Loc Loss: 2.351935, Conf Loss: 5.939863\tIter time: 0.2886\n",
            "Training... Epoch: 1, Iter: 1470,\t [47040/82081\t (57%)]\tLoss: 7.746192, Loc Loss: 2.113126, Conf Loss: 5.633066\tIter time: 0.2944\n",
            "Training... Epoch: 1, Iter: 1480,\t [47360/82081\t (58%)]\tLoss: 8.029846, Loc Loss: 2.219235, Conf Loss: 5.810611\tIter time: 0.3217\n",
            "Training... Epoch: 1, Iter: 1490,\t [47680/82081\t (58%)]\tLoss: 8.185788, Loc Loss: 2.313225, Conf Loss: 5.872563\tIter time: 0.3022\n",
            "Training... Epoch: 1, Iter: 1500,\t [48000/82081\t (58%)]\tLoss: 8.138846, Loc Loss: 2.204027, Conf Loss: 5.934819\tIter time: 0.2928\n",
            "Training... Epoch: 1, Iter: 1510,\t [48320/82081\t (59%)]\tLoss: 7.701594, Loc Loss: 2.316779, Conf Loss: 5.384816\tIter time: 0.2674\n",
            "Training... Epoch: 1, Iter: 1520,\t [48640/82081\t (59%)]\tLoss: 8.122574, Loc Loss: 2.352912, Conf Loss: 5.769661\tIter time: 0.2971\n",
            "Training... Epoch: 1, Iter: 1530,\t [48960/82081\t (60%)]\tLoss: 8.585174, Loc Loss: 2.416759, Conf Loss: 6.168415\tIter time: 0.2992\n",
            "Training... Epoch: 1, Iter: 1540,\t [49280/82081\t (60%)]\tLoss: 8.153566, Loc Loss: 2.336027, Conf Loss: 5.817539\tIter time: 0.2892\n",
            "Training... Epoch: 1, Iter: 1550,\t [49600/82081\t (60%)]\tLoss: 8.256939, Loc Loss: 2.460782, Conf Loss: 5.796157\tIter time: 0.2780\n",
            "Training... Epoch: 1, Iter: 1560,\t [49920/82081\t (61%)]\tLoss: 7.595868, Loc Loss: 2.390652, Conf Loss: 5.205216\tIter time: 0.2828\n",
            "Training... Epoch: 1, Iter: 1570,\t [50240/82081\t (61%)]\tLoss: 8.003269, Loc Loss: 2.200954, Conf Loss: 5.802314\tIter time: 0.2677\n",
            "Training... Epoch: 1, Iter: 1580,\t [50560/82081\t (62%)]\tLoss: 8.316496, Loc Loss: 2.475771, Conf Loss: 5.840725\tIter time: 0.2927\n",
            "Training... Epoch: 1, Iter: 1590,\t [50880/82081\t (62%)]\tLoss: 7.921638, Loc Loss: 2.414467, Conf Loss: 5.507172\tIter time: 0.2957\n",
            "Training... Epoch: 1, Iter: 1600,\t [51200/82081\t (62%)]\tLoss: 8.215575, Loc Loss: 2.235933, Conf Loss: 5.979643\tIter time: 0.2831\n",
            "Training... Epoch: 1, Iter: 1610,\t [51520/82081\t (63%)]\tLoss: 8.452238, Loc Loss: 2.972684, Conf Loss: 5.479554\tIter time: 0.2933\n",
            "Training... Epoch: 1, Iter: 1620,\t [51840/82081\t (63%)]\tLoss: 8.110791, Loc Loss: 2.261924, Conf Loss: 5.848867\tIter time: 0.2883\n",
            "Training... Epoch: 1, Iter: 1630,\t [52160/82081\t (64%)]\tLoss: 8.219809, Loc Loss: 2.207557, Conf Loss: 6.012252\tIter time: 0.2756\n",
            "Training... Epoch: 1, Iter: 1640,\t [52480/82081\t (64%)]\tLoss: 7.777537, Loc Loss: 2.183986, Conf Loss: 5.593552\tIter time: 0.2871\n",
            "Training... Epoch: 1, Iter: 1650,\t [52800/82081\t (64%)]\tLoss: 8.026903, Loc Loss: 2.184016, Conf Loss: 5.842887\tIter time: 0.2928\n",
            "Training... Epoch: 1, Iter: 1660,\t [53120/82081\t (65%)]\tLoss: 8.492188, Loc Loss: 2.386987, Conf Loss: 6.105201\tIter time: 0.2904\n",
            "Training... Epoch: 1, Iter: 1670,\t [53440/82081\t (65%)]\tLoss: 8.320560, Loc Loss: 2.346918, Conf Loss: 5.973642\tIter time: 0.2972\n",
            "Training... Epoch: 1, Iter: 1680,\t [53760/82081\t (65%)]\tLoss: 8.202671, Loc Loss: 2.379559, Conf Loss: 5.823112\tIter time: 0.2714\n",
            "Training... Epoch: 1, Iter: 1690,\t [54080/82081\t (66%)]\tLoss: 7.966043, Loc Loss: 2.245882, Conf Loss: 5.720160\tIter time: 0.2888\n",
            "Training... Epoch: 1, Iter: 1700,\t [54400/82081\t (66%)]\tLoss: 8.580723, Loc Loss: 2.538793, Conf Loss: 6.041930\tIter time: 0.2829\n",
            "Training... Epoch: 1, Iter: 1710,\t [54720/82081\t (67%)]\tLoss: 7.980786, Loc Loss: 2.284748, Conf Loss: 5.696038\tIter time: 0.2776\n",
            "Training... Epoch: 1, Iter: 1720,\t [55040/82081\t (67%)]\tLoss: 8.073190, Loc Loss: 2.470651, Conf Loss: 5.602539\tIter time: 0.2963\n",
            "Training... Epoch: 1, Iter: 1730,\t [55360/82081\t (67%)]\tLoss: 7.989886, Loc Loss: 2.272074, Conf Loss: 5.717813\tIter time: 0.2750\n",
            "Training... Epoch: 1, Iter: 1740,\t [55680/82081\t (68%)]\tLoss: 7.624386, Loc Loss: 2.223913, Conf Loss: 5.400473\tIter time: 0.2863\n",
            "Training... Epoch: 1, Iter: 1750,\t [56000/82081\t (68%)]\tLoss: 8.067979, Loc Loss: 2.208621, Conf Loss: 5.859358\tIter time: 0.2860\n",
            "Training... Epoch: 1, Iter: 1760,\t [56320/82081\t (69%)]\tLoss: 7.578572, Loc Loss: 2.332210, Conf Loss: 5.246362\tIter time: 0.2835\n",
            "Training... Epoch: 1, Iter: 1770,\t [56640/82081\t (69%)]\tLoss: 8.636283, Loc Loss: 2.626578, Conf Loss: 6.009705\tIter time: 0.3157\n",
            "Training... Epoch: 1, Iter: 1780,\t [56960/82081\t (69%)]\tLoss: 8.268380, Loc Loss: 2.114515, Conf Loss: 6.153865\tIter time: 0.3003\n",
            "Training... Epoch: 1, Iter: 1790,\t [57280/82081\t (70%)]\tLoss: 7.610970, Loc Loss: 2.213856, Conf Loss: 5.397114\tIter time: 0.2846\n",
            "Training... Epoch: 1, Iter: 1800,\t [57600/82081\t (70%)]\tLoss: 8.083692, Loc Loss: 2.432722, Conf Loss: 5.650970\tIter time: 0.2793\n",
            "Training... Epoch: 1, Iter: 1810,\t [57920/82081\t (71%)]\tLoss: 8.104795, Loc Loss: 2.567356, Conf Loss: 5.537439\tIter time: 0.2896\n",
            "Training... Epoch: 1, Iter: 1820,\t [58240/82081\t (71%)]\tLoss: 7.418683, Loc Loss: 2.055581, Conf Loss: 5.363102\tIter time: 0.2902\n",
            "Training... Epoch: 1, Iter: 1830,\t [58560/82081\t (71%)]\tLoss: 8.029998, Loc Loss: 2.075627, Conf Loss: 5.954370\tIter time: 0.2944\n",
            "Training... Epoch: 1, Iter: 1840,\t [58880/82081\t (72%)]\tLoss: 8.023619, Loc Loss: 2.341799, Conf Loss: 5.681819\tIter time: 0.2903\n",
            "Training... Epoch: 1, Iter: 1850,\t [59200/82081\t (72%)]\tLoss: 7.534584, Loc Loss: 2.354954, Conf Loss: 5.179630\tIter time: 0.2872\n",
            "Training... Epoch: 1, Iter: 1860,\t [59520/82081\t (72%)]\tLoss: 8.127506, Loc Loss: 2.375029, Conf Loss: 5.752477\tIter time: 0.3002\n",
            "Training... Epoch: 1, Iter: 1870,\t [59840/82081\t (73%)]\tLoss: 8.042454, Loc Loss: 2.282530, Conf Loss: 5.759923\tIter time: 0.2711\n",
            "Training... Epoch: 1, Iter: 1880,\t [60160/82081\t (73%)]\tLoss: 8.216085, Loc Loss: 2.302263, Conf Loss: 5.913822\tIter time: 0.2692\n",
            "Training... Epoch: 1, Iter: 1890,\t [60480/82081\t (74%)]\tLoss: 6.831469, Loc Loss: 1.950582, Conf Loss: 4.880887\tIter time: 0.2902\n",
            "Training... Epoch: 1, Iter: 1900,\t [60800/82081\t (74%)]\tLoss: 8.420137, Loc Loss: 2.580823, Conf Loss: 5.839314\tIter time: 0.2799\n",
            "Training... Epoch: 1, Iter: 1910,\t [61120/82081\t (74%)]\tLoss: 7.756643, Loc Loss: 2.227131, Conf Loss: 5.529512\tIter time: 0.2697\n",
            "Training... Epoch: 1, Iter: 1920,\t [61440/82081\t (75%)]\tLoss: 7.490758, Loc Loss: 2.148186, Conf Loss: 5.342572\tIter time: 0.2700\n",
            "Training... Epoch: 1, Iter: 1930,\t [61760/82081\t (75%)]\tLoss: 8.136970, Loc Loss: 2.304124, Conf Loss: 5.832846\tIter time: 0.2696\n",
            "Training... Epoch: 1, Iter: 1940,\t [62080/82081\t (76%)]\tLoss: 7.840600, Loc Loss: 2.250375, Conf Loss: 5.590226\tIter time: 0.2702\n",
            "Training... Epoch: 1, Iter: 1950,\t [62400/82081\t (76%)]\tLoss: 7.982606, Loc Loss: 2.102486, Conf Loss: 5.880121\tIter time: 0.2894\n",
            "Training... Epoch: 1, Iter: 1960,\t [62720/82081\t (76%)]\tLoss: 8.730232, Loc Loss: 2.601724, Conf Loss: 6.128508\tIter time: 0.2865\n",
            "Training... Epoch: 1, Iter: 1970,\t [63040/82081\t (77%)]\tLoss: 7.570740, Loc Loss: 2.094697, Conf Loss: 5.476043\tIter time: 0.2936\n",
            "Training... Epoch: 1, Iter: 1980,\t [63360/82081\t (77%)]\tLoss: 7.590818, Loc Loss: 2.029182, Conf Loss: 5.561636\tIter time: 0.2674\n",
            "Training... Epoch: 1, Iter: 1990,\t [63680/82081\t (78%)]\tLoss: 7.701386, Loc Loss: 2.304928, Conf Loss: 5.396459\tIter time: 0.2851\n",
            "Training... Epoch: 1, Iter: 2000,\t [64000/82081\t (78%)]\tLoss: 8.217512, Loc Loss: 2.388119, Conf Loss: 5.829393\tIter time: 0.2932\n",
            "Training... Epoch: 1, Iter: 2010,\t [64320/82081\t (78%)]\tLoss: 8.272980, Loc Loss: 2.703358, Conf Loss: 5.569623\tIter time: 0.2753\n",
            "Training... Epoch: 1, Iter: 2020,\t [64640/82081\t (79%)]\tLoss: 8.284468, Loc Loss: 2.489954, Conf Loss: 5.794514\tIter time: 0.2953\n",
            "Training... Epoch: 1, Iter: 2030,\t [64960/82081\t (79%)]\tLoss: 8.755555, Loc Loss: 2.770564, Conf Loss: 5.984992\tIter time: 0.2788\n",
            "Training... Epoch: 1, Iter: 2040,\t [65280/82081\t (80%)]\tLoss: 8.342332, Loc Loss: 2.320357, Conf Loss: 6.021975\tIter time: 0.3031\n",
            "Training... Epoch: 1, Iter: 2050,\t [65600/82081\t (80%)]\tLoss: 8.088493, Loc Loss: 2.297079, Conf Loss: 5.791414\tIter time: 0.2746\n",
            "Training... Epoch: 1, Iter: 2060,\t [65920/82081\t (80%)]\tLoss: 7.904789, Loc Loss: 2.479068, Conf Loss: 5.425721\tIter time: 0.2750\n",
            "Training... Epoch: 1, Iter: 2070,\t [66240/82081\t (81%)]\tLoss: 7.833980, Loc Loss: 2.403367, Conf Loss: 5.430613\tIter time: 0.2721\n",
            "Training... Epoch: 1, Iter: 2080,\t [66560/82081\t (81%)]\tLoss: 7.721360, Loc Loss: 2.278724, Conf Loss: 5.442636\tIter time: 0.2717\n",
            "Training... Epoch: 1, Iter: 2090,\t [66880/82081\t (81%)]\tLoss: 7.003693, Loc Loss: 1.963345, Conf Loss: 5.040348\tIter time: 0.2851\n",
            "Training... Epoch: 1, Iter: 2100,\t [67200/82081\t (82%)]\tLoss: 7.882845, Loc Loss: 2.332668, Conf Loss: 5.550177\tIter time: 0.2797\n",
            "Training... Epoch: 1, Iter: 2110,\t [67520/82081\t (82%)]\tLoss: 7.836486, Loc Loss: 2.422160, Conf Loss: 5.414326\tIter time: 0.2950\n",
            "Training... Epoch: 1, Iter: 2120,\t [67840/82081\t (83%)]\tLoss: 7.612889, Loc Loss: 2.502444, Conf Loss: 5.110445\tIter time: 0.2929\n",
            "Training... Epoch: 1, Iter: 2130,\t [68160/82081\t (83%)]\tLoss: 7.805917, Loc Loss: 2.230487, Conf Loss: 5.575430\tIter time: 0.2712\n",
            "Training... Epoch: 1, Iter: 2140,\t [68480/82081\t (83%)]\tLoss: 7.741789, Loc Loss: 2.409945, Conf Loss: 5.331844\tIter time: 0.2759\n",
            "Training... Epoch: 1, Iter: 2150,\t [68800/82081\t (84%)]\tLoss: 7.451641, Loc Loss: 2.348292, Conf Loss: 5.103349\tIter time: 0.2905\n",
            "Training... Epoch: 1, Iter: 2160,\t [69120/82081\t (84%)]\tLoss: 7.437681, Loc Loss: 2.402011, Conf Loss: 5.035669\tIter time: 0.2812\n",
            "Training... Epoch: 1, Iter: 2170,\t [69440/82081\t (85%)]\tLoss: 8.193556, Loc Loss: 2.433270, Conf Loss: 5.760286\tIter time: 0.3091\n",
            "Training... Epoch: 1, Iter: 2180,\t [69760/82081\t (85%)]\tLoss: 7.959261, Loc Loss: 2.445210, Conf Loss: 5.514050\tIter time: 0.2964\n",
            "Training... Epoch: 1, Iter: 2190,\t [70080/82081\t (85%)]\tLoss: 8.270100, Loc Loss: 2.614587, Conf Loss: 5.655512\tIter time: 0.2973\n",
            "Training... Epoch: 1, Iter: 2200,\t [70400/82081\t (86%)]\tLoss: 7.688563, Loc Loss: 2.467890, Conf Loss: 5.220673\tIter time: 0.2915\n",
            "Training... Epoch: 1, Iter: 2210,\t [70720/82081\t (86%)]\tLoss: 7.646166, Loc Loss: 2.498033, Conf Loss: 5.148133\tIter time: 0.2928\n",
            "Training... Epoch: 1, Iter: 2220,\t [71040/82081\t (87%)]\tLoss: 8.295980, Loc Loss: 2.431230, Conf Loss: 5.864750\tIter time: 0.2722\n",
            "Training... Epoch: 1, Iter: 2230,\t [71360/82081\t (87%)]\tLoss: 8.261522, Loc Loss: 2.115686, Conf Loss: 6.145836\tIter time: 0.2874\n",
            "Training... Epoch: 1, Iter: 2240,\t [71680/82081\t (87%)]\tLoss: 8.160526, Loc Loss: 2.358356, Conf Loss: 5.802169\tIter time: 0.2946\n",
            "Training... Epoch: 1, Iter: 2250,\t [72000/82081\t (88%)]\tLoss: 7.637882, Loc Loss: 2.434206, Conf Loss: 5.203676\tIter time: 0.3195\n",
            "Training... Epoch: 1, Iter: 2260,\t [72320/82081\t (88%)]\tLoss: 7.986752, Loc Loss: 2.449709, Conf Loss: 5.537043\tIter time: 0.2695\n",
            "Training... Epoch: 1, Iter: 2270,\t [72640/82081\t (88%)]\tLoss: 7.696875, Loc Loss: 2.074203, Conf Loss: 5.622672\tIter time: 0.2821\n",
            "Training... Epoch: 1, Iter: 2280,\t [72960/82081\t (89%)]\tLoss: 7.763581, Loc Loss: 2.400484, Conf Loss: 5.363097\tIter time: 0.2939\n",
            "Training... Epoch: 1, Iter: 2290,\t [73280/82081\t (89%)]\tLoss: 8.073681, Loc Loss: 2.612401, Conf Loss: 5.461280\tIter time: 0.2881\n",
            "Training... Epoch: 1, Iter: 2300,\t [73600/82081\t (90%)]\tLoss: 7.833847, Loc Loss: 2.333461, Conf Loss: 5.500385\tIter time: 0.2866\n",
            "Training... Epoch: 1, Iter: 2310,\t [73920/82081\t (90%)]\tLoss: 7.519184, Loc Loss: 2.186117, Conf Loss: 5.333067\tIter time: 0.2678\n",
            "Training... Epoch: 1, Iter: 2320,\t [74240/82081\t (90%)]\tLoss: 7.965632, Loc Loss: 2.592063, Conf Loss: 5.373569\tIter time: 0.2923\n",
            "Training... Epoch: 1, Iter: 2330,\t [74560/82081\t (91%)]\tLoss: 7.863554, Loc Loss: 2.507517, Conf Loss: 5.356037\tIter time: 0.2905\n",
            "Training... Epoch: 1, Iter: 2340,\t [74880/82081\t (91%)]\tLoss: 7.282797, Loc Loss: 2.228444, Conf Loss: 5.054353\tIter time: 0.2782\n",
            "Training... Epoch: 1, Iter: 2350,\t [75200/82081\t (92%)]\tLoss: 8.190813, Loc Loss: 2.281178, Conf Loss: 5.909635\tIter time: 0.2810\n",
            "Training... Epoch: 1, Iter: 2360,\t [75520/82081\t (92%)]\tLoss: 7.494507, Loc Loss: 2.270115, Conf Loss: 5.224391\tIter time: 0.2723\n",
            "Training... Epoch: 1, Iter: 2370,\t [75840/82081\t (92%)]\tLoss: 7.373256, Loc Loss: 2.162297, Conf Loss: 5.210959\tIter time: 0.2899\n",
            "Training... Epoch: 1, Iter: 2380,\t [76160/82081\t (93%)]\tLoss: 7.872808, Loc Loss: 2.161820, Conf Loss: 5.710988\tIter time: 0.2816\n",
            "Training... Epoch: 1, Iter: 2390,\t [76480/82081\t (93%)]\tLoss: 7.708180, Loc Loss: 2.310620, Conf Loss: 5.397561\tIter time: 0.2834\n",
            "Training... Epoch: 1, Iter: 2400,\t [76800/82081\t (94%)]\tLoss: 8.187946, Loc Loss: 2.239661, Conf Loss: 5.948285\tIter time: 0.2904\n",
            "Training... Epoch: 1, Iter: 2410,\t [77120/82081\t (94%)]\tLoss: 7.713224, Loc Loss: 2.303949, Conf Loss: 5.409276\tIter time: 0.3035\n",
            "Training... Epoch: 1, Iter: 2420,\t [77440/82081\t (94%)]\tLoss: 7.794961, Loc Loss: 2.512948, Conf Loss: 5.282013\tIter time: 0.2838\n",
            "Training... Epoch: 1, Iter: 2430,\t [77760/82081\t (95%)]\tLoss: 7.585237, Loc Loss: 2.388109, Conf Loss: 5.197127\tIter time: 0.2718\n",
            "Training... Epoch: 1, Iter: 2440,\t [78080/82081\t (95%)]\tLoss: 8.055601, Loc Loss: 2.340302, Conf Loss: 5.715299\tIter time: 0.2868\n",
            "Training... Epoch: 1, Iter: 2450,\t [78400/82081\t (95%)]\tLoss: 8.034026, Loc Loss: 2.341586, Conf Loss: 5.692440\tIter time: 0.2765\n",
            "Training... Epoch: 1, Iter: 2460,\t [78720/82081\t (96%)]\tLoss: 8.189241, Loc Loss: 2.627573, Conf Loss: 5.561668\tIter time: 0.2803\n",
            "Training... Epoch: 1, Iter: 2470,\t [79040/82081\t (96%)]\tLoss: 7.874421, Loc Loss: 2.448044, Conf Loss: 5.426377\tIter time: 0.2898\n",
            "Training... Epoch: 1, Iter: 2480,\t [79360/82081\t (97%)]\tLoss: 7.701740, Loc Loss: 2.070496, Conf Loss: 5.631245\tIter time: 0.2759\n",
            "Training... Epoch: 1, Iter: 2490,\t [79680/82081\t (97%)]\tLoss: 7.762021, Loc Loss: 2.467427, Conf Loss: 5.294594\tIter time: 0.2958\n",
            "Training... Epoch: 1, Iter: 2500,\t [80000/82081\t (97%)]\tLoss: 7.609703, Loc Loss: 1.875031, Conf Loss: 5.734672\tIter time: 0.2725\n",
            "Training... Epoch: 1, Iter: 2510,\t [80320/82081\t (98%)]\tLoss: 7.388770, Loc Loss: 2.181819, Conf Loss: 5.206950\tIter time: 0.2878\n",
            "Training... Epoch: 1, Iter: 2520,\t [80640/82081\t (98%)]\tLoss: 7.626178, Loc Loss: 2.532539, Conf Loss: 5.093639\tIter time: 0.2739\n",
            "Training... Epoch: 1, Iter: 2530,\t [80960/82081\t (99%)]\tLoss: 8.077827, Loc Loss: 2.597432, Conf Loss: 5.480395\tIter time: 0.2886\n",
            "Training... Epoch: 1, Iter: 2540,\t [81280/82081\t (99%)]\tLoss: 7.646493, Loc Loss: 2.318521, Conf Loss: 5.327973\tIter time: 0.2810\n",
            "Training... Epoch: 1, Iter: 2550,\t [81600/82081\t (99%)]\tLoss: 7.343305, Loc Loss: 2.314788, Conf Loss: 5.028517\tIter time: 0.2911\n",
            "Training... Epoch: 1, Iter: 2560,\t [81920/82081\t (100%)]\tLoss: 8.440550, Loc Loss: 2.330253, Conf Loss: 6.110296\tIter time: 0.2662\n",
            "Training... Epoch: 2, Iter: 2570,\t [128/82081\t (0%)]\tLoss: 7.890782, Loc Loss: 2.325899, Conf Loss: 5.564883\tIter time: 0.3046\n",
            "Training... Epoch: 2, Iter: 2580,\t [448/82081\t (1%)]\tLoss: 7.490275, Loc Loss: 2.212548, Conf Loss: 5.277727\tIter time: 0.2930\n",
            "Training... Epoch: 2, Iter: 2590,\t [768/82081\t (1%)]\tLoss: 7.346948, Loc Loss: 2.405456, Conf Loss: 4.941492\tIter time: 0.2903\n",
            "Training... Epoch: 2, Iter: 2600,\t [1088/82081\t (1%)]\tLoss: 7.934934, Loc Loss: 2.135078, Conf Loss: 5.799856\tIter time: 0.2890\n",
            "Training... Epoch: 2, Iter: 2610,\t [1408/82081\t (2%)]\tLoss: 7.944469, Loc Loss: 2.226731, Conf Loss: 5.717738\tIter time: 0.2957\n",
            "Training... Epoch: 2, Iter: 2620,\t [1728/82081\t (2%)]\tLoss: 7.657828, Loc Loss: 2.561570, Conf Loss: 5.096258\tIter time: 0.2918\n",
            "Training... Epoch: 2, Iter: 2630,\t [2048/82081\t (2%)]\tLoss: 7.731351, Loc Loss: 2.184646, Conf Loss: 5.546705\tIter time: 0.2897\n",
            "Training... Epoch: 2, Iter: 2640,\t [2368/82081\t (3%)]\tLoss: 8.046191, Loc Loss: 2.792259, Conf Loss: 5.253932\tIter time: 0.2806\n",
            "Training... Epoch: 2, Iter: 2650,\t [2688/82081\t (3%)]\tLoss: 7.811810, Loc Loss: 2.298455, Conf Loss: 5.513356\tIter time: 0.2911\n",
            "Training... Epoch: 2, Iter: 2660,\t [3008/82081\t (4%)]\tLoss: 7.837492, Loc Loss: 2.448445, Conf Loss: 5.389047\tIter time: 0.2869\n",
            "Training... Epoch: 2, Iter: 2670,\t [3328/82081\t (4%)]\tLoss: 8.002696, Loc Loss: 2.355582, Conf Loss: 5.647114\tIter time: 0.2960\n",
            "Training... Epoch: 2, Iter: 2680,\t [3648/82081\t (4%)]\tLoss: 8.058084, Loc Loss: 2.173050, Conf Loss: 5.885034\tIter time: 0.2886\n",
            "Training... Epoch: 2, Iter: 2690,\t [3968/82081\t (5%)]\tLoss: 7.448336, Loc Loss: 2.117656, Conf Loss: 5.330679\tIter time: 0.2848\n",
            "Training... Epoch: 2, Iter: 2700,\t [4288/82081\t (5%)]\tLoss: 6.964305, Loc Loss: 2.177654, Conf Loss: 4.786651\tIter time: 0.3100\n",
            "Training... Epoch: 2, Iter: 2710,\t [4608/82081\t (6%)]\tLoss: 7.555069, Loc Loss: 2.262545, Conf Loss: 5.292524\tIter time: 0.2897\n",
            "Training... Epoch: 2, Iter: 2720,\t [4928/82081\t (6%)]\tLoss: 7.561701, Loc Loss: 2.521377, Conf Loss: 5.040324\tIter time: 0.3001\n",
            "Training... Epoch: 2, Iter: 2730,\t [5248/82081\t (6%)]\tLoss: 7.966719, Loc Loss: 2.245636, Conf Loss: 5.721082\tIter time: 0.2868\n",
            "Training... Epoch: 2, Iter: 2740,\t [5568/82081\t (7%)]\tLoss: 7.815414, Loc Loss: 2.433921, Conf Loss: 5.381494\tIter time: 0.2960\n",
            "Training... Epoch: 2, Iter: 2750,\t [5888/82081\t (7%)]\tLoss: 7.686036, Loc Loss: 2.276421, Conf Loss: 5.409615\tIter time: 0.2754\n",
            "Training... Epoch: 2, Iter: 2760,\t [6208/82081\t (8%)]\tLoss: 7.705315, Loc Loss: 2.361069, Conf Loss: 5.344246\tIter time: 0.2888\n",
            "Training... Epoch: 2, Iter: 2770,\t [6528/82081\t (8%)]\tLoss: 7.507438, Loc Loss: 2.160086, Conf Loss: 5.347352\tIter time: 0.2835\n",
            "Training... Epoch: 2, Iter: 2780,\t [6848/82081\t (8%)]\tLoss: 7.074529, Loc Loss: 2.085576, Conf Loss: 4.988953\tIter time: 0.2718\n",
            "Training... Epoch: 2, Iter: 2790,\t [7168/82081\t (9%)]\tLoss: 7.382473, Loc Loss: 2.307453, Conf Loss: 5.075020\tIter time: 0.2939\n",
            "Training... Epoch: 2, Iter: 2800,\t [7488/82081\t (9%)]\tLoss: 7.299693, Loc Loss: 2.245661, Conf Loss: 5.054032\tIter time: 0.2773\n",
            "Training... Epoch: 2, Iter: 2810,\t [7808/82081\t (10%)]\tLoss: 7.903932, Loc Loss: 2.247044, Conf Loss: 5.656887\tIter time: 0.2811\n",
            "Training... Epoch: 2, Iter: 2820,\t [8128/82081\t (10%)]\tLoss: 7.370821, Loc Loss: 1.987969, Conf Loss: 5.382852\tIter time: 0.2873\n",
            "Training... Epoch: 2, Iter: 2830,\t [8448/82081\t (10%)]\tLoss: 7.434237, Loc Loss: 2.026486, Conf Loss: 5.407752\tIter time: 0.2722\n",
            "Training... Epoch: 2, Iter: 2840,\t [8768/82081\t (11%)]\tLoss: 7.788644, Loc Loss: 2.296260, Conf Loss: 5.492383\tIter time: 0.2895\n",
            "Training... Epoch: 2, Iter: 2850,\t [9088/82081\t (11%)]\tLoss: 7.500189, Loc Loss: 2.314875, Conf Loss: 5.185314\tIter time: 0.2826\n",
            "Training... Epoch: 2, Iter: 2860,\t [9408/82081\t (11%)]\tLoss: 7.627517, Loc Loss: 2.322174, Conf Loss: 5.305343\tIter time: 0.2847\n",
            "Training... Epoch: 2, Iter: 2870,\t [9728/82081\t (12%)]\tLoss: 6.947785, Loc Loss: 1.901804, Conf Loss: 5.045982\tIter time: 0.2903\n",
            "Training... Epoch: 2, Iter: 2880,\t [10048/82081\t (12%)]\tLoss: 7.342461, Loc Loss: 2.337536, Conf Loss: 5.004925\tIter time: 0.2876\n",
            "Training... Epoch: 2, Iter: 2890,\t [10368/82081\t (13%)]\tLoss: 7.801079, Loc Loss: 2.285890, Conf Loss: 5.515189\tIter time: 0.2791\n",
            "Training... Epoch: 2, Iter: 2900,\t [10688/82081\t (13%)]\tLoss: 7.660166, Loc Loss: 2.123658, Conf Loss: 5.536508\tIter time: 0.2723\n",
            "Training... Epoch: 2, Iter: 2910,\t [11008/82081\t (13%)]\tLoss: 7.735559, Loc Loss: 2.262533, Conf Loss: 5.473026\tIter time: 0.2997\n",
            "Training... Epoch: 2, Iter: 2920,\t [11328/82081\t (14%)]\tLoss: 7.660287, Loc Loss: 2.434855, Conf Loss: 5.225432\tIter time: 0.2812\n",
            "Training... Epoch: 2, Iter: 2930,\t [11648/82081\t (14%)]\tLoss: 7.441033, Loc Loss: 2.459720, Conf Loss: 4.981313\tIter time: 0.2731\n",
            "Training... Epoch: 2, Iter: 2940,\t [11968/82081\t (15%)]\tLoss: 7.816875, Loc Loss: 2.252906, Conf Loss: 5.563969\tIter time: 0.2735\n",
            "Training... Epoch: 2, Iter: 2950,\t [12288/82081\t (15%)]\tLoss: 8.175680, Loc Loss: 2.309034, Conf Loss: 5.866647\tIter time: 0.2671\n",
            "Training... Epoch: 2, Iter: 2960,\t [12608/82081\t (15%)]\tLoss: 7.344877, Loc Loss: 2.280455, Conf Loss: 5.064422\tIter time: 0.2833\n",
            "Training... Epoch: 2, Iter: 2970,\t [12928/82081\t (16%)]\tLoss: 7.724164, Loc Loss: 2.296975, Conf Loss: 5.427189\tIter time: 0.2915\n",
            "Training... Epoch: 2, Iter: 2980,\t [13248/82081\t (16%)]\tLoss: 7.416988, Loc Loss: 2.371419, Conf Loss: 5.045569\tIter time: 0.3044\n",
            "Training... Epoch: 2, Iter: 2990,\t [13568/82081\t (17%)]\tLoss: 7.359273, Loc Loss: 2.216594, Conf Loss: 5.142680\tIter time: 0.3008\n",
            "Training... Epoch: 2, Iter: 3000,\t [13888/82081\t (17%)]\tLoss: 7.403551, Loc Loss: 2.072585, Conf Loss: 5.330966\tIter time: 0.2887\n",
            "Training... Epoch: 2, Iter: 3010,\t [14208/82081\t (17%)]\tLoss: 8.274427, Loc Loss: 2.438714, Conf Loss: 5.835713\tIter time: 0.2922\n",
            "Training... Epoch: 2, Iter: 3020,\t [14528/82081\t (18%)]\tLoss: 7.841106, Loc Loss: 2.422207, Conf Loss: 5.418899\tIter time: 0.2899\n",
            "Training... Epoch: 2, Iter: 3030,\t [14848/82081\t (18%)]\tLoss: 7.866681, Loc Loss: 2.168005, Conf Loss: 5.698677\tIter time: 0.3198\n",
            "Training... Epoch: 2, Iter: 3040,\t [15168/82081\t (18%)]\tLoss: 7.815866, Loc Loss: 2.157623, Conf Loss: 5.658243\tIter time: 0.2920\n",
            "Training... Epoch: 2, Iter: 3050,\t [15488/82081\t (19%)]\tLoss: 8.035109, Loc Loss: 2.461646, Conf Loss: 5.573462\tIter time: 0.2897\n",
            "Training... Epoch: 2, Iter: 3060,\t [15808/82081\t (19%)]\tLoss: 8.381056, Loc Loss: 2.956696, Conf Loss: 5.424360\tIter time: 0.2871\n",
            "Training... Epoch: 2, Iter: 3070,\t [16128/82081\t (20%)]\tLoss: 7.642314, Loc Loss: 2.066272, Conf Loss: 5.576042\tIter time: 0.2940\n",
            "Training... Epoch: 2, Iter: 3080,\t [16448/82081\t (20%)]\tLoss: 7.496741, Loc Loss: 2.284269, Conf Loss: 5.212472\tIter time: 0.2990\n",
            "Training... Epoch: 2, Iter: 3090,\t [16768/82081\t (20%)]\tLoss: 8.225287, Loc Loss: 2.489597, Conf Loss: 5.735690\tIter time: 0.2690\n",
            "Training... Epoch: 2, Iter: 3100,\t [17088/82081\t (21%)]\tLoss: 7.750806, Loc Loss: 2.460688, Conf Loss: 5.290118\tIter time: 0.2673\n",
            "Training... Epoch: 2, Iter: 3110,\t [17408/82081\t (21%)]\tLoss: 7.419222, Loc Loss: 1.954701, Conf Loss: 5.464522\tIter time: 0.2978\n",
            "Training... Epoch: 2, Iter: 3120,\t [17728/82081\t (22%)]\tLoss: 7.919244, Loc Loss: 2.376330, Conf Loss: 5.542913\tIter time: 0.2829\n",
            "Training... Epoch: 2, Iter: 3130,\t [18048/82081\t (22%)]\tLoss: 7.864975, Loc Loss: 2.419810, Conf Loss: 5.445165\tIter time: 0.2689\n",
            "Training... Epoch: 2, Iter: 3140,\t [18368/82081\t (22%)]\tLoss: 7.903763, Loc Loss: 2.286469, Conf Loss: 5.617294\tIter time: 0.3132\n",
            "Training... Epoch: 2, Iter: 3150,\t [18688/82081\t (23%)]\tLoss: 7.578071, Loc Loss: 2.149133, Conf Loss: 5.428937\tIter time: 0.2844\n",
            "Training... Epoch: 2, Iter: 3160,\t [19008/82081\t (23%)]\tLoss: 7.808890, Loc Loss: 2.252064, Conf Loss: 5.556827\tIter time: 0.2707\n",
            "Training... Epoch: 2, Iter: 3170,\t [19328/82081\t (24%)]\tLoss: 7.818491, Loc Loss: 2.105356, Conf Loss: 5.713135\tIter time: 0.2934\n",
            "Training... Epoch: 2, Iter: 3180,\t [19648/82081\t (24%)]\tLoss: 7.760993, Loc Loss: 2.562618, Conf Loss: 5.198375\tIter time: 0.2901\n",
            "Training... Epoch: 2, Iter: 3190,\t [19968/82081\t (24%)]\tLoss: 7.689528, Loc Loss: 2.202225, Conf Loss: 5.487303\tIter time: 0.2974\n",
            "Training... Epoch: 2, Iter: 3200,\t [20288/82081\t (25%)]\tLoss: 7.277129, Loc Loss: 2.254305, Conf Loss: 5.022824\tIter time: 0.2932\n",
            "Training... Epoch: 2, Iter: 3210,\t [20608/82081\t (25%)]\tLoss: 7.322635, Loc Loss: 2.281056, Conf Loss: 5.041579\tIter time: 0.2875\n",
            "Training... Epoch: 2, Iter: 3220,\t [20928/82081\t (25%)]\tLoss: 7.794145, Loc Loss: 2.492853, Conf Loss: 5.301292\tIter time: 0.2798\n",
            "Training... Epoch: 2, Iter: 3230,\t [21248/82081\t (26%)]\tLoss: 7.908757, Loc Loss: 2.471534, Conf Loss: 5.437223\tIter time: 0.2734\n",
            "Training... Epoch: 2, Iter: 3240,\t [21568/82081\t (26%)]\tLoss: 7.330093, Loc Loss: 2.130381, Conf Loss: 5.199712\tIter time: 0.2871\n",
            "Training... Epoch: 2, Iter: 3250,\t [21888/82081\t (27%)]\tLoss: 7.590458, Loc Loss: 2.378251, Conf Loss: 5.212207\tIter time: 0.3027\n",
            "Training... Epoch: 2, Iter: 3260,\t [22208/82081\t (27%)]\tLoss: 7.284636, Loc Loss: 2.189764, Conf Loss: 5.094872\tIter time: 0.2939\n",
            "Training... Epoch: 2, Iter: 3270,\t [22528/82081\t (27%)]\tLoss: 7.201559, Loc Loss: 2.311330, Conf Loss: 4.890229\tIter time: 0.3129\n",
            "Training... Epoch: 2, Iter: 3280,\t [22848/82081\t (28%)]\tLoss: 8.206869, Loc Loss: 2.214915, Conf Loss: 5.991954\tIter time: 0.2881\n",
            "Training... Epoch: 2, Iter: 3290,\t [23168/82081\t (28%)]\tLoss: 7.972782, Loc Loss: 2.591664, Conf Loss: 5.381118\tIter time: 0.3030\n",
            "Training... Epoch: 2, Iter: 3300,\t [23488/82081\t (29%)]\tLoss: 7.247412, Loc Loss: 2.050997, Conf Loss: 5.196415\tIter time: 0.2701\n",
            "Training... Epoch: 2, Iter: 3310,\t [23808/82081\t (29%)]\tLoss: 7.256873, Loc Loss: 2.300990, Conf Loss: 4.955883\tIter time: 0.3121\n",
            "Training... Epoch: 2, Iter: 3320,\t [24128/82081\t (29%)]\tLoss: 7.538048, Loc Loss: 2.395178, Conf Loss: 5.142870\tIter time: 0.3030\n",
            "Training... Epoch: 2, Iter: 3330,\t [24448/82081\t (30%)]\tLoss: 7.428766, Loc Loss: 2.229444, Conf Loss: 5.199322\tIter time: 0.2957\n",
            "Training... Epoch: 2, Iter: 3340,\t [24768/82081\t (30%)]\tLoss: 7.923274, Loc Loss: 2.468852, Conf Loss: 5.454422\tIter time: 0.2975\n",
            "Training... Epoch: 2, Iter: 3350,\t [25088/82081\t (31%)]\tLoss: 7.404976, Loc Loss: 2.453847, Conf Loss: 4.951129\tIter time: 0.2948\n",
            "Training... Epoch: 2, Iter: 3360,\t [25408/82081\t (31%)]\tLoss: 7.595943, Loc Loss: 2.058732, Conf Loss: 5.537211\tIter time: 0.2812\n",
            "Training... Epoch: 2, Iter: 3370,\t [25728/82081\t (31%)]\tLoss: 7.791084, Loc Loss: 2.455375, Conf Loss: 5.335709\tIter time: 0.2858\n",
            "Training... Epoch: 2, Iter: 3380,\t [26048/82081\t (32%)]\tLoss: 8.028934, Loc Loss: 2.455118, Conf Loss: 5.573815\tIter time: 0.2833\n",
            "Training... Epoch: 2, Iter: 3390,\t [26368/82081\t (32%)]\tLoss: 7.630523, Loc Loss: 2.139416, Conf Loss: 5.491107\tIter time: 0.2809\n",
            "Training... Epoch: 2, Iter: 3400,\t [26688/82081\t (33%)]\tLoss: 7.827823, Loc Loss: 2.239556, Conf Loss: 5.588267\tIter time: 0.2889\n",
            "Training... Epoch: 2, Iter: 3410,\t [27008/82081\t (33%)]\tLoss: 7.148981, Loc Loss: 1.861308, Conf Loss: 5.287673\tIter time: 0.2666\n",
            "Training... Epoch: 2, Iter: 3420,\t [27328/82081\t (33%)]\tLoss: 7.267402, Loc Loss: 2.095414, Conf Loss: 5.171988\tIter time: 0.2874\n",
            "Training... Epoch: 2, Iter: 3430,\t [27648/82081\t (34%)]\tLoss: 7.268827, Loc Loss: 2.011656, Conf Loss: 5.257172\tIter time: 0.2928\n",
            "Training... Epoch: 2, Iter: 3440,\t [27968/82081\t (34%)]\tLoss: 7.585371, Loc Loss: 2.180312, Conf Loss: 5.405059\tIter time: 0.2813\n",
            "Training... Epoch: 2, Iter: 3450,\t [28288/82081\t (34%)]\tLoss: 7.054884, Loc Loss: 2.120965, Conf Loss: 4.933918\tIter time: 0.3215\n",
            "Training... Epoch: 2, Iter: 3460,\t [28608/82081\t (35%)]\tLoss: 7.820459, Loc Loss: 2.355233, Conf Loss: 5.465226\tIter time: 0.3364\n",
            "Training... Epoch: 2, Iter: 3470,\t [28928/82081\t (35%)]\tLoss: 7.966682, Loc Loss: 2.463068, Conf Loss: 5.503614\tIter time: 0.3058\n",
            "Training... Epoch: 2, Iter: 3480,\t [29248/82081\t (36%)]\tLoss: 7.705820, Loc Loss: 2.570421, Conf Loss: 5.135399\tIter time: 0.3053\n",
            "Training... Epoch: 2, Iter: 3490,\t [29568/82081\t (36%)]\tLoss: 7.368789, Loc Loss: 2.127430, Conf Loss: 5.241359\tIter time: 0.2737\n",
            "Training... Epoch: 2, Iter: 3500,\t [29888/82081\t (36%)]\tLoss: 7.826346, Loc Loss: 2.547839, Conf Loss: 5.278507\tIter time: 0.2943\n",
            "Training... Epoch: 2, Iter: 3510,\t [30208/82081\t (37%)]\tLoss: 7.367015, Loc Loss: 2.262996, Conf Loss: 5.104019\tIter time: 0.2719\n",
            "Training... Epoch: 2, Iter: 3520,\t [30528/82081\t (37%)]\tLoss: 7.726133, Loc Loss: 2.227812, Conf Loss: 5.498322\tIter time: 0.2804\n",
            "Training... Epoch: 2, Iter: 3530,\t [30848/82081\t (38%)]\tLoss: 7.760234, Loc Loss: 2.563808, Conf Loss: 5.196425\tIter time: 0.2955\n",
            "Training... Epoch: 2, Iter: 3540,\t [31168/82081\t (38%)]\tLoss: 7.221197, Loc Loss: 2.109787, Conf Loss: 5.111410\tIter time: 0.2749\n",
            "Training... Epoch: 2, Iter: 3550,\t [31488/82081\t (38%)]\tLoss: 7.429966, Loc Loss: 2.120546, Conf Loss: 5.309421\tIter time: 0.2680\n",
            "Training... Epoch: 2, Iter: 3560,\t [31808/82081\t (39%)]\tLoss: 7.809292, Loc Loss: 2.375477, Conf Loss: 5.433815\tIter time: 0.2846\n",
            "Training... Epoch: 2, Iter: 3570,\t [32128/82081\t (39%)]\tLoss: 7.218267, Loc Loss: 2.321551, Conf Loss: 4.896717\tIter time: 0.2932\n",
            "Training... Epoch: 2, Iter: 3580,\t [32448/82081\t (40%)]\tLoss: 7.404552, Loc Loss: 1.998385, Conf Loss: 5.406167\tIter time: 0.2684\n",
            "Training... Epoch: 2, Iter: 3590,\t [32768/82081\t (40%)]\tLoss: 7.394584, Loc Loss: 1.981506, Conf Loss: 5.413077\tIter time: 0.2942\n",
            "Training... Epoch: 2, Iter: 3600,\t [33088/82081\t (40%)]\tLoss: 7.409604, Loc Loss: 2.453877, Conf Loss: 4.955727\tIter time: 0.2825\n",
            "Training... Epoch: 2, Iter: 3610,\t [33408/82081\t (41%)]\tLoss: 7.367720, Loc Loss: 2.068196, Conf Loss: 5.299523\tIter time: 0.2908\n",
            "Training... Epoch: 2, Iter: 3620,\t [33728/82081\t (41%)]\tLoss: 7.499364, Loc Loss: 2.218612, Conf Loss: 5.280751\tIter time: 0.2850\n",
            "Training... Epoch: 2, Iter: 3630,\t [34048/82081\t (41%)]\tLoss: 7.872467, Loc Loss: 2.233926, Conf Loss: 5.638541\tIter time: 0.2955\n",
            "Training... Epoch: 2, Iter: 3640,\t [34368/82081\t (42%)]\tLoss: 7.136700, Loc Loss: 2.074003, Conf Loss: 5.062697\tIter time: 0.2834\n",
            "Training... Epoch: 2, Iter: 3650,\t [34688/82081\t (42%)]\tLoss: 7.095414, Loc Loss: 2.121113, Conf Loss: 4.974301\tIter time: 0.2951\n",
            "Training... Epoch: 2, Iter: 3660,\t [35008/82081\t (43%)]\tLoss: 7.475197, Loc Loss: 2.220001, Conf Loss: 5.255196\tIter time: 0.2677\n",
            "Training... Epoch: 2, Iter: 3670,\t [35328/82081\t (43%)]\tLoss: 7.922095, Loc Loss: 2.636553, Conf Loss: 5.285542\tIter time: 0.3073\n",
            "Training... Epoch: 2, Iter: 3680,\t [35648/82081\t (43%)]\tLoss: 7.872865, Loc Loss: 2.434774, Conf Loss: 5.438091\tIter time: 0.2818\n",
            "Training... Epoch: 2, Iter: 3690,\t [35968/82081\t (44%)]\tLoss: 7.067849, Loc Loss: 2.123342, Conf Loss: 4.944507\tIter time: 0.2866\n",
            "Training... Epoch: 2, Iter: 3700,\t [36288/82081\t (44%)]\tLoss: 7.381811, Loc Loss: 2.196445, Conf Loss: 5.185367\tIter time: 0.2978\n",
            "Training... Epoch: 2, Iter: 3710,\t [36608/82081\t (45%)]\tLoss: 7.474945, Loc Loss: 2.327239, Conf Loss: 5.147706\tIter time: 0.2834\n",
            "Training... Epoch: 2, Iter: 3720,\t [36928/82081\t (45%)]\tLoss: 7.265126, Loc Loss: 2.003405, Conf Loss: 5.261721\tIter time: 0.2848\n",
            "Training... Epoch: 2, Iter: 3730,\t [37248/82081\t (45%)]\tLoss: 7.414738, Loc Loss: 1.998308, Conf Loss: 5.416430\tIter time: 0.2892\n",
            "Training... Epoch: 2, Iter: 3740,\t [37568/82081\t (46%)]\tLoss: 7.380153, Loc Loss: 2.591169, Conf Loss: 4.788984\tIter time: 0.2775\n",
            "Training... Epoch: 2, Iter: 3750,\t [37888/82081\t (46%)]\tLoss: 8.115164, Loc Loss: 2.566397, Conf Loss: 5.548767\tIter time: 0.3092\n",
            "Training... Epoch: 2, Iter: 3760,\t [38208/82081\t (47%)]\tLoss: 7.041757, Loc Loss: 2.129244, Conf Loss: 4.912513\tIter time: 0.2829\n",
            "Training... Epoch: 2, Iter: 3770,\t [38528/82081\t (47%)]\tLoss: 7.332649, Loc Loss: 2.056900, Conf Loss: 5.275749\tIter time: 0.2718\n",
            "Training... Epoch: 2, Iter: 3780,\t [38848/82081\t (47%)]\tLoss: 7.704240, Loc Loss: 2.261406, Conf Loss: 5.442833\tIter time: 0.2936\n",
            "Training... Epoch: 2, Iter: 3790,\t [39168/82081\t (48%)]\tLoss: 8.062360, Loc Loss: 2.375201, Conf Loss: 5.687159\tIter time: 0.2789\n",
            "Training... Epoch: 2, Iter: 3800,\t [39488/82081\t (48%)]\tLoss: 7.222718, Loc Loss: 2.217671, Conf Loss: 5.005048\tIter time: 0.2824\n",
            "Training... Epoch: 2, Iter: 3810,\t [39808/82081\t (48%)]\tLoss: 7.627697, Loc Loss: 2.151005, Conf Loss: 5.476693\tIter time: 0.2901\n",
            "Training... Epoch: 2, Iter: 3820,\t [40128/82081\t (49%)]\tLoss: 7.655660, Loc Loss: 2.275424, Conf Loss: 5.380236\tIter time: 0.2924\n",
            "Training... Epoch: 2, Iter: 3830,\t [40448/82081\t (49%)]\tLoss: 7.694461, Loc Loss: 2.296416, Conf Loss: 5.398045\tIter time: 0.3047\n",
            "Training... Epoch: 2, Iter: 3840,\t [40768/82081\t (50%)]\tLoss: 6.578691, Loc Loss: 2.023725, Conf Loss: 4.554966\tIter time: 0.2777\n",
            "Training... Epoch: 2, Iter: 3850,\t [41088/82081\t (50%)]\tLoss: 7.328170, Loc Loss: 2.186558, Conf Loss: 5.141612\tIter time: 0.2730\n",
            "Training... Epoch: 2, Iter: 3860,\t [41408/82081\t (50%)]\tLoss: 7.056968, Loc Loss: 2.069943, Conf Loss: 4.987025\tIter time: 0.3224\n",
            "Training... Epoch: 2, Iter: 3870,\t [41728/82081\t (51%)]\tLoss: 7.225878, Loc Loss: 2.184716, Conf Loss: 5.041162\tIter time: 0.2926\n",
            "Training... Epoch: 2, Iter: 3880,\t [42048/82081\t (51%)]\tLoss: 7.304110, Loc Loss: 2.149826, Conf Loss: 5.154284\tIter time: 0.2889\n",
            "Training... Epoch: 2, Iter: 3890,\t [42368/82081\t (52%)]\tLoss: 6.840197, Loc Loss: 1.906944, Conf Loss: 4.933253\tIter time: 0.2835\n",
            "Training... Epoch: 2, Iter: 3900,\t [42688/82081\t (52%)]\tLoss: 7.006705, Loc Loss: 2.178654, Conf Loss: 4.828051\tIter time: 0.2881\n",
            "Training... Epoch: 2, Iter: 3910,\t [43008/82081\t (52%)]\tLoss: 7.872083, Loc Loss: 2.664285, Conf Loss: 5.207798\tIter time: 0.2978\n",
            "Training... Epoch: 2, Iter: 3920,\t [43328/82081\t (53%)]\tLoss: 7.163795, Loc Loss: 2.178428, Conf Loss: 4.985368\tIter time: 0.2747\n",
            "Training... Epoch: 2, Iter: 3930,\t [43648/82081\t (53%)]\tLoss: 7.304178, Loc Loss: 2.286039, Conf Loss: 5.018138\tIter time: 0.2784\n",
            "Training... Epoch: 2, Iter: 3940,\t [43968/82081\t (54%)]\tLoss: 6.977917, Loc Loss: 2.118647, Conf Loss: 4.859271\tIter time: 0.2794\n",
            "Training... Epoch: 2, Iter: 3950,\t [44288/82081\t (54%)]\tLoss: 6.840950, Loc Loss: 2.007058, Conf Loss: 4.833892\tIter time: 0.3000\n",
            "Training... Epoch: 2, Iter: 3960,\t [44608/82081\t (54%)]\tLoss: 6.712937, Loc Loss: 2.219158, Conf Loss: 4.493779\tIter time: 0.2789\n",
            "Training... Epoch: 2, Iter: 3970,\t [44928/82081\t (55%)]\tLoss: 7.506334, Loc Loss: 2.012037, Conf Loss: 5.494297\tIter time: 0.2863\n",
            "Training... Epoch: 2, Iter: 3980,\t [45248/82081\t (55%)]\tLoss: 7.156631, Loc Loss: 2.209696, Conf Loss: 4.946936\tIter time: 0.2697\n",
            "Training... Epoch: 2, Iter: 3990,\t [45568/82081\t (55%)]\tLoss: 6.799065, Loc Loss: 1.998646, Conf Loss: 4.800419\tIter time: 0.2788\n",
            "Training... Epoch: 2, Iter: 4000,\t [45888/82081\t (56%)]\tLoss: 7.248423, Loc Loss: 2.368759, Conf Loss: 4.879663\tIter time: 0.2710\n",
            "Training... Epoch: 2, Iter: 4010,\t [46208/82081\t (56%)]\tLoss: 7.543319, Loc Loss: 1.911813, Conf Loss: 5.631505\tIter time: 0.2794\n",
            "Training... Epoch: 2, Iter: 4020,\t [46528/82081\t (57%)]\tLoss: 7.854280, Loc Loss: 2.133523, Conf Loss: 5.720757\tIter time: 0.3003\n",
            "Training... Epoch: 2, Iter: 4030,\t [46848/82081\t (57%)]\tLoss: 7.785138, Loc Loss: 2.402544, Conf Loss: 5.382594\tIter time: 0.2844\n",
            "Training... Epoch: 2, Iter: 4040,\t [47168/82081\t (57%)]\tLoss: 7.350698, Loc Loss: 2.024562, Conf Loss: 5.326136\tIter time: 0.2758\n",
            "Training... Epoch: 2, Iter: 4050,\t [47488/82081\t (58%)]\tLoss: 8.239347, Loc Loss: 2.224068, Conf Loss: 6.015279\tIter time: 0.2753\n",
            "Training... Epoch: 2, Iter: 4060,\t [47808/82081\t (58%)]\tLoss: 7.880260, Loc Loss: 2.481824, Conf Loss: 5.398435\tIter time: 0.2835\n",
            "Training... Epoch: 2, Iter: 4070,\t [48128/82081\t (59%)]\tLoss: 7.886409, Loc Loss: 2.503555, Conf Loss: 5.382854\tIter time: 0.2873\n",
            "Training... Epoch: 2, Iter: 4080,\t [48448/82081\t (59%)]\tLoss: 7.066422, Loc Loss: 2.026731, Conf Loss: 5.039692\tIter time: 0.2885\n",
            "Training... Epoch: 2, Iter: 4090,\t [48768/82081\t (59%)]\tLoss: 7.138455, Loc Loss: 2.018911, Conf Loss: 5.119544\tIter time: 0.2800\n",
            "Training... Epoch: 2, Iter: 4100,\t [49088/82081\t (60%)]\tLoss: 7.304887, Loc Loss: 2.239573, Conf Loss: 5.065314\tIter time: 0.3041\n",
            "Training... Epoch: 2, Iter: 4110,\t [49408/82081\t (60%)]\tLoss: 7.547072, Loc Loss: 2.259578, Conf Loss: 5.287494\tIter time: 0.2880\n",
            "Training... Epoch: 2, Iter: 4120,\t [49728/82081\t (61%)]\tLoss: 7.506011, Loc Loss: 2.231479, Conf Loss: 5.274532\tIter time: 0.2816\n",
            "Training... Epoch: 2, Iter: 4130,\t [50048/82081\t (61%)]\tLoss: 7.530744, Loc Loss: 2.448314, Conf Loss: 5.082429\tIter time: 0.2881\n",
            "Training... Epoch: 2, Iter: 4140,\t [50368/82081\t (61%)]\tLoss: 7.707592, Loc Loss: 2.327335, Conf Loss: 5.380258\tIter time: 0.3197\n",
            "Training... Epoch: 2, Iter: 4150,\t [50688/82081\t (62%)]\tLoss: 6.738728, Loc Loss: 1.996438, Conf Loss: 4.742290\tIter time: 0.2957\n",
            "Training... Epoch: 2, Iter: 4160,\t [51008/82081\t (62%)]\tLoss: 7.275967, Loc Loss: 1.964240, Conf Loss: 5.311727\tIter time: 0.2844\n",
            "Training... Epoch: 2, Iter: 4170,\t [51328/82081\t (63%)]\tLoss: 7.784848, Loc Loss: 2.458277, Conf Loss: 5.326571\tIter time: 0.2942\n",
            "Training... Epoch: 2, Iter: 4180,\t [51648/82081\t (63%)]\tLoss: 7.800094, Loc Loss: 2.523759, Conf Loss: 5.276335\tIter time: 0.2935\n",
            "Training... Epoch: 2, Iter: 4190,\t [51968/82081\t (63%)]\tLoss: 7.881345, Loc Loss: 2.109277, Conf Loss: 5.772068\tIter time: 0.2953\n",
            "Training... Epoch: 2, Iter: 4200,\t [52288/82081\t (64%)]\tLoss: 7.505905, Loc Loss: 2.196080, Conf Loss: 5.309825\tIter time: 0.2764\n",
            "Training... Epoch: 2, Iter: 4210,\t [52608/82081\t (64%)]\tLoss: 7.506113, Loc Loss: 2.143829, Conf Loss: 5.362284\tIter time: 0.2886\n",
            "Training... Epoch: 2, Iter: 4220,\t [52928/82081\t (64%)]\tLoss: 7.605425, Loc Loss: 2.263170, Conf Loss: 5.342255\tIter time: 0.2798\n",
            "Training... Epoch: 2, Iter: 4230,\t [53248/82081\t (65%)]\tLoss: 7.167422, Loc Loss: 2.165437, Conf Loss: 5.001986\tIter time: 0.2771\n",
            "Training... Epoch: 2, Iter: 4240,\t [53568/82081\t (65%)]\tLoss: 7.411911, Loc Loss: 2.149698, Conf Loss: 5.262213\tIter time: 0.2680\n",
            "Training... Epoch: 2, Iter: 4250,\t [53888/82081\t (66%)]\tLoss: 7.381020, Loc Loss: 2.201334, Conf Loss: 5.179686\tIter time: 0.2838\n",
            "Training... Epoch: 2, Iter: 4260,\t [54208/82081\t (66%)]\tLoss: 6.782892, Loc Loss: 2.021408, Conf Loss: 4.761485\tIter time: 0.2810\n",
            "Training... Epoch: 2, Iter: 4270,\t [54528/82081\t (66%)]\tLoss: 7.003061, Loc Loss: 2.030818, Conf Loss: 4.972243\tIter time: 0.2897\n",
            "Training... Epoch: 2, Iter: 4280,\t [54848/82081\t (67%)]\tLoss: 7.260243, Loc Loss: 2.176505, Conf Loss: 5.083738\tIter time: 0.2907\n",
            "Training... Epoch: 2, Iter: 4290,\t [55168/82081\t (67%)]\tLoss: 7.394184, Loc Loss: 2.110753, Conf Loss: 5.283432\tIter time: 0.3029\n",
            "Training... Epoch: 2, Iter: 4300,\t [55488/82081\t (68%)]\tLoss: 7.092383, Loc Loss: 2.057095, Conf Loss: 5.035289\tIter time: 0.2917\n",
            "Training... Epoch: 2, Iter: 4310,\t [55808/82081\t (68%)]\tLoss: 7.133399, Loc Loss: 1.742232, Conf Loss: 5.391167\tIter time: 0.3060\n",
            "Training... Epoch: 2, Iter: 4320,\t [56128/82081\t (68%)]\tLoss: 7.211285, Loc Loss: 2.316028, Conf Loss: 4.895257\tIter time: 0.2849\n",
            "Training... Epoch: 2, Iter: 4330,\t [56448/82081\t (69%)]\tLoss: 6.996417, Loc Loss: 2.091102, Conf Loss: 4.905315\tIter time: 0.3195\n",
            "Training... Epoch: 2, Iter: 4340,\t [56768/82081\t (69%)]\tLoss: 7.430069, Loc Loss: 1.975293, Conf Loss: 5.454776\tIter time: 0.2708\n",
            "Training... Epoch: 2, Iter: 4350,\t [57088/82081\t (70%)]\tLoss: 7.985709, Loc Loss: 2.324819, Conf Loss: 5.660890\tIter time: 0.2775\n",
            "Training... Epoch: 2, Iter: 4360,\t [57408/82081\t (70%)]\tLoss: 6.923138, Loc Loss: 1.880489, Conf Loss: 5.042649\tIter time: 0.2855\n",
            "Training... Epoch: 2, Iter: 4370,\t [57728/82081\t (70%)]\tLoss: 7.189439, Loc Loss: 2.078926, Conf Loss: 5.110513\tIter time: 0.2893\n",
            "Training... Epoch: 2, Iter: 4380,\t [58048/82081\t (71%)]\tLoss: 7.555952, Loc Loss: 2.182105, Conf Loss: 5.373847\tIter time: 0.2949\n",
            "Training... Epoch: 2, Iter: 4390,\t [58368/82081\t (71%)]\tLoss: 7.144398, Loc Loss: 1.926749, Conf Loss: 5.217649\tIter time: 0.2879\n",
            "Training... Epoch: 2, Iter: 4400,\t [58688/82081\t (71%)]\tLoss: 8.012247, Loc Loss: 2.333063, Conf Loss: 5.679185\tIter time: 0.2947\n",
            "Training... Epoch: 2, Iter: 4410,\t [59008/82081\t (72%)]\tLoss: 7.164209, Loc Loss: 2.119023, Conf Loss: 5.045187\tIter time: 0.2882\n",
            "Training... Epoch: 2, Iter: 4420,\t [59328/82081\t (72%)]\tLoss: 7.285371, Loc Loss: 2.208828, Conf Loss: 5.076543\tIter time: 0.2737\n",
            "Training... Epoch: 2, Iter: 4430,\t [59648/82081\t (73%)]\tLoss: 6.826959, Loc Loss: 2.071228, Conf Loss: 4.755731\tIter time: 0.2794\n",
            "Training... Epoch: 2, Iter: 4440,\t [59968/82081\t (73%)]\tLoss: 6.608080, Loc Loss: 2.063264, Conf Loss: 4.544816\tIter time: 0.2810\n",
            "Training... Epoch: 2, Iter: 4450,\t [60288/82081\t (73%)]\tLoss: 7.923539, Loc Loss: 2.464017, Conf Loss: 5.459522\tIter time: 0.2787\n",
            "Training... Epoch: 2, Iter: 4460,\t [60608/82081\t (74%)]\tLoss: 7.171247, Loc Loss: 2.198551, Conf Loss: 4.972695\tIter time: 0.2904\n",
            "Training... Epoch: 2, Iter: 4470,\t [60928/82081\t (74%)]\tLoss: 7.187374, Loc Loss: 2.196605, Conf Loss: 4.990768\tIter time: 0.2943\n",
            "Training... Epoch: 2, Iter: 4480,\t [61248/82081\t (75%)]\tLoss: 7.342464, Loc Loss: 2.486984, Conf Loss: 4.855480\tIter time: 0.2925\n",
            "Training... Epoch: 2, Iter: 4490,\t [61568/82081\t (75%)]\tLoss: 7.647534, Loc Loss: 2.141856, Conf Loss: 5.505678\tIter time: 0.2829\n",
            "Training... Epoch: 2, Iter: 4500,\t [61888/82081\t (75%)]\tLoss: 7.404189, Loc Loss: 2.086175, Conf Loss: 5.318014\tIter time: 0.2833\n",
            "Training... Epoch: 2, Iter: 4510,\t [62208/82081\t (76%)]\tLoss: 7.254488, Loc Loss: 2.262172, Conf Loss: 4.992316\tIter time: 0.2901\n",
            "Training... Epoch: 2, Iter: 4520,\t [62528/82081\t (76%)]\tLoss: 7.049750, Loc Loss: 2.342864, Conf Loss: 4.706887\tIter time: 0.3080\n",
            "Training... Epoch: 2, Iter: 4530,\t [62848/82081\t (77%)]\tLoss: 7.651169, Loc Loss: 2.261166, Conf Loss: 5.390003\tIter time: 0.2942\n",
            "Training... Epoch: 2, Iter: 4540,\t [63168/82081\t (77%)]\tLoss: 7.328115, Loc Loss: 2.130736, Conf Loss: 5.197379\tIter time: 0.2878\n",
            "Training... Epoch: 2, Iter: 4550,\t [63488/82081\t (77%)]\tLoss: 7.238022, Loc Loss: 2.202649, Conf Loss: 5.035373\tIter time: 0.2931\n",
            "Training... Epoch: 2, Iter: 4560,\t [63808/82081\t (78%)]\tLoss: 7.517776, Loc Loss: 2.067095, Conf Loss: 5.450680\tIter time: 0.2783\n",
            "Training... Epoch: 2, Iter: 4570,\t [64128/82081\t (78%)]\tLoss: 7.486635, Loc Loss: 2.238075, Conf Loss: 5.248560\tIter time: 0.2919\n",
            "Training... Epoch: 2, Iter: 4580,\t [64448/82081\t (78%)]\tLoss: 7.726462, Loc Loss: 2.168640, Conf Loss: 5.557822\tIter time: 0.2803\n",
            "Training... Epoch: 2, Iter: 4590,\t [64768/82081\t (79%)]\tLoss: 7.528183, Loc Loss: 2.378072, Conf Loss: 5.150111\tIter time: 0.2842\n",
            "Training... Epoch: 2, Iter: 4600,\t [65088/82081\t (79%)]\tLoss: 7.553086, Loc Loss: 2.263020, Conf Loss: 5.290066\tIter time: 0.3085\n",
            "Training... Epoch: 2, Iter: 4610,\t [65408/82081\t (80%)]\tLoss: 7.991493, Loc Loss: 2.531834, Conf Loss: 5.459659\tIter time: 0.2746\n",
            "Training... Epoch: 2, Iter: 4620,\t [65728/82081\t (80%)]\tLoss: 7.109165, Loc Loss: 2.093920, Conf Loss: 5.015245\tIter time: 0.2731\n",
            "Training... Epoch: 2, Iter: 4630,\t [66048/82081\t (80%)]\tLoss: 7.053207, Loc Loss: 2.219768, Conf Loss: 4.833440\tIter time: 0.2865\n",
            "Training... Epoch: 2, Iter: 4640,\t [66368/82081\t (81%)]\tLoss: 7.558311, Loc Loss: 2.255351, Conf Loss: 5.302960\tIter time: 0.2679\n",
            "Training... Epoch: 2, Iter: 4650,\t [66688/82081\t (81%)]\tLoss: 7.443371, Loc Loss: 2.054594, Conf Loss: 5.388777\tIter time: 0.2923\n",
            "Training... Epoch: 2, Iter: 4660,\t [67008/82081\t (82%)]\tLoss: 7.309927, Loc Loss: 2.091156, Conf Loss: 5.218771\tIter time: 0.2880\n",
            "Training... Epoch: 2, Iter: 4670,\t [67328/82081\t (82%)]\tLoss: 7.521734, Loc Loss: 2.223742, Conf Loss: 5.297993\tIter time: 0.2964\n",
            "Training... Epoch: 2, Iter: 4680,\t [67648/82081\t (82%)]\tLoss: 7.105828, Loc Loss: 2.357934, Conf Loss: 4.747894\tIter time: 0.2929\n",
            "Training... Epoch: 2, Iter: 4690,\t [67968/82081\t (83%)]\tLoss: 7.355371, Loc Loss: 2.126770, Conf Loss: 5.228601\tIter time: 0.2994\n",
            "Training... Epoch: 2, Iter: 4700,\t [68288/82081\t (83%)]\tLoss: 6.718439, Loc Loss: 2.023045, Conf Loss: 4.695395\tIter time: 0.3187\n",
            "Training... Epoch: 2, Iter: 4710,\t [68608/82081\t (84%)]\tLoss: 6.640109, Loc Loss: 2.045315, Conf Loss: 4.594794\tIter time: 0.2898\n",
            "Training... Epoch: 2, Iter: 4720,\t [68928/82081\t (84%)]\tLoss: 7.557549, Loc Loss: 2.492661, Conf Loss: 5.064888\tIter time: 0.3174\n",
            "Training... Epoch: 2, Iter: 4730,\t [69248/82081\t (84%)]\tLoss: 7.694964, Loc Loss: 2.382949, Conf Loss: 5.312016\tIter time: 0.2983\n",
            "Training... Epoch: 2, Iter: 4740,\t [69568/82081\t (85%)]\tLoss: 6.714243, Loc Loss: 1.730147, Conf Loss: 4.984096\tIter time: 0.2758\n",
            "Training... Epoch: 2, Iter: 4750,\t [69888/82081\t (85%)]\tLoss: 7.211029, Loc Loss: 2.025504, Conf Loss: 5.185525\tIter time: 0.2847\n",
            "Training... Epoch: 2, Iter: 4760,\t [70208/82081\t (86%)]\tLoss: 7.194580, Loc Loss: 2.062715, Conf Loss: 5.131865\tIter time: 0.2723\n",
            "Training... Epoch: 2, Iter: 4770,\t [70528/82081\t (86%)]\tLoss: 7.682089, Loc Loss: 2.378939, Conf Loss: 5.303150\tIter time: 0.2851\n",
            "Training... Epoch: 2, Iter: 4780,\t [70848/82081\t (86%)]\tLoss: 7.350599, Loc Loss: 2.280643, Conf Loss: 5.069956\tIter time: 0.2744\n",
            "Training... Epoch: 2, Iter: 4790,\t [71168/82081\t (87%)]\tLoss: 7.226523, Loc Loss: 2.612928, Conf Loss: 4.613596\tIter time: 0.2969\n",
            "Training... Epoch: 2, Iter: 4800,\t [71488/82081\t (87%)]\tLoss: 7.374299, Loc Loss: 2.454238, Conf Loss: 4.920060\tIter time: 0.2970\n",
            "Training... Epoch: 2, Iter: 4810,\t [71808/82081\t (87%)]\tLoss: 7.639285, Loc Loss: 2.159837, Conf Loss: 5.479448\tIter time: 0.2915\n",
            "Training... Epoch: 2, Iter: 4820,\t [72128/82081\t (88%)]\tLoss: 6.946847, Loc Loss: 2.162178, Conf Loss: 4.784669\tIter time: 0.2847\n",
            "Training... Epoch: 2, Iter: 4830,\t [72448/82081\t (88%)]\tLoss: 6.576782, Loc Loss: 2.010936, Conf Loss: 4.565847\tIter time: 0.2884\n",
            "Training... Epoch: 2, Iter: 4840,\t [72768/82081\t (89%)]\tLoss: 7.557068, Loc Loss: 2.089165, Conf Loss: 5.467902\tIter time: 0.2767\n",
            "Training... Epoch: 2, Iter: 4850,\t [73088/82081\t (89%)]\tLoss: 6.927127, Loc Loss: 2.076834, Conf Loss: 4.850293\tIter time: 0.2696\n",
            "Training... Epoch: 2, Iter: 4860,\t [73408/82081\t (89%)]\tLoss: 7.730104, Loc Loss: 2.249796, Conf Loss: 5.480309\tIter time: 0.2980\n",
            "Training... Epoch: 2, Iter: 4870,\t [73728/82081\t (90%)]\tLoss: 7.290215, Loc Loss: 2.115651, Conf Loss: 5.174563\tIter time: 0.3070\n",
            "Training... Epoch: 2, Iter: 4880,\t [74048/82081\t (90%)]\tLoss: 7.201246, Loc Loss: 2.152156, Conf Loss: 5.049090\tIter time: 0.2891\n",
            "Training... Epoch: 2, Iter: 4890,\t [74368/82081\t (91%)]\tLoss: 7.957897, Loc Loss: 2.488620, Conf Loss: 5.469276\tIter time: 0.2815\n",
            "Training... Epoch: 2, Iter: 4900,\t [74688/82081\t (91%)]\tLoss: 6.984267, Loc Loss: 2.268125, Conf Loss: 4.716142\tIter time: 0.3027\n",
            "Training... Epoch: 2, Iter: 4910,\t [75008/82081\t (91%)]\tLoss: 7.379121, Loc Loss: 2.041227, Conf Loss: 5.337893\tIter time: 0.2968\n",
            "Training... Epoch: 2, Iter: 4920,\t [75328/82081\t (92%)]\tLoss: 7.110625, Loc Loss: 1.986530, Conf Loss: 5.124095\tIter time: 0.2907\n",
            "Training... Epoch: 2, Iter: 4930,\t [75648/82081\t (92%)]\tLoss: 6.976795, Loc Loss: 2.393650, Conf Loss: 4.583145\tIter time: 0.2976\n",
            "Training... Epoch: 2, Iter: 4940,\t [75968/82081\t (93%)]\tLoss: 7.686475, Loc Loss: 2.231277, Conf Loss: 5.455198\tIter time: 0.2804\n",
            "Training... Epoch: 2, Iter: 4950,\t [76288/82081\t (93%)]\tLoss: 7.162477, Loc Loss: 2.032255, Conf Loss: 5.130221\tIter time: 0.3275\n",
            "Training... Epoch: 2, Iter: 4960,\t [76608/82081\t (93%)]\tLoss: 7.317472, Loc Loss: 2.163790, Conf Loss: 5.153682\tIter time: 0.2848\n",
            "Training... Epoch: 2, Iter: 4970,\t [76928/82081\t (94%)]\tLoss: 7.368298, Loc Loss: 2.151407, Conf Loss: 5.216891\tIter time: 0.2882\n",
            "Training... Epoch: 2, Iter: 4980,\t [77248/82081\t (94%)]\tLoss: 7.673434, Loc Loss: 2.476133, Conf Loss: 5.197301\tIter time: 0.2897\n",
            "Training... Epoch: 2, Iter: 4990,\t [77568/82081\t (94%)]\tLoss: 6.639186, Loc Loss: 2.324386, Conf Loss: 4.314800\tIter time: 0.2988\n",
            "Training... Epoch: 2, Iter: 5000,\t [77888/82081\t (95%)]\tLoss: 7.765291, Loc Loss: 2.455607, Conf Loss: 5.309683\tIter time: 0.2853\n",
            "\n",
            "Training finished\n",
            "Saved model to ./weights/results/SSD300_i-5000.pth\n",
            "Saved graph to ./weights/results/SSD300_learning-curve_i-5000.png\n"
          ]
        }
      ],
      "source": [
        "#additional batchnorm layers\n",
        "!python easy_train.py COCO -na -bn --max_iteration 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbxhHYmDN4do",
        "outputId": "a719b3b7-f5e2-4e77-fea8-f46fdea03139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=11.98s)\n",
            "creating index...\n",
            "index created!\n",
            "INFO:root:Dataset info:\n",
            "root dir: ['/root/data/coco/coco2014/trainval'],\n",
            "focus: ['train2014'],\n",
            "labels:['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
            "ignore object: None\n",
            "augmentation: True\n",
            "batch size: 32\n",
            "num_workers: 4\n",
            "\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /pytorch_SSD/weights/vgg16_bn-6c64b313.pth\n",
            "100% 528M/528M [00:05<00:00, 99.2MB/s]\n",
            "INFO:root:model loaded\n",
            "INFO:root:DataParallel(\n",
            "  (module): SSD300(\n",
            "    (codec): Codec(\n",
            "      (encoder): Encoder()\n",
            "      (decoder): Decoder()\n",
            "    )\n",
            "    (defaultBox): DBoxSSDOriginal()\n",
            "    (predictor): Predictor()\n",
            "    (inferenceBox): InferenceBox()\n",
            "    (feature_layers): ModuleDict(\n",
            "      (convBnRL1_1): ConvRelu(\n",
            "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL1_2): ConvRelu(\n",
            "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convBnRL2_1): ConvRelu(\n",
            "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL2_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convBnRL3_1): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL3_2): ConvRelu(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL3_3): ConvRelu(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=True)\n",
            "      (convBnRL4_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL4_2): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL4_3): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "      (convBnRL5_1): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL5_2): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL5_3): ConvRelu(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (pool5): MaxPool2d(kernel_size=(3, 3), stride=(1, 1), padding=1, dilation=1, ceil_mode=False)\n",
            "      (convBnRL6): ConvRelu(\n",
            "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL7): ConvRelu(\n",
            "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL8_1): ConvRelu(\n",
            "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL8_2): ConvRelu(\n",
            "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL9_1): ConvRelu(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL9_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL10_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL10_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convBnRL11_1): ConvRelu(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (convRL11_2): ConvRelu(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (addon_layers): ModuleDict(\n",
            "      (addon_1): L2Normalization()\n",
            "    )\n",
            "    (localization_layers): ModuleDict(\n",
            "      (conv_loc_1): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_2): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_3): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_4): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_loc_6): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (confidence_layers): ModuleDict(\n",
            "      (conv_conf_1): Conv2d(512, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_2): Conv2d(1024, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_3): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_4): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_conf_6): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "INFO:root:Optimizer Info:\n",
            "Optimizer: SGD\n",
            "learning rate: 0.001, Momentum: 0.9, Weight decay: 0.0005\n",
            "\n",
            "INFO:root:Multi Step Info:\n",
            "milestones: [40000, 50000]\n",
            "gamma: 0.1\n",
            "\n",
            "INFO:root:Save Info:\n",
            "filename: SSD300\n",
            "checkpoints interval: 5000\n",
            "\n",
            "INFO:root:Start Training\n",
            "\n",
            "\n",
            "Training... Epoch: 1, Iter: 1,\t [32/82081\t (0%)]\tLoss: 32.228615, Loc Loss: 4.387867, Conf Loss: 27.840748\tIter time: 0.4518\n",
            "Training... Epoch: 1, Iter: 10,\t [320/82081\t (0%)]\tLoss: 22.604942, Loc Loss: 3.999766, Conf Loss: 18.605177\tIter time: 0.4021\n",
            "Training... Epoch: 1, Iter: 20,\t [640/82081\t (1%)]\tLoss: 15.297423, Loc Loss: 3.343867, Conf Loss: 11.953556\tIter time: 0.2757\n",
            "Training... Epoch: 1, Iter: 30,\t [960/82081\t (1%)]\tLoss: 11.917905, Loc Loss: 3.166064, Conf Loss: 8.751842\tIter time: 0.3069\n",
            "Training... Epoch: 1, Iter: 40,\t [1280/82081\t (2%)]\tLoss: 11.568768, Loc Loss: 3.458296, Conf Loss: 8.110472\tIter time: 0.2889\n",
            "Training... Epoch: 1, Iter: 50,\t [1600/82081\t (2%)]\tLoss: 11.003117, Loc Loss: 3.552919, Conf Loss: 7.450197\tIter time: 0.2868\n",
            "Training... Epoch: 1, Iter: 60,\t [1920/82081\t (2%)]\tLoss: 10.064226, Loc Loss: 3.191292, Conf Loss: 6.872935\tIter time: 0.2722\n",
            "Training... Epoch: 1, Iter: 70,\t [2240/82081\t (3%)]\tLoss: 10.091066, Loc Loss: 2.899273, Conf Loss: 7.191793\tIter time: 0.2855\n",
            "Training... Epoch: 1, Iter: 80,\t [2560/82081\t (3%)]\tLoss: 10.195824, Loc Loss: 3.031601, Conf Loss: 7.164222\tIter time: 0.2827\n",
            "Training... Epoch: 1, Iter: 90,\t [2880/82081\t (4%)]\tLoss: 10.102465, Loc Loss: 2.793120, Conf Loss: 7.309345\tIter time: 0.2912\n",
            "Training... Epoch: 1, Iter: 100,\t [3200/82081\t (4%)]\tLoss: 10.190011, Loc Loss: 3.047277, Conf Loss: 7.142734\tIter time: 0.2902\n",
            "Training... Epoch: 1, Iter: 110,\t [3520/82081\t (4%)]\tLoss: 10.085121, Loc Loss: 3.124141, Conf Loss: 6.960980\tIter time: 0.3011\n",
            "Training... Epoch: 1, Iter: 120,\t [3840/82081\t (5%)]\tLoss: 9.478512, Loc Loss: 2.901312, Conf Loss: 6.577200\tIter time: 0.2726\n",
            "Training... Epoch: 1, Iter: 130,\t [4160/82081\t (5%)]\tLoss: 9.548941, Loc Loss: 2.840721, Conf Loss: 6.708220\tIter time: 0.2778\n",
            "Training... Epoch: 1, Iter: 140,\t [4480/82081\t (5%)]\tLoss: 9.823107, Loc Loss: 2.828391, Conf Loss: 6.994715\tIter time: 0.3063\n",
            "Training... Epoch: 1, Iter: 150,\t [4800/82081\t (6%)]\tLoss: 10.430286, Loc Loss: 2.879933, Conf Loss: 7.550354\tIter time: 0.2831\n",
            "Training... Epoch: 1, Iter: 160,\t [5120/82081\t (6%)]\tLoss: 9.723467, Loc Loss: 2.805274, Conf Loss: 6.918193\tIter time: 0.2719\n",
            "Training... Epoch: 1, Iter: 170,\t [5440/82081\t (7%)]\tLoss: 9.597157, Loc Loss: 3.188475, Conf Loss: 6.408683\tIter time: 0.2926\n",
            "Training... Epoch: 1, Iter: 180,\t [5760/82081\t (7%)]\tLoss: 9.225739, Loc Loss: 2.765578, Conf Loss: 6.460162\tIter time: 0.2940\n",
            "Training... Epoch: 1, Iter: 190,\t [6080/82081\t (7%)]\tLoss: 9.915327, Loc Loss: 3.258883, Conf Loss: 6.656444\tIter time: 0.2840\n",
            "Training... Epoch: 1, Iter: 200,\t [6400/82081\t (8%)]\tLoss: 9.604545, Loc Loss: 3.071718, Conf Loss: 6.532827\tIter time: 0.2870\n",
            "Training... Epoch: 1, Iter: 210,\t [6720/82081\t (8%)]\tLoss: 9.158238, Loc Loss: 2.707419, Conf Loss: 6.450819\tIter time: 0.2870\n",
            "Training... Epoch: 1, Iter: 220,\t [7040/82081\t (9%)]\tLoss: 9.922597, Loc Loss: 3.003272, Conf Loss: 6.919325\tIter time: 0.2742\n",
            "Training... Epoch: 1, Iter: 230,\t [7360/82081\t (9%)]\tLoss: 9.305307, Loc Loss: 2.723813, Conf Loss: 6.581495\tIter time: 0.2877\n",
            "Training... Epoch: 1, Iter: 240,\t [7680/82081\t (9%)]\tLoss: 9.524328, Loc Loss: 2.988295, Conf Loss: 6.536034\tIter time: 0.2940\n",
            "Training... Epoch: 1, Iter: 250,\t [8000/82081\t (10%)]\tLoss: 10.539642, Loc Loss: 3.043179, Conf Loss: 7.496463\tIter time: 0.2858\n",
            "Training... Epoch: 1, Iter: 260,\t [8320/82081\t (10%)]\tLoss: 9.077003, Loc Loss: 2.625551, Conf Loss: 6.451452\tIter time: 0.2782\n",
            "Training... Epoch: 1, Iter: 270,\t [8640/82081\t (11%)]\tLoss: 9.402822, Loc Loss: 3.213072, Conf Loss: 6.189750\tIter time: 0.2841\n",
            "Training... Epoch: 1, Iter: 280,\t [8960/82081\t (11%)]\tLoss: 8.398840, Loc Loss: 2.528588, Conf Loss: 5.870251\tIter time: 0.2816\n",
            "Training... Epoch: 1, Iter: 290,\t [9280/82081\t (11%)]\tLoss: 8.725772, Loc Loss: 2.660473, Conf Loss: 6.065299\tIter time: 0.2849\n",
            "Training... Epoch: 1, Iter: 300,\t [9600/82081\t (12%)]\tLoss: 9.514949, Loc Loss: 2.788180, Conf Loss: 6.726768\tIter time: 0.2742\n",
            "Training... Epoch: 1, Iter: 310,\t [9920/82081\t (12%)]\tLoss: 9.329888, Loc Loss: 2.491322, Conf Loss: 6.838567\tIter time: 0.2885\n",
            "Training... Epoch: 1, Iter: 320,\t [10240/82081\t (12%)]\tLoss: 9.129761, Loc Loss: 2.946578, Conf Loss: 6.183183\tIter time: 0.2955\n",
            "Training... Epoch: 1, Iter: 330,\t [10560/82081\t (13%)]\tLoss: 10.101411, Loc Loss: 2.712827, Conf Loss: 7.388584\tIter time: 0.2838\n",
            "Training... Epoch: 1, Iter: 340,\t [10880/82081\t (13%)]\tLoss: 9.460787, Loc Loss: 2.951487, Conf Loss: 6.509300\tIter time: 0.2944\n",
            "Training... Epoch: 1, Iter: 350,\t [11200/82081\t (14%)]\tLoss: 8.912470, Loc Loss: 2.820271, Conf Loss: 6.092199\tIter time: 0.2897\n",
            "Training... Epoch: 1, Iter: 360,\t [11520/82081\t (14%)]\tLoss: 8.444935, Loc Loss: 2.427951, Conf Loss: 6.016984\tIter time: 0.2764\n",
            "Training... Epoch: 1, Iter: 370,\t [11840/82081\t (14%)]\tLoss: 9.285965, Loc Loss: 2.948101, Conf Loss: 6.337865\tIter time: 0.2969\n",
            "Training... Epoch: 1, Iter: 380,\t [12160/82081\t (15%)]\tLoss: 9.211323, Loc Loss: 2.936014, Conf Loss: 6.275309\tIter time: 0.2951\n",
            "Training... Epoch: 1, Iter: 390,\t [12480/82081\t (15%)]\tLoss: 8.640685, Loc Loss: 2.617603, Conf Loss: 6.023082\tIter time: 0.2924\n",
            "Training... Epoch: 1, Iter: 400,\t [12800/82081\t (16%)]\tLoss: 8.649818, Loc Loss: 2.661756, Conf Loss: 5.988063\tIter time: 0.2830\n",
            "Training... Epoch: 1, Iter: 410,\t [13120/82081\t (16%)]\tLoss: 8.744481, Loc Loss: 2.490781, Conf Loss: 6.253700\tIter time: 0.2708\n",
            "Training... Epoch: 1, Iter: 420,\t [13440/82081\t (16%)]\tLoss: 9.307176, Loc Loss: 2.523947, Conf Loss: 6.783228\tIter time: 0.3114\n",
            "Training... Epoch: 1, Iter: 430,\t [13760/82081\t (17%)]\tLoss: 9.315168, Loc Loss: 2.708475, Conf Loss: 6.606694\tIter time: 0.2865\n",
            "Training... Epoch: 1, Iter: 440,\t [14080/82081\t (17%)]\tLoss: 9.085762, Loc Loss: 2.998421, Conf Loss: 6.087341\tIter time: 0.2717\n",
            "Training... Epoch: 1, Iter: 450,\t [14400/82081\t (18%)]\tLoss: 8.371220, Loc Loss: 2.550656, Conf Loss: 5.820564\tIter time: 0.3080\n",
            "Training... Epoch: 1, Iter: 460,\t [14720/82081\t (18%)]\tLoss: 9.039433, Loc Loss: 2.673780, Conf Loss: 6.365653\tIter time: 0.2673\n",
            "Training... Epoch: 1, Iter: 470,\t [15040/82081\t (18%)]\tLoss: 8.931995, Loc Loss: 2.691994, Conf Loss: 6.240001\tIter time: 0.2831\n",
            "Training... Epoch: 1, Iter: 480,\t [15360/82081\t (19%)]\tLoss: 8.942646, Loc Loss: 2.934961, Conf Loss: 6.007686\tIter time: 0.2805\n",
            "Training... Epoch: 1, Iter: 490,\t [15680/82081\t (19%)]\tLoss: 8.983716, Loc Loss: 2.637718, Conf Loss: 6.345997\tIter time: 0.2918\n",
            "Training... Epoch: 1, Iter: 500,\t [16000/82081\t (19%)]\tLoss: 8.347651, Loc Loss: 2.596084, Conf Loss: 5.751566\tIter time: 0.2736\n",
            "Training... Epoch: 1, Iter: 510,\t [16320/82081\t (20%)]\tLoss: 9.243697, Loc Loss: 2.550852, Conf Loss: 6.692845\tIter time: 0.2718\n",
            "Training... Epoch: 1, Iter: 520,\t [16640/82081\t (20%)]\tLoss: 9.028461, Loc Loss: 2.667966, Conf Loss: 6.360495\tIter time: 0.2891\n",
            "Training... Epoch: 1, Iter: 530,\t [16960/82081\t (21%)]\tLoss: 9.036983, Loc Loss: 2.869155, Conf Loss: 6.167828\tIter time: 0.3052\n",
            "Training... Epoch: 1, Iter: 540,\t [17280/82081\t (21%)]\tLoss: 9.130213, Loc Loss: 2.740039, Conf Loss: 6.390174\tIter time: 0.3084\n",
            "Training... Epoch: 1, Iter: 550,\t [17600/82081\t (21%)]\tLoss: 8.778181, Loc Loss: 2.530316, Conf Loss: 6.247865\tIter time: 0.2890\n",
            "Training... Epoch: 1, Iter: 560,\t [17920/82081\t (22%)]\tLoss: 8.830648, Loc Loss: 2.545879, Conf Loss: 6.284770\tIter time: 0.2718\n",
            "Training... Epoch: 1, Iter: 570,\t [18240/82081\t (22%)]\tLoss: 8.646421, Loc Loss: 2.618246, Conf Loss: 6.028176\tIter time: 0.3026\n",
            "Training... Epoch: 1, Iter: 580,\t [18560/82081\t (23%)]\tLoss: 8.561661, Loc Loss: 2.796863, Conf Loss: 5.764798\tIter time: 0.2818\n",
            "Training... Epoch: 1, Iter: 590,\t [18880/82081\t (23%)]\tLoss: 9.103828, Loc Loss: 2.542354, Conf Loss: 6.561474\tIter time: 0.3046\n",
            "Training... Epoch: 1, Iter: 600,\t [19200/82081\t (23%)]\tLoss: 8.543808, Loc Loss: 2.500829, Conf Loss: 6.042979\tIter time: 0.2937\n",
            "Training... Epoch: 1, Iter: 610,\t [19520/82081\t (24%)]\tLoss: 8.866905, Loc Loss: 2.816556, Conf Loss: 6.050350\tIter time: 0.2931\n",
            "Training... Epoch: 1, Iter: 620,\t [19840/82081\t (24%)]\tLoss: 8.496185, Loc Loss: 2.605647, Conf Loss: 5.890538\tIter time: 0.2821\n",
            "Training... Epoch: 1, Iter: 630,\t [20160/82081\t (25%)]\tLoss: 8.459190, Loc Loss: 2.602936, Conf Loss: 5.856254\tIter time: 0.2893\n",
            "Training... Epoch: 1, Iter: 640,\t [20480/82081\t (25%)]\tLoss: 8.214144, Loc Loss: 2.376276, Conf Loss: 5.837867\tIter time: 0.2994\n",
            "Training... Epoch: 1, Iter: 650,\t [20800/82081\t (25%)]\tLoss: 8.517616, Loc Loss: 2.643821, Conf Loss: 5.873796\tIter time: 0.2691\n",
            "Training... Epoch: 1, Iter: 660,\t [21120/82081\t (26%)]\tLoss: 9.301482, Loc Loss: 3.329265, Conf Loss: 5.972217\tIter time: 0.2748\n",
            "Training... Epoch: 1, Iter: 670,\t [21440/82081\t (26%)]\tLoss: 8.364868, Loc Loss: 2.577492, Conf Loss: 5.787375\tIter time: 0.3021\n",
            "Training... Epoch: 1, Iter: 680,\t [21760/82081\t (27%)]\tLoss: 8.848392, Loc Loss: 2.767387, Conf Loss: 6.081005\tIter time: 0.2927\n",
            "Training... Epoch: 1, Iter: 690,\t [22080/82081\t (27%)]\tLoss: 8.826741, Loc Loss: 2.715655, Conf Loss: 6.111087\tIter time: 0.2852\n",
            "Training... Epoch: 1, Iter: 700,\t [22400/82081\t (27%)]\tLoss: 9.144836, Loc Loss: 2.873824, Conf Loss: 6.271013\tIter time: 0.2700\n",
            "Training... Epoch: 1, Iter: 710,\t [22720/82081\t (28%)]\tLoss: 8.314954, Loc Loss: 2.454345, Conf Loss: 5.860610\tIter time: 0.3048\n",
            "Training... Epoch: 1, Iter: 720,\t [23040/82081\t (28%)]\tLoss: 8.976004, Loc Loss: 2.989578, Conf Loss: 5.986426\tIter time: 0.3025\n",
            "Training... Epoch: 1, Iter: 730,\t [23360/82081\t (28%)]\tLoss: 8.605227, Loc Loss: 2.510112, Conf Loss: 6.095114\tIter time: 0.2684\n",
            "Training... Epoch: 1, Iter: 740,\t [23680/82081\t (29%)]\tLoss: 8.432576, Loc Loss: 2.592324, Conf Loss: 5.840252\tIter time: 0.3019\n",
            "Training... Epoch: 1, Iter: 750,\t [24000/82081\t (29%)]\tLoss: 9.058573, Loc Loss: 2.639313, Conf Loss: 6.419259\tIter time: 0.2774\n",
            "Training... Epoch: 1, Iter: 760,\t [24320/82081\t (30%)]\tLoss: 8.647762, Loc Loss: 2.592084, Conf Loss: 6.055678\tIter time: 0.2857\n",
            "Training... Epoch: 1, Iter: 770,\t [24640/82081\t (30%)]\tLoss: 9.230562, Loc Loss: 2.605520, Conf Loss: 6.625042\tIter time: 0.2921\n",
            "Training... Epoch: 1, Iter: 780,\t [24960/82081\t (30%)]\tLoss: 8.758451, Loc Loss: 2.720928, Conf Loss: 6.037523\tIter time: 0.2939\n",
            "Training... Epoch: 1, Iter: 790,\t [25280/82081\t (31%)]\tLoss: 8.919872, Loc Loss: 2.594794, Conf Loss: 6.325079\tIter time: 0.2759\n",
            "Training... Epoch: 1, Iter: 800,\t [25600/82081\t (31%)]\tLoss: 8.571255, Loc Loss: 2.418345, Conf Loss: 6.152909\tIter time: 0.2892\n",
            "Training... Epoch: 1, Iter: 810,\t [25920/82081\t (32%)]\tLoss: 8.699657, Loc Loss: 2.596790, Conf Loss: 6.102867\tIter time: 0.3021\n",
            "Training... Epoch: 1, Iter: 820,\t [26240/82081\t (32%)]\tLoss: 8.799144, Loc Loss: 2.436575, Conf Loss: 6.362569\tIter time: 0.2702\n",
            "Training... Epoch: 1, Iter: 830,\t [26560/82081\t (32%)]\tLoss: 9.223886, Loc Loss: 2.805729, Conf Loss: 6.418158\tIter time: 0.3088\n",
            "Training... Epoch: 1, Iter: 840,\t [26880/82081\t (33%)]\tLoss: 8.113302, Loc Loss: 2.335805, Conf Loss: 5.777498\tIter time: 0.2722\n",
            "Training... Epoch: 1, Iter: 850,\t [27200/82081\t (33%)]\tLoss: 8.376547, Loc Loss: 2.642779, Conf Loss: 5.733768\tIter time: 0.2932\n",
            "Training... Epoch: 1, Iter: 860,\t [27520/82081\t (34%)]\tLoss: 8.498708, Loc Loss: 2.629765, Conf Loss: 5.868942\tIter time: 0.2919\n",
            "Training... Epoch: 1, Iter: 870,\t [27840/82081\t (34%)]\tLoss: 8.273783, Loc Loss: 2.557906, Conf Loss: 5.715877\tIter time: 0.3015\n",
            "Training... Epoch: 1, Iter: 880,\t [28160/82081\t (34%)]\tLoss: 8.849291, Loc Loss: 2.554776, Conf Loss: 6.294515\tIter time: 0.2788\n",
            "Training... Epoch: 1, Iter: 890,\t [28480/82081\t (35%)]\tLoss: 8.994078, Loc Loss: 2.505929, Conf Loss: 6.488149\tIter time: 0.3098\n",
            "Training... Epoch: 1, Iter: 900,\t [28800/82081\t (35%)]\tLoss: 8.174031, Loc Loss: 2.496625, Conf Loss: 5.677406\tIter time: 0.3172\n",
            "Training... Epoch: 1, Iter: 910,\t [29120/82081\t (35%)]\tLoss: 8.580661, Loc Loss: 2.652333, Conf Loss: 5.928328\tIter time: 0.2896\n",
            "Training... Epoch: 1, Iter: 920,\t [29440/82081\t (36%)]\tLoss: 8.316323, Loc Loss: 2.435884, Conf Loss: 5.880439\tIter time: 0.2965\n",
            "Training... Epoch: 1, Iter: 930,\t [29760/82081\t (36%)]\tLoss: 8.755733, Loc Loss: 2.766247, Conf Loss: 5.989486\tIter time: 0.2852\n",
            "Training... Epoch: 1, Iter: 940,\t [30080/82081\t (37%)]\tLoss: 8.905793, Loc Loss: 2.758415, Conf Loss: 6.147378\tIter time: 0.2937\n",
            "Training... Epoch: 1, Iter: 950,\t [30400/82081\t (37%)]\tLoss: 8.615357, Loc Loss: 2.580507, Conf Loss: 6.034850\tIter time: 0.2727\n",
            "Training... Epoch: 1, Iter: 960,\t [30720/82081\t (37%)]\tLoss: 8.428946, Loc Loss: 2.490740, Conf Loss: 5.938207\tIter time: 0.2961\n",
            "Training... Epoch: 1, Iter: 970,\t [31040/82081\t (38%)]\tLoss: 8.942614, Loc Loss: 2.482001, Conf Loss: 6.460612\tIter time: 0.2942\n",
            "Training... Epoch: 1, Iter: 980,\t [31360/82081\t (38%)]\tLoss: 8.017100, Loc Loss: 2.155252, Conf Loss: 5.861848\tIter time: 0.2724\n",
            "Training... Epoch: 1, Iter: 990,\t [31680/82081\t (39%)]\tLoss: 8.902107, Loc Loss: 2.452104, Conf Loss: 6.450004\tIter time: 0.2995\n",
            "Training... Epoch: 1, Iter: 1000,\t [32000/82081\t (39%)]\tLoss: 8.543895, Loc Loss: 2.472863, Conf Loss: 6.071031\tIter time: 0.2989\n",
            "Training... Epoch: 1, Iter: 1010,\t [32320/82081\t (39%)]\tLoss: 8.890313, Loc Loss: 2.558323, Conf Loss: 6.331990\tIter time: 0.2883\n",
            "Training... Epoch: 1, Iter: 1020,\t [32640/82081\t (40%)]\tLoss: 8.286230, Loc Loss: 2.403401, Conf Loss: 5.882830\tIter time: 0.3037\n",
            "Training... Epoch: 1, Iter: 1030,\t [32960/82081\t (40%)]\tLoss: 8.101516, Loc Loss: 2.509722, Conf Loss: 5.591794\tIter time: 0.2801\n",
            "Training... Epoch: 1, Iter: 1040,\t [33280/82081\t (41%)]\tLoss: 9.137434, Loc Loss: 2.796703, Conf Loss: 6.340731\tIter time: 0.2950\n",
            "Training... Epoch: 1, Iter: 1050,\t [33600/82081\t (41%)]\tLoss: 8.472281, Loc Loss: 2.609946, Conf Loss: 5.862334\tIter time: 0.2915\n",
            "Training... Epoch: 1, Iter: 1060,\t [33920/82081\t (41%)]\tLoss: 8.550949, Loc Loss: 2.409610, Conf Loss: 6.141339\tIter time: 0.2935\n",
            "Training... Epoch: 1, Iter: 1070,\t [34240/82081\t (42%)]\tLoss: 8.639593, Loc Loss: 2.513007, Conf Loss: 6.126586\tIter time: 0.2928\n",
            "Training... Epoch: 1, Iter: 1080,\t [34560/82081\t (42%)]\tLoss: 8.557970, Loc Loss: 2.526863, Conf Loss: 6.031107\tIter time: 0.2985\n",
            "Training... Epoch: 1, Iter: 1090,\t [34880/82081\t (42%)]\tLoss: 8.317038, Loc Loss: 2.702623, Conf Loss: 5.614414\tIter time: 0.2751\n",
            "Training... Epoch: 1, Iter: 1100,\t [35200/82081\t (43%)]\tLoss: 8.496861, Loc Loss: 2.680520, Conf Loss: 5.816341\tIter time: 0.2900\n",
            "Training... Epoch: 1, Iter: 1110,\t [35520/82081\t (43%)]\tLoss: 7.944637, Loc Loss: 2.455380, Conf Loss: 5.489257\tIter time: 0.3222\n",
            "Training... Epoch: 1, Iter: 1120,\t [35840/82081\t (44%)]\tLoss: 8.269703, Loc Loss: 2.603819, Conf Loss: 5.665884\tIter time: 0.2909\n",
            "Training... Epoch: 1, Iter: 1130,\t [36160/82081\t (44%)]\tLoss: 8.764555, Loc Loss: 2.567610, Conf Loss: 6.196945\tIter time: 0.2976\n",
            "Training... Epoch: 1, Iter: 1140,\t [36480/82081\t (44%)]\tLoss: 8.195549, Loc Loss: 2.276368, Conf Loss: 5.919181\tIter time: 0.2856\n",
            "Training... Epoch: 1, Iter: 1150,\t [36800/82081\t (45%)]\tLoss: 8.215641, Loc Loss: 2.501800, Conf Loss: 5.713840\tIter time: 0.2896\n",
            "Training... Epoch: 1, Iter: 1160,\t [37120/82081\t (45%)]\tLoss: 8.650472, Loc Loss: 2.585445, Conf Loss: 6.065027\tIter time: 0.2899\n",
            "Training... Epoch: 1, Iter: 1170,\t [37440/82081\t (46%)]\tLoss: 8.233397, Loc Loss: 2.607364, Conf Loss: 5.626034\tIter time: 0.2914\n",
            "Training... Epoch: 1, Iter: 1180,\t [37760/82081\t (46%)]\tLoss: 8.380583, Loc Loss: 2.445144, Conf Loss: 5.935439\tIter time: 0.2894\n",
            "Training... Epoch: 1, Iter: 1190,\t [38080/82081\t (46%)]\tLoss: 8.130621, Loc Loss: 2.326523, Conf Loss: 5.804098\tIter time: 0.2954\n",
            "Training... Epoch: 1, Iter: 1200,\t [38400/82081\t (47%)]\tLoss: 7.894911, Loc Loss: 2.593238, Conf Loss: 5.301673\tIter time: 0.2754\n",
            "Training... Epoch: 1, Iter: 1210,\t [38720/82081\t (47%)]\tLoss: 7.757076, Loc Loss: 2.180865, Conf Loss: 5.576212\tIter time: 0.2737\n",
            "Training... Epoch: 1, Iter: 1220,\t [39040/82081\t (48%)]\tLoss: 7.715042, Loc Loss: 2.520499, Conf Loss: 5.194543\tIter time: 0.2867\n",
            "Training... Epoch: 1, Iter: 1230,\t [39360/82081\t (48%)]\tLoss: 8.286248, Loc Loss: 2.274653, Conf Loss: 6.011595\tIter time: 0.2919\n",
            "Training... Epoch: 1, Iter: 1240,\t [39680/82081\t (48%)]\tLoss: 8.486294, Loc Loss: 2.423477, Conf Loss: 6.062817\tIter time: 0.3005\n",
            "Training... Epoch: 1, Iter: 1250,\t [40000/82081\t (49%)]\tLoss: 8.362157, Loc Loss: 2.632866, Conf Loss: 5.729290\tIter time: 0.3012\n",
            "Training... Epoch: 1, Iter: 1260,\t [40320/82081\t (49%)]\tLoss: 8.578183, Loc Loss: 2.403447, Conf Loss: 6.174736\tIter time: 0.2693\n",
            "Training... Epoch: 1, Iter: 1270,\t [40640/82081\t (49%)]\tLoss: 8.156131, Loc Loss: 2.415421, Conf Loss: 5.740710\tIter time: 0.2955\n",
            "Training... Epoch: 1, Iter: 1280,\t [40960/82081\t (50%)]\tLoss: 8.170094, Loc Loss: 2.373682, Conf Loss: 5.796412\tIter time: 0.2997\n",
            "Training... Epoch: 1, Iter: 1290,\t [41280/82081\t (50%)]\tLoss: 8.630424, Loc Loss: 2.562444, Conf Loss: 6.067979\tIter time: 0.2711\n",
            "Training... Epoch: 1, Iter: 1300,\t [41600/82081\t (51%)]\tLoss: 8.966099, Loc Loss: 2.729826, Conf Loss: 6.236273\tIter time: 0.2846\n",
            "Training... Epoch: 1, Iter: 1310,\t [41920/82081\t (51%)]\tLoss: 8.525242, Loc Loss: 2.448149, Conf Loss: 6.077092\tIter time: 0.2987\n",
            "Training... Epoch: 1, Iter: 1320,\t [42240/82081\t (51%)]\tLoss: 8.026148, Loc Loss: 2.441770, Conf Loss: 5.584378\tIter time: 0.2915\n",
            "Training... Epoch: 1, Iter: 1330,\t [42560/82081\t (52%)]\tLoss: 8.438807, Loc Loss: 2.482424, Conf Loss: 5.956382\tIter time: 0.2861\n",
            "Training... Epoch: 1, Iter: 1340,\t [42880/82081\t (52%)]\tLoss: 8.218131, Loc Loss: 2.415246, Conf Loss: 5.802885\tIter time: 0.2891\n",
            "Training... Epoch: 1, Iter: 1350,\t [43200/82081\t (53%)]\tLoss: 7.479368, Loc Loss: 2.133387, Conf Loss: 5.345982\tIter time: 0.2929\n",
            "Training... Epoch: 1, Iter: 1360,\t [43520/82081\t (53%)]\tLoss: 7.759377, Loc Loss: 2.129834, Conf Loss: 5.629543\tIter time: 0.2784\n",
            "Training... Epoch: 1, Iter: 1370,\t [43840/82081\t (53%)]\tLoss: 8.603958, Loc Loss: 2.769464, Conf Loss: 5.834494\tIter time: 0.2681\n",
            "Training... Epoch: 1, Iter: 1380,\t [44160/82081\t (54%)]\tLoss: 8.109851, Loc Loss: 2.182395, Conf Loss: 5.927455\tIter time: 0.3065\n",
            "Training... Epoch: 1, Iter: 1390,\t [44480/82081\t (54%)]\tLoss: 8.459366, Loc Loss: 2.741948, Conf Loss: 5.717417\tIter time: 0.3019\n",
            "Training... Epoch: 1, Iter: 1400,\t [44800/82081\t (55%)]\tLoss: 7.914497, Loc Loss: 2.252942, Conf Loss: 5.661556\tIter time: 0.2703\n",
            "Training... Epoch: 1, Iter: 1410,\t [45120/82081\t (55%)]\tLoss: 8.474577, Loc Loss: 2.545504, Conf Loss: 5.929073\tIter time: 0.2909\n",
            "Training... Epoch: 1, Iter: 1420,\t [45440/82081\t (55%)]\tLoss: 7.648212, Loc Loss: 2.210890, Conf Loss: 5.437322\tIter time: 0.2861\n",
            "Training... Epoch: 1, Iter: 1430,\t [45760/82081\t (56%)]\tLoss: 7.783368, Loc Loss: 2.218170, Conf Loss: 5.565198\tIter time: 0.2888\n",
            "Training... Epoch: 1, Iter: 1440,\t [46080/82081\t (56%)]\tLoss: 8.344854, Loc Loss: 2.498039, Conf Loss: 5.846815\tIter time: 0.2967\n",
            "Training... Epoch: 1, Iter: 1450,\t [46400/82081\t (57%)]\tLoss: 8.147911, Loc Loss: 2.656699, Conf Loss: 5.491212\tIter time: 0.3378\n",
            "Training... Epoch: 1, Iter: 1460,\t [46720/82081\t (57%)]\tLoss: 7.810165, Loc Loss: 2.187389, Conf Loss: 5.622777\tIter time: 0.2912\n",
            "Training... Epoch: 1, Iter: 1470,\t [47040/82081\t (57%)]\tLoss: 8.070417, Loc Loss: 2.573919, Conf Loss: 5.496498\tIter time: 0.3156\n",
            "Training... Epoch: 1, Iter: 1480,\t [47360/82081\t (58%)]\tLoss: 8.087173, Loc Loss: 2.513489, Conf Loss: 5.573683\tIter time: 0.2913\n",
            "Training... Epoch: 1, Iter: 1490,\t [47680/82081\t (58%)]\tLoss: 7.942326, Loc Loss: 2.372021, Conf Loss: 5.570305\tIter time: 0.2964\n",
            "Training... Epoch: 1, Iter: 1500,\t [48000/82081\t (58%)]\tLoss: 8.665564, Loc Loss: 2.746310, Conf Loss: 5.919254\tIter time: 0.2757\n",
            "Training... Epoch: 1, Iter: 1510,\t [48320/82081\t (59%)]\tLoss: 8.080519, Loc Loss: 2.171066, Conf Loss: 5.909453\tIter time: 0.2717\n",
            "Training... Epoch: 1, Iter: 1520,\t [48640/82081\t (59%)]\tLoss: 8.050125, Loc Loss: 2.370413, Conf Loss: 5.679712\tIter time: 0.2927\n",
            "Training... Epoch: 1, Iter: 1530,\t [48960/82081\t (60%)]\tLoss: 8.845852, Loc Loss: 2.538338, Conf Loss: 6.307515\tIter time: 0.2870\n",
            "Training... Epoch: 1, Iter: 1540,\t [49280/82081\t (60%)]\tLoss: 8.017548, Loc Loss: 2.345894, Conf Loss: 5.671653\tIter time: 0.2699\n",
            "Training... Epoch: 1, Iter: 1550,\t [49600/82081\t (60%)]\tLoss: 7.761294, Loc Loss: 2.602697, Conf Loss: 5.158597\tIter time: 0.2965\n",
            "Training... Epoch: 1, Iter: 1560,\t [49920/82081\t (61%)]\tLoss: 8.402212, Loc Loss: 2.676744, Conf Loss: 5.725469\tIter time: 0.2797\n",
            "Training... Epoch: 1, Iter: 1570,\t [50240/82081\t (61%)]\tLoss: 8.256091, Loc Loss: 2.423454, Conf Loss: 5.832637\tIter time: 0.2790\n",
            "Training... Epoch: 1, Iter: 1580,\t [50560/82081\t (62%)]\tLoss: 8.298919, Loc Loss: 2.454061, Conf Loss: 5.844858\tIter time: 0.2793\n",
            "Training... Epoch: 1, Iter: 1590,\t [50880/82081\t (62%)]\tLoss: 7.963441, Loc Loss: 2.137996, Conf Loss: 5.825445\tIter time: 0.2830\n",
            "Training... Epoch: 1, Iter: 1600,\t [51200/82081\t (62%)]\tLoss: 7.825274, Loc Loss: 2.324275, Conf Loss: 5.500998\tIter time: 0.2741\n",
            "Training... Epoch: 1, Iter: 1610,\t [51520/82081\t (63%)]\tLoss: 7.900824, Loc Loss: 2.489056, Conf Loss: 5.411768\tIter time: 0.2726\n",
            "Training... Epoch: 1, Iter: 1620,\t [51840/82081\t (63%)]\tLoss: 7.802541, Loc Loss: 2.513566, Conf Loss: 5.288975\tIter time: 0.3034\n",
            "Training... Epoch: 1, Iter: 1630,\t [52160/82081\t (64%)]\tLoss: 7.843090, Loc Loss: 2.342262, Conf Loss: 5.500828\tIter time: 0.3168\n",
            "Training... Epoch: 1, Iter: 1640,\t [52480/82081\t (64%)]\tLoss: 7.643637, Loc Loss: 2.306869, Conf Loss: 5.336769\tIter time: 0.3102\n",
            "Training... Epoch: 1, Iter: 1650,\t [52800/82081\t (64%)]\tLoss: 7.897714, Loc Loss: 2.621861, Conf Loss: 5.275853\tIter time: 0.2884\n",
            "Training... Epoch: 1, Iter: 1660,\t [53120/82081\t (65%)]\tLoss: 7.931250, Loc Loss: 2.220285, Conf Loss: 5.710965\tIter time: 0.2747\n",
            "Training... Epoch: 1, Iter: 1670,\t [53440/82081\t (65%)]\tLoss: 8.203392, Loc Loss: 2.113240, Conf Loss: 6.090151\tIter time: 0.3019\n",
            "Training... Epoch: 1, Iter: 1680,\t [53760/82081\t (65%)]\tLoss: 7.848359, Loc Loss: 2.515454, Conf Loss: 5.332905\tIter time: 0.2810\n",
            "Training... Epoch: 1, Iter: 1690,\t [54080/82081\t (66%)]\tLoss: 7.989618, Loc Loss: 2.176386, Conf Loss: 5.813232\tIter time: 0.2817\n",
            "Training... Epoch: 1, Iter: 1700,\t [54400/82081\t (66%)]\tLoss: 8.067806, Loc Loss: 2.443844, Conf Loss: 5.623962\tIter time: 0.2775\n",
            "Training... Epoch: 1, Iter: 1710,\t [54720/82081\t (67%)]\tLoss: 7.959560, Loc Loss: 2.125392, Conf Loss: 5.834168\tIter time: 0.2917\n",
            "Training... Epoch: 1, Iter: 1720,\t [55040/82081\t (67%)]\tLoss: 8.149683, Loc Loss: 2.374388, Conf Loss: 5.775295\tIter time: 0.3020\n",
            "Training... Epoch: 1, Iter: 1730,\t [55360/82081\t (67%)]\tLoss: 7.412219, Loc Loss: 2.025792, Conf Loss: 5.386427\tIter time: 0.2710\n",
            "Training... Epoch: 1, Iter: 1740,\t [55680/82081\t (68%)]\tLoss: 7.897158, Loc Loss: 2.217770, Conf Loss: 5.679388\tIter time: 0.2949\n",
            "Training... Epoch: 1, Iter: 1750,\t [56000/82081\t (68%)]\tLoss: 8.072087, Loc Loss: 2.400381, Conf Loss: 5.671707\tIter time: 0.2723\n",
            "Training... Epoch: 1, Iter: 1760,\t [56320/82081\t (69%)]\tLoss: 7.539265, Loc Loss: 2.121431, Conf Loss: 5.417834\tIter time: 0.2927\n",
            "Training... Epoch: 1, Iter: 1770,\t [56640/82081\t (69%)]\tLoss: 8.041156, Loc Loss: 2.452025, Conf Loss: 5.589130\tIter time: 0.2911\n",
            "Training... Epoch: 1, Iter: 1780,\t [56960/82081\t (69%)]\tLoss: 8.304898, Loc Loss: 2.372852, Conf Loss: 5.932046\tIter time: 0.2935\n",
            "Training... Epoch: 1, Iter: 1790,\t [57280/82081\t (70%)]\tLoss: 8.339680, Loc Loss: 2.778776, Conf Loss: 5.560905\tIter time: 0.3153\n",
            "Training... Epoch: 1, Iter: 1800,\t [57600/82081\t (70%)]\tLoss: 7.760474, Loc Loss: 2.108884, Conf Loss: 5.651590\tIter time: 0.2906\n",
            "Training... Epoch: 1, Iter: 1810,\t [57920/82081\t (71%)]\tLoss: 8.268196, Loc Loss: 2.339870, Conf Loss: 5.928327\tIter time: 0.2675\n",
            "Training... Epoch: 1, Iter: 1820,\t [58240/82081\t (71%)]\tLoss: 8.105385, Loc Loss: 2.284707, Conf Loss: 5.820677\tIter time: 0.2887\n",
            "Training... Epoch: 1, Iter: 1830,\t [58560/82081\t (71%)]\tLoss: 8.484320, Loc Loss: 2.612509, Conf Loss: 5.871811\tIter time: 0.3012\n",
            "Training... Epoch: 1, Iter: 1840,\t [58880/82081\t (72%)]\tLoss: 7.933250, Loc Loss: 2.325063, Conf Loss: 5.608188\tIter time: 0.3146\n",
            "Training... Epoch: 1, Iter: 1850,\t [59200/82081\t (72%)]\tLoss: 7.551490, Loc Loss: 2.211394, Conf Loss: 5.340096\tIter time: 0.2911\n",
            "Training... Epoch: 1, Iter: 1860,\t [59520/82081\t (72%)]\tLoss: 7.855533, Loc Loss: 2.389937, Conf Loss: 5.465595\tIter time: 0.2797\n",
            "Training... Epoch: 1, Iter: 1870,\t [59840/82081\t (73%)]\tLoss: 8.002389, Loc Loss: 2.353455, Conf Loss: 5.648934\tIter time: 0.3004\n",
            "Training... Epoch: 1, Iter: 1880,\t [60160/82081\t (73%)]\tLoss: 7.796918, Loc Loss: 2.273667, Conf Loss: 5.523252\tIter time: 0.2930\n",
            "Training... Epoch: 1, Iter: 1890,\t [60480/82081\t (74%)]\tLoss: 7.986802, Loc Loss: 2.343161, Conf Loss: 5.643641\tIter time: 0.2951\n",
            "Training... Epoch: 1, Iter: 1900,\t [60800/82081\t (74%)]\tLoss: 8.307762, Loc Loss: 2.824289, Conf Loss: 5.483473\tIter time: 0.2936\n",
            "Training... Epoch: 1, Iter: 1910,\t [61120/82081\t (74%)]\tLoss: 8.403101, Loc Loss: 2.454947, Conf Loss: 5.948154\tIter time: 0.2764\n",
            "Training... Epoch: 1, Iter: 1920,\t [61440/82081\t (75%)]\tLoss: 8.037943, Loc Loss: 2.590826, Conf Loss: 5.447117\tIter time: 0.3015\n",
            "Training... Epoch: 1, Iter: 1930,\t [61760/82081\t (75%)]\tLoss: 8.612677, Loc Loss: 2.789053, Conf Loss: 5.823623\tIter time: 0.2893\n",
            "Training... Epoch: 1, Iter: 1940,\t [62080/82081\t (76%)]\tLoss: 7.367426, Loc Loss: 2.330286, Conf Loss: 5.037140\tIter time: 0.2955\n",
            "Training... Epoch: 1, Iter: 1950,\t [62400/82081\t (76%)]\tLoss: 7.893666, Loc Loss: 2.108126, Conf Loss: 5.785540\tIter time: 0.2860\n",
            "Training... Epoch: 1, Iter: 1960,\t [62720/82081\t (76%)]\tLoss: 7.512236, Loc Loss: 2.076208, Conf Loss: 5.436028\tIter time: 0.2850\n",
            "Training... Epoch: 1, Iter: 1970,\t [63040/82081\t (77%)]\tLoss: 7.967750, Loc Loss: 2.397586, Conf Loss: 5.570164\tIter time: 0.2743\n",
            "Training... Epoch: 1, Iter: 1980,\t [63360/82081\t (77%)]\tLoss: 7.744041, Loc Loss: 2.264683, Conf Loss: 5.479359\tIter time: 0.3328\n",
            "Training... Epoch: 1, Iter: 1990,\t [63680/82081\t (78%)]\tLoss: 7.952791, Loc Loss: 2.460634, Conf Loss: 5.492158\tIter time: 0.2957\n",
            "Training... Epoch: 1, Iter: 2000,\t [64000/82081\t (78%)]\tLoss: 8.022419, Loc Loss: 2.317257, Conf Loss: 5.705162\tIter time: 0.3040\n",
            "Training... Epoch: 1, Iter: 2010,\t [64320/82081\t (78%)]\tLoss: 8.083179, Loc Loss: 2.458758, Conf Loss: 5.624422\tIter time: 0.2954\n",
            "Training... Epoch: 1, Iter: 2020,\t [64640/82081\t (79%)]\tLoss: 7.668677, Loc Loss: 2.246193, Conf Loss: 5.422484\tIter time: 0.2842\n",
            "Training... Epoch: 1, Iter: 2030,\t [64960/82081\t (79%)]\tLoss: 8.339747, Loc Loss: 2.499617, Conf Loss: 5.840130\tIter time: 0.2952\n",
            "Training... Epoch: 1, Iter: 2040,\t [65280/82081\t (80%)]\tLoss: 7.806503, Loc Loss: 2.233729, Conf Loss: 5.572774\tIter time: 0.3002\n",
            "Training... Epoch: 1, Iter: 2050,\t [65600/82081\t (80%)]\tLoss: 7.702460, Loc Loss: 2.328318, Conf Loss: 5.374142\tIter time: 0.2997\n",
            "Training... Epoch: 1, Iter: 2060,\t [65920/82081\t (80%)]\tLoss: 7.769038, Loc Loss: 2.249570, Conf Loss: 5.519468\tIter time: 0.2937\n",
            "Training... Epoch: 1, Iter: 2070,\t [66240/82081\t (81%)]\tLoss: 7.731874, Loc Loss: 1.825085, Conf Loss: 5.906789\tIter time: 0.2873\n",
            "Training... Epoch: 1, Iter: 2080,\t [66560/82081\t (81%)]\tLoss: 7.635715, Loc Loss: 2.199050, Conf Loss: 5.436666\tIter time: 0.2924\n",
            "Training... Epoch: 1, Iter: 2090,\t [66880/82081\t (81%)]\tLoss: 7.697547, Loc Loss: 2.294385, Conf Loss: 5.403162\tIter time: 0.2999\n",
            "Training... Epoch: 1, Iter: 2100,\t [67200/82081\t (82%)]\tLoss: 8.403067, Loc Loss: 2.064442, Conf Loss: 6.338624\tIter time: 0.2931\n",
            "Training... Epoch: 1, Iter: 2110,\t [67520/82081\t (82%)]\tLoss: 7.532883, Loc Loss: 2.183386, Conf Loss: 5.349496\tIter time: 0.2866\n",
            "Training... Epoch: 1, Iter: 2120,\t [67840/82081\t (83%)]\tLoss: 7.894160, Loc Loss: 2.179716, Conf Loss: 5.714444\tIter time: 0.2839\n",
            "Training... Epoch: 1, Iter: 2130,\t [68160/82081\t (83%)]\tLoss: 8.171524, Loc Loss: 2.242432, Conf Loss: 5.929092\tIter time: 0.3060\n",
            "Training... Epoch: 1, Iter: 2140,\t [68480/82081\t (83%)]\tLoss: 8.264865, Loc Loss: 2.691564, Conf Loss: 5.573301\tIter time: 0.2792\n",
            "Training... Epoch: 1, Iter: 2150,\t [68800/82081\t (84%)]\tLoss: 7.629628, Loc Loss: 2.177366, Conf Loss: 5.452262\tIter time: 0.2886\n",
            "Training... Epoch: 1, Iter: 2160,\t [69120/82081\t (84%)]\tLoss: 7.825605, Loc Loss: 2.430952, Conf Loss: 5.394653\tIter time: 0.3025\n",
            "Training... Epoch: 1, Iter: 2170,\t [69440/82081\t (85%)]\tLoss: 8.150774, Loc Loss: 2.573078, Conf Loss: 5.577697\tIter time: 0.2991\n",
            "Training... Epoch: 1, Iter: 2180,\t [69760/82081\t (85%)]\tLoss: 8.391041, Loc Loss: 2.587216, Conf Loss: 5.803825\tIter time: 0.2984\n",
            "Training... Epoch: 1, Iter: 2190,\t [70080/82081\t (85%)]\tLoss: 7.780353, Loc Loss: 2.534553, Conf Loss: 5.245800\tIter time: 0.2950\n",
            "Training... Epoch: 1, Iter: 2200,\t [70400/82081\t (86%)]\tLoss: 8.504808, Loc Loss: 2.428443, Conf Loss: 6.076365\tIter time: 0.2696\n",
            "Training... Epoch: 1, Iter: 2210,\t [70720/82081\t (86%)]\tLoss: 7.633020, Loc Loss: 2.207986, Conf Loss: 5.425034\tIter time: 0.2863\n",
            "Training... Epoch: 1, Iter: 2220,\t [71040/82081\t (87%)]\tLoss: 7.169731, Loc Loss: 2.174860, Conf Loss: 4.994872\tIter time: 0.2964\n",
            "Training... Epoch: 1, Iter: 2230,\t [71360/82081\t (87%)]\tLoss: 7.568702, Loc Loss: 2.179970, Conf Loss: 5.388731\tIter time: 0.2922\n",
            "Training... Epoch: 1, Iter: 2240,\t [71680/82081\t (87%)]\tLoss: 7.775489, Loc Loss: 1.935947, Conf Loss: 5.839541\tIter time: 0.2895\n",
            "Training... Epoch: 1, Iter: 2250,\t [72000/82081\t (88%)]\tLoss: 8.090339, Loc Loss: 2.275384, Conf Loss: 5.814954\tIter time: 0.2921\n",
            "Training... Epoch: 1, Iter: 2260,\t [72320/82081\t (88%)]\tLoss: 8.062059, Loc Loss: 2.163839, Conf Loss: 5.898220\tIter time: 0.2665\n",
            "Training... Epoch: 1, Iter: 2270,\t [72640/82081\t (88%)]\tLoss: 7.661370, Loc Loss: 2.317825, Conf Loss: 5.343545\tIter time: 0.2965\n",
            "Training... Epoch: 1, Iter: 2280,\t [72960/82081\t (89%)]\tLoss: 7.658596, Loc Loss: 2.060267, Conf Loss: 5.598329\tIter time: 0.3188\n",
            "Training... Epoch: 1, Iter: 2290,\t [73280/82081\t (89%)]\tLoss: 8.082079, Loc Loss: 2.335379, Conf Loss: 5.746700\tIter time: 0.2652\n",
            "Training... Epoch: 1, Iter: 2300,\t [73600/82081\t (90%)]\tLoss: 8.001890, Loc Loss: 2.396507, Conf Loss: 5.605383\tIter time: 0.2948\n",
            "Training... Epoch: 1, Iter: 2310,\t [73920/82081\t (90%)]\tLoss: 8.110514, Loc Loss: 2.347722, Conf Loss: 5.762792\tIter time: 0.2763\n",
            "Training... Epoch: 1, Iter: 2320,\t [74240/82081\t (90%)]\tLoss: 7.852250, Loc Loss: 2.116959, Conf Loss: 5.735291\tIter time: 0.2948\n",
            "Training... Epoch: 1, Iter: 2330,\t [74560/82081\t (91%)]\tLoss: 7.790881, Loc Loss: 2.254131, Conf Loss: 5.536749\tIter time: 0.2900\n",
            "Training... Epoch: 1, Iter: 2340,\t [74880/82081\t (91%)]\tLoss: 7.932170, Loc Loss: 2.528220, Conf Loss: 5.403950\tIter time: 0.2749\n",
            "Training... Epoch: 1, Iter: 2350,\t [75200/82081\t (92%)]\tLoss: 8.191998, Loc Loss: 2.151859, Conf Loss: 6.040139\tIter time: 0.2720\n",
            "Training... Epoch: 1, Iter: 2360,\t [75520/82081\t (92%)]\tLoss: 7.656429, Loc Loss: 2.421731, Conf Loss: 5.234698\tIter time: 0.2950\n",
            "Training... Epoch: 1, Iter: 2370,\t [75840/82081\t (92%)]\tLoss: 7.436792, Loc Loss: 2.106426, Conf Loss: 5.330367\tIter time: 0.3262\n",
            "Training... Epoch: 1, Iter: 2380,\t [76160/82081\t (93%)]\tLoss: 7.661480, Loc Loss: 2.143133, Conf Loss: 5.518347\tIter time: 0.2815\n",
            "Training... Epoch: 1, Iter: 2390,\t [76480/82081\t (93%)]\tLoss: 8.153176, Loc Loss: 2.585413, Conf Loss: 5.567763\tIter time: 0.2776\n",
            "Training... Epoch: 1, Iter: 2400,\t [76800/82081\t (94%)]\tLoss: 7.478576, Loc Loss: 2.197355, Conf Loss: 5.281221\tIter time: 0.2805\n",
            "Training... Epoch: 1, Iter: 2410,\t [77120/82081\t (94%)]\tLoss: 7.863582, Loc Loss: 2.239818, Conf Loss: 5.623764\tIter time: 0.2951\n",
            "Training... Epoch: 1, Iter: 2420,\t [77440/82081\t (94%)]\tLoss: 7.778151, Loc Loss: 2.198153, Conf Loss: 5.579998\tIter time: 0.2989\n",
            "Training... Epoch: 1, Iter: 2430,\t [77760/82081\t (95%)]\tLoss: 7.906551, Loc Loss: 2.224422, Conf Loss: 5.682129\tIter time: 0.3113\n",
            "Training... Epoch: 1, Iter: 2440,\t [78080/82081\t (95%)]\tLoss: 7.335277, Loc Loss: 2.002589, Conf Loss: 5.332687\tIter time: 0.2758\n",
            "Training... Epoch: 1, Iter: 2450,\t [78400/82081\t (95%)]\tLoss: 8.317376, Loc Loss: 2.538354, Conf Loss: 5.779022\tIter time: 0.3015\n",
            "Training... Epoch: 1, Iter: 2460,\t [78720/82081\t (96%)]\tLoss: 7.981686, Loc Loss: 2.447198, Conf Loss: 5.534488\tIter time: 0.2701\n",
            "Training... Epoch: 1, Iter: 2470,\t [79040/82081\t (96%)]\tLoss: 8.305116, Loc Loss: 2.692553, Conf Loss: 5.612562\tIter time: 0.3026\n",
            "Training... Epoch: 1, Iter: 2480,\t [79360/82081\t (97%)]\tLoss: 7.555094, Loc Loss: 2.089528, Conf Loss: 5.465566\tIter time: 0.2857\n",
            "Training... Epoch: 1, Iter: 2490,\t [79680/82081\t (97%)]\tLoss: 7.411534, Loc Loss: 2.271997, Conf Loss: 5.139537\tIter time: 0.3080\n",
            "Training... Epoch: 1, Iter: 2500,\t [80000/82081\t (97%)]\tLoss: 7.533298, Loc Loss: 2.175089, Conf Loss: 5.358210\tIter time: 0.2963\n",
            "Training... Epoch: 1, Iter: 2510,\t [80320/82081\t (98%)]\tLoss: 7.985555, Loc Loss: 2.401857, Conf Loss: 5.583697\tIter time: 0.2724\n",
            "Training... Epoch: 1, Iter: 2520,\t [80640/82081\t (98%)]\tLoss: 7.118315, Loc Loss: 2.317939, Conf Loss: 4.800376\tIter time: 0.2999\n",
            "Training... Epoch: 1, Iter: 2530,\t [80960/82081\t (99%)]\tLoss: 7.983034, Loc Loss: 2.271406, Conf Loss: 5.711628\tIter time: 0.2830\n",
            "Training... Epoch: 1, Iter: 2540,\t [81280/82081\t (99%)]\tLoss: 7.793298, Loc Loss: 2.379352, Conf Loss: 5.413946\tIter time: 0.2784\n",
            "Training... Epoch: 1, Iter: 2550,\t [81600/82081\t (99%)]\tLoss: 7.318443, Loc Loss: 2.006574, Conf Loss: 5.311869\tIter time: 0.2875\n",
            "Training... Epoch: 1, Iter: 2560,\t [81920/82081\t (100%)]\tLoss: 7.597861, Loc Loss: 2.511839, Conf Loss: 5.086023\tIter time: 0.2684\n",
            "Training... Epoch: 2, Iter: 2570,\t [128/82081\t (0%)]\tLoss: 7.852075, Loc Loss: 2.352470, Conf Loss: 5.499605\tIter time: 0.3038\n",
            "Training... Epoch: 2, Iter: 2580,\t [448/82081\t (1%)]\tLoss: 8.240173, Loc Loss: 2.547883, Conf Loss: 5.692290\tIter time: 0.2815\n",
            "Training... Epoch: 2, Iter: 2590,\t [768/82081\t (1%)]\tLoss: 7.846029, Loc Loss: 2.229883, Conf Loss: 5.616146\tIter time: 0.2856\n",
            "Training... Epoch: 2, Iter: 2600,\t [1088/82081\t (1%)]\tLoss: 7.617062, Loc Loss: 2.264115, Conf Loss: 5.352947\tIter time: 0.3016\n",
            "Training... Epoch: 2, Iter: 2610,\t [1408/82081\t (2%)]\tLoss: 7.130633, Loc Loss: 2.117015, Conf Loss: 5.013618\tIter time: 0.2902\n",
            "Training... Epoch: 2, Iter: 2620,\t [1728/82081\t (2%)]\tLoss: 7.659389, Loc Loss: 2.298544, Conf Loss: 5.360846\tIter time: 0.2875\n",
            "Training... Epoch: 2, Iter: 2630,\t [2048/82081\t (2%)]\tLoss: 7.598596, Loc Loss: 2.372787, Conf Loss: 5.225808\tIter time: 0.2843\n",
            "Training... Epoch: 2, Iter: 2640,\t [2368/82081\t (3%)]\tLoss: 7.987949, Loc Loss: 2.731052, Conf Loss: 5.256897\tIter time: 0.2983\n",
            "Training... Epoch: 2, Iter: 2650,\t [2688/82081\t (3%)]\tLoss: 7.805499, Loc Loss: 2.370571, Conf Loss: 5.434928\tIter time: 0.3005\n",
            "Training... Epoch: 2, Iter: 2660,\t [3008/82081\t (4%)]\tLoss: 7.741024, Loc Loss: 2.005614, Conf Loss: 5.735410\tIter time: 0.2807\n",
            "Training... Epoch: 2, Iter: 2670,\t [3328/82081\t (4%)]\tLoss: 7.630508, Loc Loss: 2.367059, Conf Loss: 5.263450\tIter time: 0.2789\n",
            "Training... Epoch: 2, Iter: 2680,\t [3648/82081\t (4%)]\tLoss: 7.918448, Loc Loss: 2.459553, Conf Loss: 5.458895\tIter time: 0.2896\n",
            "Training... Epoch: 2, Iter: 2690,\t [3968/82081\t (5%)]\tLoss: 8.037326, Loc Loss: 2.175813, Conf Loss: 5.861513\tIter time: 0.2956\n",
            "Training... Epoch: 2, Iter: 2700,\t [4288/82081\t (5%)]\tLoss: 7.380208, Loc Loss: 2.177097, Conf Loss: 5.203111\tIter time: 0.2942\n",
            "Training... Epoch: 2, Iter: 2710,\t [4608/82081\t (6%)]\tLoss: 7.527489, Loc Loss: 2.047177, Conf Loss: 5.480311\tIter time: 0.2752\n",
            "Training... Epoch: 2, Iter: 2720,\t [4928/82081\t (6%)]\tLoss: 7.799477, Loc Loss: 2.483462, Conf Loss: 5.316015\tIter time: 0.2681\n",
            "Training... Epoch: 2, Iter: 2730,\t [5248/82081\t (6%)]\tLoss: 7.530579, Loc Loss: 2.331981, Conf Loss: 5.198598\tIter time: 0.2920\n",
            "Training... Epoch: 2, Iter: 2740,\t [5568/82081\t (7%)]\tLoss: 8.010032, Loc Loss: 2.311428, Conf Loss: 5.698604\tIter time: 0.2954\n",
            "Training... Epoch: 2, Iter: 2750,\t [5888/82081\t (7%)]\tLoss: 7.956141, Loc Loss: 2.373415, Conf Loss: 5.582726\tIter time: 0.2908\n",
            "Training... Epoch: 2, Iter: 2760,\t [6208/82081\t (8%)]\tLoss: 7.787095, Loc Loss: 2.323179, Conf Loss: 5.463916\tIter time: 0.2881\n",
            "Training... Epoch: 2, Iter: 2770,\t [6528/82081\t (8%)]\tLoss: 7.627755, Loc Loss: 2.154099, Conf Loss: 5.473656\tIter time: 0.2897\n",
            "Training... Epoch: 2, Iter: 2780,\t [6848/82081\t (8%)]\tLoss: 7.773479, Loc Loss: 2.119290, Conf Loss: 5.654189\tIter time: 0.2928\n",
            "Training... Epoch: 2, Iter: 2790,\t [7168/82081\t (9%)]\tLoss: 7.807211, Loc Loss: 2.059850, Conf Loss: 5.747361\tIter time: 0.2855\n",
            "Training... Epoch: 2, Iter: 2800,\t [7488/82081\t (9%)]\tLoss: 7.471614, Loc Loss: 2.272120, Conf Loss: 5.199494\tIter time: 0.2750\n",
            "Training... Epoch: 2, Iter: 2810,\t [7808/82081\t (10%)]\tLoss: 7.638266, Loc Loss: 2.244433, Conf Loss: 5.393833\tIter time: 0.2842\n",
            "Training... Epoch: 2, Iter: 2820,\t [8128/82081\t (10%)]\tLoss: 7.468600, Loc Loss: 2.062336, Conf Loss: 5.406264\tIter time: 0.2987\n",
            "Training... Epoch: 2, Iter: 2830,\t [8448/82081\t (10%)]\tLoss: 7.546262, Loc Loss: 2.267417, Conf Loss: 5.278844\tIter time: 0.3012\n",
            "Training... Epoch: 2, Iter: 2840,\t [8768/82081\t (11%)]\tLoss: 7.459615, Loc Loss: 2.511518, Conf Loss: 4.948097\tIter time: 0.2865\n",
            "Training... Epoch: 2, Iter: 2850,\t [9088/82081\t (11%)]\tLoss: 7.879169, Loc Loss: 2.348676, Conf Loss: 5.530493\tIter time: 0.2848\n",
            "Training... Epoch: 2, Iter: 2860,\t [9408/82081\t (11%)]\tLoss: 7.440848, Loc Loss: 2.298753, Conf Loss: 5.142096\tIter time: 0.3008\n",
            "Training... Epoch: 2, Iter: 2870,\t [9728/82081\t (12%)]\tLoss: 7.465559, Loc Loss: 2.408889, Conf Loss: 5.056670\tIter time: 0.2801\n",
            "Training... Epoch: 2, Iter: 2880,\t [10048/82081\t (12%)]\tLoss: 7.655190, Loc Loss: 2.036540, Conf Loss: 5.618650\tIter time: 0.2756\n",
            "Training... Epoch: 2, Iter: 2890,\t [10368/82081\t (13%)]\tLoss: 7.796824, Loc Loss: 2.604360, Conf Loss: 5.192465\tIter time: 0.2879\n",
            "Training... Epoch: 2, Iter: 2900,\t [10688/82081\t (13%)]\tLoss: 8.151041, Loc Loss: 2.552475, Conf Loss: 5.598566\tIter time: 0.3052\n",
            "Training... Epoch: 2, Iter: 2910,\t [11008/82081\t (13%)]\tLoss: 7.736226, Loc Loss: 2.230424, Conf Loss: 5.505801\tIter time: 0.2906\n",
            "Training... Epoch: 2, Iter: 2920,\t [11328/82081\t (14%)]\tLoss: 7.667345, Loc Loss: 2.358267, Conf Loss: 5.309078\tIter time: 0.2891\n",
            "Training... Epoch: 2, Iter: 2930,\t [11648/82081\t (14%)]\tLoss: 7.925744, Loc Loss: 2.476842, Conf Loss: 5.448902\tIter time: 0.2895\n",
            "Training... Epoch: 2, Iter: 2940,\t [11968/82081\t (15%)]\tLoss: 7.562610, Loc Loss: 2.246061, Conf Loss: 5.316549\tIter time: 0.2981\n",
            "Training... Epoch: 2, Iter: 2950,\t [12288/82081\t (15%)]\tLoss: 7.624742, Loc Loss: 2.206658, Conf Loss: 5.418084\tIter time: 0.2953\n",
            "Training... Epoch: 2, Iter: 2960,\t [12608/82081\t (15%)]\tLoss: 7.897840, Loc Loss: 2.519423, Conf Loss: 5.378417\tIter time: 0.2852\n",
            "Training... Epoch: 2, Iter: 2970,\t [12928/82081\t (16%)]\tLoss: 7.377569, Loc Loss: 2.216175, Conf Loss: 5.161394\tIter time: 0.2922\n",
            "Training... Epoch: 2, Iter: 2980,\t [13248/82081\t (16%)]\tLoss: 7.483460, Loc Loss: 2.358113, Conf Loss: 5.125347\tIter time: 0.2960\n",
            "Training... Epoch: 2, Iter: 2990,\t [13568/82081\t (17%)]\tLoss: 7.082582, Loc Loss: 2.067793, Conf Loss: 5.014790\tIter time: 0.2897\n",
            "Training... Epoch: 2, Iter: 3000,\t [13888/82081\t (17%)]\tLoss: 7.366982, Loc Loss: 2.174152, Conf Loss: 5.192830\tIter time: 0.2930\n",
            "Training... Epoch: 2, Iter: 3010,\t [14208/82081\t (17%)]\tLoss: 8.045547, Loc Loss: 2.301202, Conf Loss: 5.744345\tIter time: 0.2704\n",
            "Training... Epoch: 2, Iter: 3020,\t [14528/82081\t (18%)]\tLoss: 7.645307, Loc Loss: 2.263473, Conf Loss: 5.381835\tIter time: 0.2985\n",
            "Training... Epoch: 2, Iter: 3030,\t [14848/82081\t (18%)]\tLoss: 7.719725, Loc Loss: 2.299085, Conf Loss: 5.420640\tIter time: 0.3008\n",
            "Training... Epoch: 2, Iter: 3040,\t [15168/82081\t (18%)]\tLoss: 7.476038, Loc Loss: 2.262305, Conf Loss: 5.213732\tIter time: 0.3031\n",
            "Training... Epoch: 2, Iter: 3050,\t [15488/82081\t (19%)]\tLoss: 7.404111, Loc Loss: 2.385999, Conf Loss: 5.018112\tIter time: 0.3205\n",
            "Training... Epoch: 2, Iter: 3060,\t [15808/82081\t (19%)]\tLoss: 7.848714, Loc Loss: 1.950508, Conf Loss: 5.898206\tIter time: 0.3237\n",
            "Training... Epoch: 2, Iter: 3070,\t [16128/82081\t (20%)]\tLoss: 7.731225, Loc Loss: 2.316595, Conf Loss: 5.414630\tIter time: 0.2888\n",
            "Training... Epoch: 2, Iter: 3080,\t [16448/82081\t (20%)]\tLoss: 6.968632, Loc Loss: 1.956421, Conf Loss: 5.012210\tIter time: 0.2878\n",
            "Training... Epoch: 2, Iter: 3090,\t [16768/82081\t (20%)]\tLoss: 7.367130, Loc Loss: 2.114428, Conf Loss: 5.252702\tIter time: 0.2704\n",
            "Training... Epoch: 2, Iter: 3100,\t [17088/82081\t (21%)]\tLoss: 7.432395, Loc Loss: 2.095610, Conf Loss: 5.336785\tIter time: 0.3059\n",
            "Training... Epoch: 2, Iter: 3110,\t [17408/82081\t (21%)]\tLoss: 7.471012, Loc Loss: 2.101550, Conf Loss: 5.369462\tIter time: 0.2977\n",
            "Training... Epoch: 2, Iter: 3120,\t [17728/82081\t (22%)]\tLoss: 6.976853, Loc Loss: 1.954391, Conf Loss: 5.022461\tIter time: 0.2739\n",
            "Training... Epoch: 2, Iter: 3130,\t [18048/82081\t (22%)]\tLoss: 7.618930, Loc Loss: 2.330624, Conf Loss: 5.288306\tIter time: 0.2937\n",
            "Training... Epoch: 2, Iter: 3140,\t [18368/82081\t (22%)]\tLoss: 7.341334, Loc Loss: 2.360423, Conf Loss: 4.980911\tIter time: 0.2700\n",
            "Training... Epoch: 2, Iter: 3150,\t [18688/82081\t (23%)]\tLoss: 7.597447, Loc Loss: 2.406180, Conf Loss: 5.191267\tIter time: 0.3126\n",
            "Training... Epoch: 2, Iter: 3160,\t [19008/82081\t (23%)]\tLoss: 7.527082, Loc Loss: 2.419415, Conf Loss: 5.107667\tIter time: 0.2922\n",
            "Training... Epoch: 2, Iter: 3170,\t [19328/82081\t (24%)]\tLoss: 7.286600, Loc Loss: 1.970838, Conf Loss: 5.315762\tIter time: 0.2768\n",
            "Training... Epoch: 2, Iter: 3180,\t [19648/82081\t (24%)]\tLoss: 7.849273, Loc Loss: 2.378748, Conf Loss: 5.470525\tIter time: 0.2935\n",
            "Training... Epoch: 2, Iter: 3190,\t [19968/82081\t (24%)]\tLoss: 7.651462, Loc Loss: 2.211485, Conf Loss: 5.439977\tIter time: 0.2799\n",
            "Training... Epoch: 2, Iter: 3200,\t [20288/82081\t (25%)]\tLoss: 7.451645, Loc Loss: 2.354494, Conf Loss: 5.097151\tIter time: 0.3089\n",
            "Training... Epoch: 2, Iter: 3210,\t [20608/82081\t (25%)]\tLoss: 7.392300, Loc Loss: 2.138541, Conf Loss: 5.253758\tIter time: 0.2935\n",
            "Training... Epoch: 2, Iter: 3220,\t [20928/82081\t (25%)]\tLoss: 7.225462, Loc Loss: 2.063044, Conf Loss: 5.162418\tIter time: 0.2788\n",
            "Training... Epoch: 2, Iter: 3230,\t [21248/82081\t (26%)]\tLoss: 7.800436, Loc Loss: 2.328373, Conf Loss: 5.472064\tIter time: 0.2856\n",
            "Training... Epoch: 2, Iter: 3240,\t [21568/82081\t (26%)]\tLoss: 7.902279, Loc Loss: 2.209288, Conf Loss: 5.692990\tIter time: 0.2702\n",
            "Training... Epoch: 2, Iter: 3250,\t [21888/82081\t (27%)]\tLoss: 7.530784, Loc Loss: 2.376531, Conf Loss: 5.154253\tIter time: 0.2826\n",
            "Training... Epoch: 2, Iter: 3260,\t [22208/82081\t (27%)]\tLoss: 7.547536, Loc Loss: 2.217597, Conf Loss: 5.329939\tIter time: 0.3084\n",
            "Training... Epoch: 2, Iter: 3270,\t [22528/82081\t (27%)]\tLoss: 8.135112, Loc Loss: 2.449885, Conf Loss: 5.685226\tIter time: 0.2736\n",
            "Training... Epoch: 2, Iter: 3280,\t [22848/82081\t (28%)]\tLoss: 7.406509, Loc Loss: 2.197237, Conf Loss: 5.209272\tIter time: 0.2831\n",
            "Training... Epoch: 2, Iter: 3290,\t [23168/82081\t (28%)]\tLoss: 7.374412, Loc Loss: 2.226802, Conf Loss: 5.147610\tIter time: 0.3012\n",
            "Training... Epoch: 2, Iter: 3300,\t [23488/82081\t (29%)]\tLoss: 7.571259, Loc Loss: 2.203031, Conf Loss: 5.368227\tIter time: 0.2951\n",
            "Training... Epoch: 2, Iter: 3310,\t [23808/82081\t (29%)]\tLoss: 7.757504, Loc Loss: 2.285285, Conf Loss: 5.472219\tIter time: 0.2869\n",
            "Training... Epoch: 2, Iter: 3320,\t [24128/82081\t (29%)]\tLoss: 7.816313, Loc Loss: 2.152709, Conf Loss: 5.663605\tIter time: 0.2791\n",
            "Training... Epoch: 2, Iter: 3330,\t [24448/82081\t (30%)]\tLoss: 7.622551, Loc Loss: 2.153805, Conf Loss: 5.468746\tIter time: 0.2781\n",
            "Training... Epoch: 2, Iter: 3340,\t [24768/82081\t (30%)]\tLoss: 8.080923, Loc Loss: 2.313749, Conf Loss: 5.767174\tIter time: 0.2930\n",
            "Training... Epoch: 2, Iter: 3350,\t [25088/82081\t (31%)]\tLoss: 7.878503, Loc Loss: 2.330471, Conf Loss: 5.548032\tIter time: 0.2929\n",
            "Training... Epoch: 2, Iter: 3360,\t [25408/82081\t (31%)]\tLoss: 7.865715, Loc Loss: 2.091074, Conf Loss: 5.774641\tIter time: 0.2893\n",
            "Training... Epoch: 2, Iter: 3370,\t [25728/82081\t (31%)]\tLoss: 7.881439, Loc Loss: 2.421227, Conf Loss: 5.460213\tIter time: 0.2803\n",
            "Training... Epoch: 2, Iter: 3380,\t [26048/82081\t (32%)]\tLoss: 7.452723, Loc Loss: 2.202565, Conf Loss: 5.250158\tIter time: 0.2709\n",
            "Training... Epoch: 2, Iter: 3390,\t [26368/82081\t (32%)]\tLoss: 7.850077, Loc Loss: 2.390222, Conf Loss: 5.459855\tIter time: 0.2990\n",
            "Training... Epoch: 2, Iter: 3400,\t [26688/82081\t (33%)]\tLoss: 7.741852, Loc Loss: 2.607527, Conf Loss: 5.134326\tIter time: 0.2740\n",
            "Training... Epoch: 2, Iter: 3410,\t [27008/82081\t (33%)]\tLoss: 7.396703, Loc Loss: 2.027995, Conf Loss: 5.368707\tIter time: 0.2873\n",
            "Training... Epoch: 2, Iter: 3420,\t [27328/82081\t (33%)]\tLoss: 7.375283, Loc Loss: 2.238097, Conf Loss: 5.137186\tIter time: 0.2714\n",
            "Training... Epoch: 2, Iter: 3430,\t [27648/82081\t (34%)]\tLoss: 7.409780, Loc Loss: 2.278478, Conf Loss: 5.131301\tIter time: 0.2798\n",
            "Training... Epoch: 2, Iter: 3440,\t [27968/82081\t (34%)]\tLoss: 7.625129, Loc Loss: 2.474840, Conf Loss: 5.150289\tIter time: 0.2974\n",
            "Training... Epoch: 2, Iter: 3450,\t [28288/82081\t (34%)]\tLoss: 7.437999, Loc Loss: 2.260365, Conf Loss: 5.177633\tIter time: 0.2966\n",
            "Training... Epoch: 2, Iter: 3460,\t [28608/82081\t (35%)]\tLoss: 7.676929, Loc Loss: 2.435952, Conf Loss: 5.240976\tIter time: 0.2955\n",
            "Training... Epoch: 2, Iter: 3470,\t [28928/82081\t (35%)]\tLoss: 7.682254, Loc Loss: 2.221656, Conf Loss: 5.460598\tIter time: 0.3065\n",
            "Training... Epoch: 2, Iter: 3480,\t [29248/82081\t (36%)]\tLoss: 7.118189, Loc Loss: 2.174312, Conf Loss: 4.943877\tIter time: 0.3194\n",
            "Training... Epoch: 2, Iter: 3490,\t [29568/82081\t (36%)]\tLoss: 7.822186, Loc Loss: 2.594772, Conf Loss: 5.227414\tIter time: 0.2960\n",
            "Training... Epoch: 2, Iter: 3500,\t [29888/82081\t (36%)]\tLoss: 7.471747, Loc Loss: 2.026741, Conf Loss: 5.445006\tIter time: 0.3022\n",
            "Training... Epoch: 2, Iter: 3510,\t [30208/82081\t (37%)]\tLoss: 7.678631, Loc Loss: 2.252578, Conf Loss: 5.426053\tIter time: 0.2972\n",
            "Training... Epoch: 2, Iter: 3520,\t [30528/82081\t (37%)]\tLoss: 7.314466, Loc Loss: 2.118467, Conf Loss: 5.196000\tIter time: 0.2808\n",
            "Training... Epoch: 2, Iter: 3530,\t [30848/82081\t (38%)]\tLoss: 7.370286, Loc Loss: 2.257976, Conf Loss: 5.112310\tIter time: 0.2854\n",
            "Training... Epoch: 2, Iter: 3540,\t [31168/82081\t (38%)]\tLoss: 7.914313, Loc Loss: 2.569512, Conf Loss: 5.344801\tIter time: 0.2962\n",
            "Training... Epoch: 2, Iter: 3550,\t [31488/82081\t (38%)]\tLoss: 8.109742, Loc Loss: 2.231300, Conf Loss: 5.878442\tIter time: 0.2965\n",
            "Training... Epoch: 2, Iter: 3560,\t [31808/82081\t (39%)]\tLoss: 7.127334, Loc Loss: 1.939343, Conf Loss: 5.187991\tIter time: 0.3170\n",
            "Training... Epoch: 2, Iter: 3570,\t [32128/82081\t (39%)]\tLoss: 7.673223, Loc Loss: 2.107406, Conf Loss: 5.565817\tIter time: 0.2924\n",
            "Training... Epoch: 2, Iter: 3580,\t [32448/82081\t (40%)]\tLoss: 7.658438, Loc Loss: 2.240402, Conf Loss: 5.418036\tIter time: 0.3258\n",
            "Training... Epoch: 2, Iter: 3590,\t [32768/82081\t (40%)]\tLoss: 7.986619, Loc Loss: 2.528203, Conf Loss: 5.458415\tIter time: 0.2821\n",
            "Training... Epoch: 2, Iter: 3600,\t [33088/82081\t (40%)]\tLoss: 7.661428, Loc Loss: 2.334895, Conf Loss: 5.326534\tIter time: 0.2953\n",
            "Training... Epoch: 2, Iter: 3610,\t [33408/82081\t (41%)]\tLoss: 7.386143, Loc Loss: 2.239283, Conf Loss: 5.146860\tIter time: 0.3029\n",
            "Training... Epoch: 2, Iter: 3620,\t [33728/82081\t (41%)]\tLoss: 6.977136, Loc Loss: 1.896879, Conf Loss: 5.080257\tIter time: 0.2918\n",
            "Training... Epoch: 2, Iter: 3630,\t [34048/82081\t (41%)]\tLoss: 7.801794, Loc Loss: 2.607754, Conf Loss: 5.194040\tIter time: 0.3064\n",
            "Training... Epoch: 2, Iter: 3640,\t [34368/82081\t (42%)]\tLoss: 7.465284, Loc Loss: 2.379995, Conf Loss: 5.085289\tIter time: 0.2997\n",
            "Training... Epoch: 2, Iter: 3650,\t [34688/82081\t (42%)]\tLoss: 7.434252, Loc Loss: 2.158117, Conf Loss: 5.276135\tIter time: 0.2800\n",
            "Training... Epoch: 2, Iter: 3660,\t [35008/82081\t (43%)]\tLoss: 7.279948, Loc Loss: 2.103089, Conf Loss: 5.176859\tIter time: 0.2958\n",
            "Training... Epoch: 2, Iter: 3670,\t [35328/82081\t (43%)]\tLoss: 6.998590, Loc Loss: 2.054134, Conf Loss: 4.944456\tIter time: 0.2771\n",
            "Training... Epoch: 2, Iter: 3680,\t [35648/82081\t (43%)]\tLoss: 7.774852, Loc Loss: 2.217667, Conf Loss: 5.557185\tIter time: 0.2986\n",
            "Training... Epoch: 2, Iter: 3690,\t [35968/82081\t (44%)]\tLoss: 7.586543, Loc Loss: 2.325744, Conf Loss: 5.260799\tIter time: 0.2968\n",
            "Training... Epoch: 2, Iter: 3700,\t [36288/82081\t (44%)]\tLoss: 6.974786, Loc Loss: 2.101261, Conf Loss: 4.873526\tIter time: 0.2922\n",
            "Training... Epoch: 2, Iter: 3710,\t [36608/82081\t (45%)]\tLoss: 7.569314, Loc Loss: 2.170087, Conf Loss: 5.399228\tIter time: 0.3014\n",
            "Training... Epoch: 2, Iter: 3720,\t [36928/82081\t (45%)]\tLoss: 7.279282, Loc Loss: 2.181472, Conf Loss: 5.097810\tIter time: 0.2731\n",
            "Training... Epoch: 2, Iter: 3730,\t [37248/82081\t (45%)]\tLoss: 7.336013, Loc Loss: 2.094676, Conf Loss: 5.241337\tIter time: 0.2953\n",
            "Training... Epoch: 2, Iter: 3740,\t [37568/82081\t (46%)]\tLoss: 7.677155, Loc Loss: 2.327493, Conf Loss: 5.349662\tIter time: 0.2691\n",
            "Training... Epoch: 2, Iter: 3750,\t [37888/82081\t (46%)]\tLoss: 7.329774, Loc Loss: 2.385618, Conf Loss: 4.944157\tIter time: 0.2970\n",
            "Training... Epoch: 2, Iter: 3760,\t [38208/82081\t (47%)]\tLoss: 7.651862, Loc Loss: 2.356336, Conf Loss: 5.295527\tIter time: 0.2840\n",
            "Training... Epoch: 2, Iter: 3770,\t [38528/82081\t (47%)]\tLoss: 7.922292, Loc Loss: 2.504084, Conf Loss: 5.418208\tIter time: 0.2720\n",
            "Training... Epoch: 2, Iter: 3780,\t [38848/82081\t (47%)]\tLoss: 7.327259, Loc Loss: 2.337691, Conf Loss: 4.989568\tIter time: 0.2924\n",
            "Training... Epoch: 2, Iter: 3790,\t [39168/82081\t (48%)]\tLoss: 7.121120, Loc Loss: 2.060202, Conf Loss: 5.060919\tIter time: 0.3069\n",
            "Training... Epoch: 2, Iter: 3800,\t [39488/82081\t (48%)]\tLoss: 7.380656, Loc Loss: 2.429040, Conf Loss: 4.951615\tIter time: 0.2958\n",
            "Training... Epoch: 2, Iter: 3810,\t [39808/82081\t (48%)]\tLoss: 7.450915, Loc Loss: 1.956800, Conf Loss: 5.494115\tIter time: 0.2769\n",
            "Training... Epoch: 2, Iter: 3820,\t [40128/82081\t (49%)]\tLoss: 7.796678, Loc Loss: 2.106839, Conf Loss: 5.689839\tIter time: 0.3095\n",
            "Training... Epoch: 2, Iter: 3830,\t [40448/82081\t (49%)]\tLoss: 7.502223, Loc Loss: 2.252502, Conf Loss: 5.249720\tIter time: 0.2978\n",
            "Training... Epoch: 2, Iter: 3840,\t [40768/82081\t (50%)]\tLoss: 6.964008, Loc Loss: 2.171381, Conf Loss: 4.792627\tIter time: 0.2809\n",
            "Training... Epoch: 2, Iter: 3850,\t [41088/82081\t (50%)]\tLoss: 7.226465, Loc Loss: 2.125369, Conf Loss: 5.101096\tIter time: 0.2911\n",
            "Training... Epoch: 2, Iter: 3860,\t [41408/82081\t (50%)]\tLoss: 7.595257, Loc Loss: 2.280253, Conf Loss: 5.315004\tIter time: 0.2897\n",
            "Training... Epoch: 2, Iter: 3870,\t [41728/82081\t (51%)]\tLoss: 7.115293, Loc Loss: 2.143734, Conf Loss: 4.971560\tIter time: 0.2714\n",
            "Training... Epoch: 2, Iter: 3880,\t [42048/82081\t (51%)]\tLoss: 6.974628, Loc Loss: 1.878373, Conf Loss: 5.096255\tIter time: 0.2970\n",
            "Training... Epoch: 2, Iter: 3890,\t [42368/82081\t (52%)]\tLoss: 8.011816, Loc Loss: 2.527731, Conf Loss: 5.484085\tIter time: 0.2734\n",
            "Training... Epoch: 2, Iter: 3900,\t [42688/82081\t (52%)]\tLoss: 7.343550, Loc Loss: 2.015811, Conf Loss: 5.327739\tIter time: 0.3013\n",
            "Training... Epoch: 2, Iter: 3910,\t [43008/82081\t (52%)]\tLoss: 7.508026, Loc Loss: 2.340909, Conf Loss: 5.167117\tIter time: 0.2795\n",
            "Training... Epoch: 2, Iter: 3920,\t [43328/82081\t (53%)]\tLoss: 7.085929, Loc Loss: 2.107656, Conf Loss: 4.978273\tIter time: 0.2865\n",
            "Training... Epoch: 2, Iter: 3930,\t [43648/82081\t (53%)]\tLoss: 7.402825, Loc Loss: 2.111109, Conf Loss: 5.291717\tIter time: 0.2846\n",
            "Training... Epoch: 2, Iter: 3940,\t [43968/82081\t (54%)]\tLoss: 7.669546, Loc Loss: 2.236268, Conf Loss: 5.433279\tIter time: 0.2803\n",
            "Training... Epoch: 2, Iter: 3950,\t [44288/82081\t (54%)]\tLoss: 7.090458, Loc Loss: 2.056422, Conf Loss: 5.034036\tIter time: 0.2802\n",
            "Training... Epoch: 2, Iter: 3960,\t [44608/82081\t (54%)]\tLoss: 7.299378, Loc Loss: 2.094418, Conf Loss: 5.204961\tIter time: 0.2932\n",
            "Training... Epoch: 2, Iter: 3970,\t [44928/82081\t (55%)]\tLoss: 6.865724, Loc Loss: 1.931082, Conf Loss: 4.934641\tIter time: 0.2734\n",
            "Training... Epoch: 2, Iter: 3980,\t [45248/82081\t (55%)]\tLoss: 7.460296, Loc Loss: 2.152231, Conf Loss: 5.308065\tIter time: 0.2974\n",
            "Training... Epoch: 2, Iter: 3990,\t [45568/82081\t (55%)]\tLoss: 7.079225, Loc Loss: 2.029358, Conf Loss: 5.049866\tIter time: 0.2902\n",
            "Training... Epoch: 2, Iter: 4000,\t [45888/82081\t (56%)]\tLoss: 6.995811, Loc Loss: 1.847654, Conf Loss: 5.148156\tIter time: 0.2767\n",
            "Training... Epoch: 2, Iter: 4010,\t [46208/82081\t (56%)]\tLoss: 7.541457, Loc Loss: 2.392484, Conf Loss: 5.148973\tIter time: 0.3124\n",
            "Training... Epoch: 2, Iter: 4020,\t [46528/82081\t (57%)]\tLoss: 7.347980, Loc Loss: 2.148463, Conf Loss: 5.199517\tIter time: 0.2784\n",
            "Training... Epoch: 2, Iter: 4030,\t [46848/82081\t (57%)]\tLoss: 7.397994, Loc Loss: 2.177994, Conf Loss: 5.220000\tIter time: 0.3080\n",
            "Training... Epoch: 2, Iter: 4040,\t [47168/82081\t (57%)]\tLoss: 8.121630, Loc Loss: 2.666054, Conf Loss: 5.455575\tIter time: 0.2957\n",
            "Training... Epoch: 2, Iter: 4050,\t [47488/82081\t (58%)]\tLoss: 7.667007, Loc Loss: 2.322704, Conf Loss: 5.344304\tIter time: 0.2877\n",
            "Training... Epoch: 2, Iter: 4060,\t [47808/82081\t (58%)]\tLoss: 7.248519, Loc Loss: 2.171320, Conf Loss: 5.077199\tIter time: 0.2794\n",
            "Training... Epoch: 2, Iter: 4070,\t [48128/82081\t (59%)]\tLoss: 7.781953, Loc Loss: 2.155771, Conf Loss: 5.626182\tIter time: 0.2957\n",
            "Training... Epoch: 2, Iter: 4080,\t [48448/82081\t (59%)]\tLoss: 6.685241, Loc Loss: 2.057165, Conf Loss: 4.628076\tIter time: 0.2828\n",
            "Training... Epoch: 2, Iter: 4090,\t [48768/82081\t (59%)]\tLoss: 7.154909, Loc Loss: 2.201839, Conf Loss: 4.953070\tIter time: 0.2930\n",
            "Training... Epoch: 2, Iter: 4100,\t [49088/82081\t (60%)]\tLoss: 7.013693, Loc Loss: 2.025435, Conf Loss: 4.988258\tIter time: 0.2891\n",
            "Training... Epoch: 2, Iter: 4110,\t [49408/82081\t (60%)]\tLoss: 7.854820, Loc Loss: 2.641552, Conf Loss: 5.213268\tIter time: 0.2991\n",
            "Training... Epoch: 2, Iter: 4120,\t [49728/82081\t (61%)]\tLoss: 7.199734, Loc Loss: 2.074613, Conf Loss: 5.125120\tIter time: 0.2886\n",
            "Training... Epoch: 2, Iter: 4130,\t [50048/82081\t (61%)]\tLoss: 7.216085, Loc Loss: 2.233903, Conf Loss: 4.982182\tIter time: 0.2869\n",
            "Training... Epoch: 2, Iter: 4140,\t [50368/82081\t (61%)]\tLoss: 6.937223, Loc Loss: 1.915876, Conf Loss: 5.021348\tIter time: 0.2874\n",
            "Training... Epoch: 2, Iter: 4150,\t [50688/82081\t (62%)]\tLoss: 7.077226, Loc Loss: 2.052662, Conf Loss: 5.024563\tIter time: 0.2924\n",
            "Training... Epoch: 2, Iter: 4160,\t [51008/82081\t (62%)]\tLoss: 7.465369, Loc Loss: 2.095550, Conf Loss: 5.369819\tIter time: 0.2943\n",
            "Training... Epoch: 2, Iter: 4170,\t [51328/82081\t (63%)]\tLoss: 7.373569, Loc Loss: 2.187295, Conf Loss: 5.186274\tIter time: 0.2914\n",
            "Training... Epoch: 2, Iter: 4180,\t [51648/82081\t (63%)]\tLoss: 7.100109, Loc Loss: 2.137288, Conf Loss: 4.962821\tIter time: 0.2756\n",
            "Training... Epoch: 2, Iter: 4190,\t [51968/82081\t (63%)]\tLoss: 7.779641, Loc Loss: 2.313576, Conf Loss: 5.466065\tIter time: 0.2739\n",
            "Training... Epoch: 2, Iter: 4200,\t [52288/82081\t (64%)]\tLoss: 7.158017, Loc Loss: 2.138868, Conf Loss: 5.019149\tIter time: 0.2811\n",
            "Training... Epoch: 2, Iter: 4210,\t [52608/82081\t (64%)]\tLoss: 7.350407, Loc Loss: 2.326091, Conf Loss: 5.024316\tIter time: 0.2961\n",
            "Training... Epoch: 2, Iter: 4220,\t [52928/82081\t (64%)]\tLoss: 7.029200, Loc Loss: 2.121548, Conf Loss: 4.907651\tIter time: 0.2860\n",
            "Training... Epoch: 2, Iter: 4230,\t [53248/82081\t (65%)]\tLoss: 7.186290, Loc Loss: 2.297724, Conf Loss: 4.888566\tIter time: 0.3058\n",
            "Training... Epoch: 2, Iter: 4240,\t [53568/82081\t (65%)]\tLoss: 7.057201, Loc Loss: 1.879934, Conf Loss: 5.177268\tIter time: 0.2672\n",
            "Training... Epoch: 2, Iter: 4250,\t [53888/82081\t (66%)]\tLoss: 7.576562, Loc Loss: 2.426367, Conf Loss: 5.150195\tIter time: 0.2717\n",
            "Training... Epoch: 2, Iter: 4260,\t [54208/82081\t (66%)]\tLoss: 7.433588, Loc Loss: 2.272930, Conf Loss: 5.160658\tIter time: 0.2884\n",
            "Training... Epoch: 2, Iter: 4270,\t [54528/82081\t (66%)]\tLoss: 7.044519, Loc Loss: 1.930449, Conf Loss: 5.114070\tIter time: 0.2886\n",
            "Training... Epoch: 2, Iter: 4280,\t [54848/82081\t (67%)]\tLoss: 7.009416, Loc Loss: 1.964013, Conf Loss: 5.045403\tIter time: 0.2877\n",
            "Training... Epoch: 2, Iter: 4290,\t [55168/82081\t (67%)]\tLoss: 7.554822, Loc Loss: 1.913878, Conf Loss: 5.640944\tIter time: 0.3068\n",
            "Training... Epoch: 2, Iter: 4300,\t [55488/82081\t (68%)]\tLoss: 7.791348, Loc Loss: 2.552309, Conf Loss: 5.239039\tIter time: 0.3083\n",
            "Training... Epoch: 2, Iter: 4310,\t [55808/82081\t (68%)]\tLoss: 7.383714, Loc Loss: 2.361515, Conf Loss: 5.022199\tIter time: 0.2859\n",
            "Training... Epoch: 2, Iter: 4320,\t [56128/82081\t (68%)]\tLoss: 7.251929, Loc Loss: 2.157999, Conf Loss: 5.093931\tIter time: 0.2887\n",
            "Training... Epoch: 2, Iter: 4330,\t [56448/82081\t (69%)]\tLoss: 7.398765, Loc Loss: 2.271514, Conf Loss: 5.127251\tIter time: 0.2964\n",
            "Training... Epoch: 2, Iter: 4340,\t [56768/82081\t (69%)]\tLoss: 7.194087, Loc Loss: 2.378674, Conf Loss: 4.815413\tIter time: 0.2926\n",
            "Training... Epoch: 2, Iter: 4350,\t [57088/82081\t (70%)]\tLoss: 7.301395, Loc Loss: 2.235747, Conf Loss: 5.065648\tIter time: 0.2971\n",
            "Training... Epoch: 2, Iter: 4360,\t [57408/82081\t (70%)]\tLoss: 7.695705, Loc Loss: 2.344147, Conf Loss: 5.351558\tIter time: 0.2721\n",
            "Training... Epoch: 2, Iter: 4370,\t [57728/82081\t (70%)]\tLoss: 7.353552, Loc Loss: 2.086967, Conf Loss: 5.266585\tIter time: 0.2929\n",
            "Training... Epoch: 2, Iter: 4380,\t [58048/82081\t (71%)]\tLoss: 7.260448, Loc Loss: 2.065647, Conf Loss: 5.194801\tIter time: 0.2974\n",
            "Training... Epoch: 2, Iter: 4390,\t [58368/82081\t (71%)]\tLoss: 7.135459, Loc Loss: 2.256251, Conf Loss: 4.879209\tIter time: 0.3117\n",
            "Training... Epoch: 2, Iter: 4400,\t [58688/82081\t (71%)]\tLoss: 7.558890, Loc Loss: 2.127542, Conf Loss: 5.431347\tIter time: 0.2835\n",
            "Training... Epoch: 2, Iter: 4410,\t [59008/82081\t (72%)]\tLoss: 7.414108, Loc Loss: 2.382722, Conf Loss: 5.031386\tIter time: 0.2885\n",
            "Training... Epoch: 2, Iter: 4420,\t [59328/82081\t (72%)]\tLoss: 7.258461, Loc Loss: 2.051678, Conf Loss: 5.206783\tIter time: 0.2715\n",
            "Training... Epoch: 2, Iter: 4430,\t [59648/82081\t (73%)]\tLoss: 7.325466, Loc Loss: 2.156526, Conf Loss: 5.168940\tIter time: 0.3283\n",
            "Training... Epoch: 2, Iter: 4440,\t [59968/82081\t (73%)]\tLoss: 7.922567, Loc Loss: 2.577296, Conf Loss: 5.345271\tIter time: 0.3126\n",
            "Training... Epoch: 2, Iter: 4450,\t [60288/82081\t (73%)]\tLoss: 6.879525, Loc Loss: 2.159959, Conf Loss: 4.719567\tIter time: 0.3060\n",
            "Training... Epoch: 2, Iter: 4460,\t [60608/82081\t (74%)]\tLoss: 6.816780, Loc Loss: 2.015360, Conf Loss: 4.801421\tIter time: 0.3022\n",
            "Training... Epoch: 2, Iter: 4470,\t [60928/82081\t (74%)]\tLoss: 7.713026, Loc Loss: 2.481514, Conf Loss: 5.231512\tIter time: 0.2952\n",
            "Training... Epoch: 2, Iter: 4480,\t [61248/82081\t (75%)]\tLoss: 7.420455, Loc Loss: 2.214422, Conf Loss: 5.206033\tIter time: 0.2793\n",
            "Training... Epoch: 2, Iter: 4490,\t [61568/82081\t (75%)]\tLoss: 7.826786, Loc Loss: 2.411000, Conf Loss: 5.415786\tIter time: 0.2853\n",
            "Training... Epoch: 2, Iter: 4500,\t [61888/82081\t (75%)]\tLoss: 7.103401, Loc Loss: 2.097790, Conf Loss: 5.005611\tIter time: 0.2781\n",
            "Training... Epoch: 2, Iter: 4510,\t [62208/82081\t (76%)]\tLoss: 7.331643, Loc Loss: 2.365620, Conf Loss: 4.966022\tIter time: 0.2817\n",
            "Training... Epoch: 2, Iter: 4520,\t [62528/82081\t (76%)]\tLoss: 6.994234, Loc Loss: 2.222443, Conf Loss: 4.771791\tIter time: 0.2937\n",
            "Training... Epoch: 2, Iter: 4530,\t [62848/82081\t (77%)]\tLoss: 7.220660, Loc Loss: 2.120175, Conf Loss: 5.100486\tIter time: 0.2967\n",
            "Training... Epoch: 2, Iter: 4540,\t [63168/82081\t (77%)]\tLoss: 7.775116, Loc Loss: 2.420823, Conf Loss: 5.354293\tIter time: 0.2991\n",
            "Training... Epoch: 2, Iter: 4550,\t [63488/82081\t (77%)]\tLoss: 7.351220, Loc Loss: 2.228376, Conf Loss: 5.122845\tIter time: 0.3080\n",
            "Training... Epoch: 2, Iter: 4560,\t [63808/82081\t (78%)]\tLoss: 7.298486, Loc Loss: 1.932075, Conf Loss: 5.366411\tIter time: 0.2715\n",
            "Training... Epoch: 2, Iter: 4570,\t [64128/82081\t (78%)]\tLoss: 7.027729, Loc Loss: 2.162758, Conf Loss: 4.864972\tIter time: 0.2968\n",
            "Training... Epoch: 2, Iter: 4580,\t [64448/82081\t (78%)]\tLoss: 7.379576, Loc Loss: 2.158205, Conf Loss: 5.221371\tIter time: 0.2936\n",
            "Training... Epoch: 2, Iter: 4590,\t [64768/82081\t (79%)]\tLoss: 7.039067, Loc Loss: 1.890277, Conf Loss: 5.148790\tIter time: 0.2827\n",
            "Training... Epoch: 2, Iter: 4600,\t [65088/82081\t (79%)]\tLoss: 7.251016, Loc Loss: 2.134838, Conf Loss: 5.116177\tIter time: 0.2917\n",
            "Training... Epoch: 2, Iter: 4610,\t [65408/82081\t (80%)]\tLoss: 7.249708, Loc Loss: 2.361394, Conf Loss: 4.888313\tIter time: 0.2769\n",
            "Training... Epoch: 2, Iter: 4620,\t [65728/82081\t (80%)]\tLoss: 7.891653, Loc Loss: 2.229043, Conf Loss: 5.662610\tIter time: 0.2802\n",
            "Training... Epoch: 2, Iter: 4630,\t [66048/82081\t (80%)]\tLoss: 7.255520, Loc Loss: 2.069998, Conf Loss: 5.185523\tIter time: 0.2810\n",
            "Training... Epoch: 2, Iter: 4640,\t [66368/82081\t (81%)]\tLoss: 7.138628, Loc Loss: 2.348307, Conf Loss: 4.790321\tIter time: 0.3067\n",
            "Training... Epoch: 2, Iter: 4650,\t [66688/82081\t (81%)]\tLoss: 7.447873, Loc Loss: 2.076578, Conf Loss: 5.371295\tIter time: 0.2791\n",
            "Training... Epoch: 2, Iter: 4660,\t [67008/82081\t (82%)]\tLoss: 7.355475, Loc Loss: 1.964639, Conf Loss: 5.390837\tIter time: 0.2925\n",
            "Training... Epoch: 2, Iter: 4670,\t [67328/82081\t (82%)]\tLoss: 7.021345, Loc Loss: 2.091343, Conf Loss: 4.930002\tIter time: 0.2903\n",
            "Training... Epoch: 2, Iter: 4680,\t [67648/82081\t (82%)]\tLoss: 7.174658, Loc Loss: 2.321077, Conf Loss: 4.853581\tIter time: 0.2796\n",
            "Training... Epoch: 2, Iter: 4690,\t [67968/82081\t (83%)]\tLoss: 7.447585, Loc Loss: 1.949001, Conf Loss: 5.498585\tIter time: 0.3261\n",
            "Training... Epoch: 2, Iter: 4700,\t [68288/82081\t (83%)]\tLoss: 7.035948, Loc Loss: 2.281702, Conf Loss: 4.754246\tIter time: 0.2999\n",
            "Training... Epoch: 2, Iter: 4710,\t [68608/82081\t (84%)]\tLoss: 7.706166, Loc Loss: 2.014675, Conf Loss: 5.691491\tIter time: 0.2904\n",
            "Training... Epoch: 2, Iter: 4720,\t [68928/82081\t (84%)]\tLoss: 7.397629, Loc Loss: 2.157490, Conf Loss: 5.240139\tIter time: 0.2813\n",
            "Training... Epoch: 2, Iter: 4730,\t [69248/82081\t (84%)]\tLoss: 7.457347, Loc Loss: 2.099685, Conf Loss: 5.357662\tIter time: 0.2920\n",
            "Training... Epoch: 2, Iter: 4740,\t [69568/82081\t (85%)]\tLoss: 7.724577, Loc Loss: 2.299435, Conf Loss: 5.425141\tIter time: 0.2740\n",
            "Training... Epoch: 2, Iter: 4750,\t [69888/82081\t (85%)]\tLoss: 8.077146, Loc Loss: 2.728856, Conf Loss: 5.348289\tIter time: 0.3044\n",
            "Training... Epoch: 2, Iter: 4760,\t [70208/82081\t (86%)]\tLoss: 7.460033, Loc Loss: 2.578853, Conf Loss: 4.881180\tIter time: 0.3173\n",
            "Training... Epoch: 2, Iter: 4770,\t [70528/82081\t (86%)]\tLoss: 7.118752, Loc Loss: 2.125832, Conf Loss: 4.992920\tIter time: 0.2994\n",
            "Training... Epoch: 2, Iter: 4780,\t [70848/82081\t (86%)]\tLoss: 7.420465, Loc Loss: 2.074004, Conf Loss: 5.346460\tIter time: 0.2676\n",
            "Training... Epoch: 2, Iter: 4790,\t [71168/82081\t (87%)]\tLoss: 6.869438, Loc Loss: 1.921876, Conf Loss: 4.947561\tIter time: 0.2862\n",
            "Training... Epoch: 2, Iter: 4800,\t [71488/82081\t (87%)]\tLoss: 7.354908, Loc Loss: 2.152698, Conf Loss: 5.202209\tIter time: 0.2821\n",
            "Training... Epoch: 2, Iter: 4810,\t [71808/82081\t (87%)]\tLoss: 7.464498, Loc Loss: 2.066880, Conf Loss: 5.397617\tIter time: 0.2950\n",
            "Training... Epoch: 2, Iter: 4820,\t [72128/82081\t (88%)]\tLoss: 7.350653, Loc Loss: 2.326834, Conf Loss: 5.023818\tIter time: 0.2705\n",
            "Training... Epoch: 2, Iter: 4830,\t [72448/82081\t (88%)]\tLoss: 7.661394, Loc Loss: 2.447153, Conf Loss: 5.214242\tIter time: 0.3009\n",
            "Training... Epoch: 2, Iter: 4840,\t [72768/82081\t (89%)]\tLoss: 6.981485, Loc Loss: 2.041991, Conf Loss: 4.939495\tIter time: 0.2921\n",
            "Training... Epoch: 2, Iter: 4850,\t [73088/82081\t (89%)]\tLoss: 7.281583, Loc Loss: 2.014833, Conf Loss: 5.266749\tIter time: 0.2909\n",
            "Training... Epoch: 2, Iter: 4860,\t [73408/82081\t (89%)]\tLoss: 7.399212, Loc Loss: 2.234542, Conf Loss: 5.164670\tIter time: 0.2983\n",
            "Training... Epoch: 2, Iter: 4870,\t [73728/82081\t (90%)]\tLoss: 7.318278, Loc Loss: 2.101378, Conf Loss: 5.216900\tIter time: 0.2763\n",
            "Training... Epoch: 2, Iter: 4880,\t [74048/82081\t (90%)]\tLoss: 7.107306, Loc Loss: 2.288366, Conf Loss: 4.818939\tIter time: 0.3052\n",
            "Training... Epoch: 2, Iter: 4890,\t [74368/82081\t (91%)]\tLoss: 6.953015, Loc Loss: 2.172340, Conf Loss: 4.780675\tIter time: 0.2886\n",
            "Training... Epoch: 2, Iter: 4900,\t [74688/82081\t (91%)]\tLoss: 7.148400, Loc Loss: 2.002753, Conf Loss: 5.145648\tIter time: 0.2690\n",
            "Training... Epoch: 2, Iter: 4910,\t [75008/82081\t (91%)]\tLoss: 7.375514, Loc Loss: 2.275083, Conf Loss: 5.100430\tIter time: 0.2795\n",
            "Training... Epoch: 2, Iter: 4920,\t [75328/82081\t (92%)]\tLoss: 7.200087, Loc Loss: 2.036390, Conf Loss: 5.163697\tIter time: 0.2946\n",
            "Training... Epoch: 2, Iter: 4930,\t [75648/82081\t (92%)]\tLoss: 6.960110, Loc Loss: 1.948340, Conf Loss: 5.011770\tIter time: 0.2850\n",
            "Training... Epoch: 2, Iter: 4940,\t [75968/82081\t (93%)]\tLoss: 7.232592, Loc Loss: 2.339050, Conf Loss: 4.893541\tIter time: 0.2999\n",
            "Training... Epoch: 2, Iter: 4950,\t [76288/82081\t (93%)]\tLoss: 7.091183, Loc Loss: 2.304218, Conf Loss: 4.786965\tIter time: 0.2859\n",
            "Training... Epoch: 2, Iter: 4960,\t [76608/82081\t (93%)]\tLoss: 6.727638, Loc Loss: 1.969767, Conf Loss: 4.757871\tIter time: 0.3039\n",
            "Training... Epoch: 2, Iter: 4970,\t [76928/82081\t (94%)]\tLoss: 7.569490, Loc Loss: 2.226766, Conf Loss: 5.342724\tIter time: 0.2845\n",
            "Training... Epoch: 2, Iter: 4980,\t [77248/82081\t (94%)]\tLoss: 7.337811, Loc Loss: 2.078702, Conf Loss: 5.259109\tIter time: 0.3125\n",
            "Training... Epoch: 2, Iter: 4990,\t [77568/82081\t (94%)]\tLoss: 8.059103, Loc Loss: 2.476211, Conf Loss: 5.582891\tIter time: 0.2981\n",
            "Training... Epoch: 2, Iter: 5000,\t [77888/82081\t (95%)]\tLoss: 7.388043, Loc Loss: 2.214238, Conf Loss: 5.173805\tIter time: 0.2976\n",
            "\n",
            "Training finished\n",
            "Saved model to ./weights/results/SSD300_i-5000.pth\n",
            "Saved graph to ./weights/results/SSD300_learning-curve_i-5000.png\n"
          ]
        }
      ],
      "source": [
        "#augmentation + batchnorm\n",
        "!python easy_train.py COCO -na -bn --max_iteration 5000"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "ssd_extending.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvbh79yOd8UdoZ6il03Hpu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}